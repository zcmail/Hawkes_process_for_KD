{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Experiment parameters\n",
      "=====================\n",
      "        exp_dir = .\n",
      " param_filename = params.json\n",
      "output_filename = penalty10_decay0.3+s032_10400-10450-2.json\n",
      "\n",
      "\n",
      "Start time is:  2020-03-18 17:51:04.468028\n",
      "\n",
      "Number of jumps: 1100\n",
      "\n",
      "per node: [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n",
      "\n",
      "INFERENCE\n",
      "=========\n",
      "\n",
      "Run VI (vi_exp)\n",
      "------\n",
      "vi random seed: 19424\n",
      "\n",
      "\n",
      "\n",
      "Save results...\n",
      "\n",
      "coeffs: [-0.1898204603640246, -3.2213385361296356, -3.745944678435798, -3.756940678904234, -3.7237081209313825, -4.25962950884117, -4.659875792614725, -4.780056913223221, -4.858173471102482, -4.9117358466320855, -5.004432329516409, -4.279241752413425, -4.569074259045719, -4.536307454684296, -4.469544175583058, -4.301934972843825, -4.0787515141401265, -3.9536681863340224, -3.8509739896255355, -3.7288425818176925, -3.5041671407287267, -2.9807294725290756, 0.4663735589952158, -4.238177111910703, -4.538926727707631, -4.4963192338113664, -4.302411852801408, -4.081195871961445, -3.939053652044516, -3.8381490574854493, -3.7541800240814682, -3.488278069485897, -2.9820013724119536, -2.7307243697883785, 0.5071843452297523, -4.2177944650796855, -4.4535164709171795, -4.289249828162512, -4.0830178636287995, -3.958653556822058, -3.8410787922402645, -3.722026274808092, -3.4802183931181574, -2.994941835351868, -2.9889737597100328, -1.9568827537425444, 0.45493574730688835, -4.146393401660224, -4.3045089784551305, -4.080173615602414, -3.952739448922681, -3.8497952587956497, -3.7407044736516966, -3.497293993725383, -2.970469698098214, -3.4247993302517976, -2.9046874842882593, -2.333158127847108, 0.5061855258377941, -3.910081244920555, -4.083817823358493, -3.9499218253608097, -3.8427592753186532, -3.740890276861466, -3.472393883421151, -2.987145746465172, -3.9082259159375603, -3.670552367230807, -3.45488384025633, -3.206552467656974, 0.754315953415786, -3.649644538234083, -3.9563810875455676, -3.8554352056407857, -3.731617839683714, -3.500826193618877, -2.96755750229645, -4.193762377123535, -4.039513459526427, -3.90077705067124, -3.769804584856823, -3.1310123598045854, 0.9930225193732585, -3.614323996546078, -3.8250200150994624, -3.7227872027845885, -3.4739371011279037, -3.008150426485423, -4.256135554308072, -4.1194959188401095, -4.032049247547333, -3.886997917178395, -3.3763455727928293, -2.199699225293694, 1.0843956219304158, -3.510305276484828, -3.746244010107102, -3.4910411030065154, -2.9912442603743936, -4.334936827584331, -4.210069039663473, -4.136546238639341, -4.0149104031008305, -3.5998275480120996, -2.8178633834502653, -1.9971447844965584, 1.1629403258205167, -3.3910586785792467, -3.483920025345519, -2.9844515670171523, -4.401673082045694, -4.262185424853096, -4.19140404855685, -4.098702876790832, -3.7337841733676522, -3.137697035463845, -2.6374475793261434, -2.018477258553404, 1.2797161147498477, -3.0846276923637865, -3.0183320262442948, -4.438906658941121, -4.3608352883917005, -4.284794810998394, -4.205663448957459, -3.911549023588965, -3.4821825797699923, -3.152176342497469, -2.863179973264889, -2.4150291260820076, 1.5513388472663832, -2.4061947864086966, -2.3855732298363947, -0.2243952203756365, -0.11354248829842682, -0.08278865416126861, -0.1186174238121378, -0.03977536758888697, -0.004826190139710669, 0.009927889303308424, -0.009895015039136961, 0.005086093667035808, 0.009705367981368982, 0.006834340359829002, -0.01066119942824957, -0.00805867354532941, 0.014830218703868796, 0.012045773212352794, 0.017443762549691634, 0.008265397157366934, -0.006520413207713291, 0.008425073606289036, -0.009116514850791848, -0.0029009308228112574, -2.31339813709851, 0.01397529468928789, -0.019176968911056837, 0.009828770493236752, 0.008590627742910582, 0.0032821255790248423, 0.02618386706033529, 0.017093752936116695, 0.0037378483924370744, 0.012093039390278424, 0.016764384322937784, -0.1498946615828945, -2.2813144748022474, 0.0005354778469671452, 0.009026459994176278, 0.004739407711683817, 0.007918237903170519, 0.004110400512257145, 0.042649896531842, 0.02883035304610662, 0.00784960787048854, 0.015086630066243896, -0.09660125239754966, -0.3938709187150136, -2.1800841603847645, -0.001948361250923285, -0.003149167949420045, -0.01010083616301438, 0.008562568910032833, 0.004538556760453366, -0.009816572088160246, 0.012885118059076996, -1.1051862654781945e-05, -0.0343164686566803, -0.11231774711703718, -0.23904088538416543, -2.190301054925933, -0.011747540707811656, 0.017806242431705643, 0.019945897312267914, 0.007994057794662463, -0.0011037372113523497, 0.003180244712536068, 0.0010713130209212085, -0.0027670418591031506, -0.02817098992655606, -0.023435011715411683, -0.04607433578390006, -2.258370037431991, -0.00037882485010164526, -0.005105871220483934, -0.007740904708003623, 0.001068622808817559, -0.0006328813937798378, 0.012520801240307036, -0.011354056869861212, 0.009455578754309434, 0.007735063040281967, -0.0007381699082698006, -0.03970629716897993, -2.2757384936471055, -0.008036535876276852, 0.00047907962275842863, -0.012504666874162447, 0.030088981797165657, 0.010281389544915788, 0.021828478273032054, 0.011103615985156147, -0.012997172094465425, 0.016660291156835583, -0.025434091360459102, -0.15339992374077926, -2.232283192019656, 0.00787077940503376, -0.0027630260686788834, 0.001314220620551564, 0.011284102290170007, -0.002266662526933905, 0.00037759674778494346, 0.007865804044373167, 0.0028001876206133216, 0.01610739025247421, -0.04676685969361826, -0.15470925784716616, -2.217072546291789, -0.0035682694160514505, 0.021180558602223332, 0.006943217440530517, 0.0011528797123480097, 0.01367705641795117, -0.017841917264743174, 0.001373389213178694, -0.015111563086746096, -0.014684488403436622, -0.05686617147206118, -0.14410195641186985, -2.209845811902814, -0.0016305088721081831, -0.0021707354545532423, -0.005527836454016843, -0.002246133810872829, 0.006783609651362285, -0.0005199435396683107, -0.009125706896240796, -0.010390668696124542, -0.0023528249634110505, -0.004289636514726131, -0.060583179566301625, -2.234285293436705, -0.01173260062168991]\n",
      "\n",
      "adjacency: [0.0050266361470321175, 0.003895327288139923, 0.004004569090887985, 0.004088206698415634, 0.004861933575542361, 0.006010455468092053, 0.006940812959135702, 0.007922742749417663, 0.008687800371944884, 0.011264497344814951, 0.018780345480473165, 1.5786775425991375, 0.005161531279512506, 0.004081466216349202, 0.004021214705243818, 0.004894018396365396, 0.006171695292462755, 0.006786521080490352, 0.007650933035997687, 0.008551199327494935, 0.01096815720457155, 0.01802314407076451, 0.031064217647682437, 1.643371220826008, 0.005413464545815517, 0.004203939025886354, 0.004997718804104973, 0.006102965972353538, 0.006964647791172624, 0.007225619550735702, 0.008384405583601748, 0.011153058776449587, 0.017853157039058484, 0.022075457912922224, 0.08965793586085687, 1.5560639289324578, 0.0058430388787521, 0.0050004346741440555, 0.006344451485270389, 0.006943064283107597, 0.007758907861068292, 0.00890392752611193, 0.010852073044820294, 0.01886498737835094, 0.012797970662571352, 0.02463727300679218, 0.05217615823568291, 1.6383140693621774, 0.007545076678835595, 0.00597559247046454, 0.006801446394633157, 0.007759201227342831, 0.008750142989240975, 0.011347309135745222, 0.018512841185144867, 0.007426451560387516, 0.009894579440337689, 0.012166180644187148, 0.01626854120888849, 2.1030556833452114, 0.009572248238279455, 0.007110225584311296, 0.007906479835617345, 0.008793368942205318, 0.01111387188469533, 0.01844586082191349, 0.005677126046529025, 0.006354420506420746, 0.00732569345738072, 0.00849455988175132, 0.01734118260023814, 2.671048016912409, 0.010068138882860475, 0.008018702658034208, 0.009112683801791597, 0.010716586122959018, 0.017793428485049, 0.004987804249008243, 0.00584626918782354, 0.006695029806287695, 0.007292711548745472, 0.013210418046544702, 0.05310431547834784, 2.923805252241889, 0.010822030230710704, 0.008732241371401222, 0.011179505962549999, 0.018059759397210256, 0.004842066132137172, 0.005457172293244402, 0.0057854898853792035, 0.006601050408833094, 0.00972975228726603, 0.024027153511543886, 0.06515290723861, 3.161590173839073, 0.012476011675867225, 0.010810999626249429, 0.01834432775781408, 0.004498633919320579, 0.005042178258282313, 0.005762698777690922, 0.0060878918010886865, 0.009058849087576685, 0.016428212694438317, 0.02930654566687311, 0.0627820559024163, 3.552594461637549, 0.016884284752732376, 0.018061007145729138, 0.00439225781527708, 0.0047180811601346025, 0.004999314466465586, 0.005491114149808104, 0.007495419651343226, 0.011543697218555783, 0.015804165304977625, 0.02118128231053822, 0.036849409013758716, 4.664007964830921, 0.03394537200664266]\n",
      "\n",
      "mu: [0.8201310588072991, 0.021073511560950386, 0.010643586827945663, 0.01000825498356414, 0.010970843260321779, 0.005610246213403385, 0.003516567711493282, 0.0030272183149364124, 0.002912982005721054, 0.002679942482252166, 0.0024198912479879786]\n",
      "\n",
      "\n",
      "Finished.\n",
      "\n",
      "End time is:  2020-03-18 22:30:33.200459\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import argparse\n",
    "import json\n",
    "import sys\n",
    "import os\n",
    "import math\n",
    "from scipy.optimize import fsolve\n",
    "from scipy import log\n",
    "import random\n",
    "import datetime\n",
    "\n",
    "\n",
    "# External libraries\n",
    "import torch\n",
    "from torch import optim\n",
    "\n",
    "# Internal libraries\n",
    "\n",
    "import models\n",
    "import posteriors\n",
    "import priors\n",
    "import hawkes_model, excitation_kernels\n",
    "import learners\n",
    "import utils\n",
    "\n",
    "from make_data_for_samples import make_data              #多个样本数据\n",
    "from make_data_for_estimate import make_estimate_data    #单个样本数据\n",
    "\n",
    "def make_object(module, name, args):\n",
    "    return getattr(module, name)(**args)\n",
    "\n",
    "#def learn_vi(events, end_time, vi_seed, adjacency_true, inference_param_dict, return_learner=False):\n",
    "def learn_vi(events, vi_seed, inference_param_dict, return_learner=False):\n",
    "    # Extract some parameters for easier access\n",
    "    #n_nodes = len(events)\n",
    "    n_events = len(events)\n",
    "    n_nodes = len(events[0])\n",
    "    M = inference_param_dict['excitation']['args'].get('M', 1)\n",
    "    n_params = n_nodes * (n_nodes * M + 1)\n",
    "    n_edges = M * n_nodes ** 2\n",
    "    # Set seed\n",
    "    np.random.seed(vi_seed)\n",
    "    # Set starting pointM * n_nodes ** 2\n",
    "    x0 = torch.tensor(\n",
    "        np.hstack((\n",
    "            np.hstack((  # alpha, the mean of the parameters\n",
    "                np.random.normal(loc=0.1, scale=0.1, size=n_nodes),\n",
    "                np.random.normal(loc=0.1, scale=0.1, size=n_edges),)),\n",
    "            np.hstack((  # beta=log(sigma), log of the variance of the parameters\n",
    "                np.log(np.clip(np.random.normal(loc=0.2, scale=0.1, size=n_nodes), 1e-1, 2.0)),\n",
    "                np.log(np.clip(np.random.normal(loc=0.2, scale=0.1, size=n_edges), 1e-1, 2.0)),))\n",
    "        )),\n",
    "        dtype=torch.float64, requires_grad=True\n",
    "    )\n",
    "    # Init Hawkes process model object\n",
    "    excitation_obj = make_object(excitation_kernels, **inference_param_dict['excitation'])\n",
    "    hawkes_model_obj = hawkes_model.HawkesModel(excitation=excitation_obj, verbose=False)\n",
    "    # Init the posterior object\n",
    "    posterior_obj = make_object(posteriors, **inference_param_dict['posterior'])\n",
    "    # Init the prior object\n",
    "    prior_type = inference_param_dict['prior']['name']\n",
    "    prior_args = inference_param_dict['prior']['args']\n",
    "    prior_args['C'] = torch.tensor(prior_args['C'], dtype=torch.float64)  # cast to tensor\n",
    "    prior_obj = make_object(priors, prior_type, prior_args)\n",
    "    # Init the variational inference model object\n",
    "    model = models.ModelHawkesVariational(\n",
    "        model=hawkes_model_obj, posterior=posterior_obj, prior=prior_obj,\n",
    "        **inference_param_dict['model']['args'])\n",
    "   \n",
    "    # Init the optimizer\n",
    "    opt_type = inference_param_dict['optimizer']['name']\n",
    "    opt_args = inference_param_dict['optimizer']['args']\n",
    "    opt = getattr(optim, opt_type)([x0], **opt_args)\n",
    "    # Init learner\n",
    "    learner = learners.VariationalInferenceLearner(\n",
    "        model=model, optimizer=opt, **inference_param_dict['learner']['args'])\n",
    "    # Fit the model\n",
    "    events_t = [torch.tensor(events_i) for events_i in events]  # cast to tensor\n",
    "    #learner.fit(events_t, end_time, x0, callback=callback)\n",
    "    learner.fit(events_t, x0=x0, callback=None)\n",
    "    print()\n",
    "    if return_learner:\n",
    "        return learner\n",
    "    # Extract the mode of the posterior\n",
    "    z_est_mode = learner.model.posterior.mode(learner.coeffs[:n_params], learner.coeffs[n_params:])\n",
    "    adj_est_ora = z_est_mode[n_nodes:].detach()\n",
    "    mu_est_ora = z_est_mode[:n_nodes].detach()\n",
    "    adj_est_ora = adj_est_ora.view(n_nodes, n_nodes, M)\n",
    "    adj_est = z_est_mode[n_nodes:].detach().numpy()\n",
    "    adj_est = np.reshape(adj_est, (n_nodes, n_nodes, M)).sum(-1).ravel()\n",
    "    mu_est = z_est_mode[:n_nodes].detach().numpy()\n",
    "    #mu_est = np.reshape(mu_est,n_nodes).ravel()\n",
    "    coeffs_est = learner.coeffs.detach().numpy()\n",
    "    #log_like_sum,min_intens,log_like,end_time = hawkes_model_obj.log_likelihood(mu_est_ora,adj_est_ora)\n",
    "    log_like_sum,intens_sum,integral_instesity,end_time = hawkes_model_obj.log_likelihood(mu_est_ora,adj_est_ora)\n",
    "    \n",
    "    return coeffs_est, adj_est,mu_est,intens_sum,integral_instesity,end_time\n",
    "\n",
    "\n",
    "def run(exp_dir, param_filename, output_filename, stdout=None, stderr=None):\n",
    "    # Reset random seed\n",
    "    np.random.seed(None)\n",
    "\n",
    "    if stdout is not None:\n",
    "        sys.stdout = open(stdout, 'w')\n",
    "    if stderr is not None:\n",
    "        sys.stderr = open(stderr, 'w')\n",
    "\n",
    "    print('\\nExperiment parameters')\n",
    "    print('=====================')\n",
    "    print(f'        exp_dir = {exp_dir:s}')\n",
    "    print(f' param_filename = {param_filename:s}')\n",
    "    print(f'output_filename = {output_filename:s}')\n",
    "    print(flush=True)\n",
    "    print('\\nStart time is: ', datetime.datetime.today())\n",
    "\n",
    "    result_dict = {}\n",
    "    \n",
    "    data_fileName = \"./data/DSL-StrongPasswordData.xls\"\n",
    "    global events\n",
    "    events = make_data('s032',10400,10450,data_fileName)\n",
    "    n_jumps_per_dim = list(map(len, events[0]))\n",
    "    print('\\nNumber of jumps:', len(events)*sum(n_jumps_per_dim))\n",
    "    print('\\nper node:', n_jumps_per_dim)\n",
    "    \n",
    "    C_list = [1.0]*132\n",
    "    \n",
    "    param_dict={'inference':{'vi_exp':{'excitation': {'name': 'ExponentialKernel','args': {'decay': 0.3, 'cut_off': 1000.0}}, \n",
    "                          'posterior': {'name': 'LogNormalPosterior', 'args': {}},\n",
    "                          'prior': {'name': 'GaussianLaplacianPrior', 'args': {'dim': 11, 'n_params': 132, 'C': C_list}}, \n",
    "                          'model': {'args': {'n_samples': 1, 'n_weights': 1, 'weight_temp': 1.0}}, \n",
    "                          'optimizer': {'name': 'Adam', 'args': {'lr': 0.01}}, \n",
    "                          'learner': {'args': {'tol': 1e-05, 'lr_gamma': 0.9999, 'max_iter': 40000, 'hyperparam_momentum': 0.5, 'hyperparam_interval': 100, 'hyperparam_offset': 0}}}}\n",
    "               }\n",
    "    \n",
    "\n",
    "    print('\\nINFERENCE')\n",
    "    print('=========')\n",
    "\n",
    "    for key, inference_param_dict in param_dict['inference'].items():\n",
    "        if key.startswith('vi'):\n",
    "            print(f'\\nRun VI ({key:s})')\n",
    "            print('------')\n",
    "            # Set random seed (for reproducibility)\n",
    "            np.random.seed()  # Reset random number generator to avoid dependency on simulation seed\n",
    "            #vi_seed = np.random.randint(2**32 - 1)\n",
    "            vi_seed = np.random.randint(2**16 - 1)\n",
    "            print(f'vi random seed: {vi_seed}')\n",
    "            # Run inference\n",
    "            global intens_sum\n",
    "            global integral_instesity\n",
    "            #coeffs_var, adj_var, mu_var, nu, varsigma = learn_vi(events, vi_seed, inference_param_dict)\n",
    "            coeffs_var, adj_var, mu_var,intens_sum,integral_instesity,end_time  = learn_vi(events, vi_seed, inference_param_dict)\n",
    "            #模型参数\n",
    "            adj_var = adj_var.ravel()\n",
    "            mu_var = mu_var.ravel()            \n",
    "          \n",
    "            global  end_time_result\n",
    "            end_time_result = [0.0]*len(end_time)\n",
    "            \n",
    "            for i in range(len(end_time)):\n",
    "                end_time_result[i]=end_time[i].tolist()\n",
    "                \n",
    "            expresion_temp = ''\n",
    "            events_n = len(events)\n",
    "            dim = len(events[0])\n",
    "            \n",
    "            for i in range(events_n):\n",
    "                temp = ''                  \n",
    "                for j in range(dim):\n",
    "                    temp += 'log('+str(intens_sum[i][j].detach().numpy())+ '-'+ 'epsilon_noise['+str(i)+'])'+ '+'   \n",
    "                #print(intens)\n",
    "                expresion_temp += temp[:-1] + '-' + str(integral_instesity[i].detach().numpy()) + '+' + str(dim) +'*'+ str(end_time_result[i])+'*'+ 'epsilon_noise['+str(i)+'],'\n",
    "\n",
    "            expresion = expresion_temp[:-1]\n",
    "            expresion = '['+expresion+']'\n",
    "         \n",
    "            result_dict.update({\n",
    "                key: {\n",
    "                    'vi_seed': vi_seed,             # VI random seed\n",
    "                    'coeffs': coeffs_var.tolist(),  # VI parameters\n",
    "                    'adjacency': adj_var.tolist(),  # VI Estimator\n",
    "                    'mu':  mu_var.tolist(),\n",
    "                    'expresion': expresion,\n",
    "                }\n",
    "            })\n",
    " \n",
    "\n",
    "    print('\\n\\nSave results...')\n",
    "    \n",
    "    print('\\ncoeffs:',  coeffs_var.tolist())\n",
    "    print( '\\nadjacency:', adj_var.tolist())\n",
    "    print('\\nmu:', mu_var.tolist())\n",
    "    #print('\\nnu:',nu)\n",
    "    #print('\\nvarsigma:',varsigma)\n",
    "\n",
    "    with open(os.path.join(exp_dir, output_filename), 'w') as output_file:\n",
    "        json.dump(result_dict, output_file)\n",
    "\n",
    "    # Log that the run is finished\n",
    "    print('\\n\\nFinished.')\n",
    "    print('\\nEnd time is: ', datetime.datetime.today())\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('-d', '--dir', dest='dir', type=str,\n",
    "                        #required=True, help=\"Working directory\")\n",
    "                        required=False, default=\".\")\n",
    "    parser.add_argument('-p', '--params', dest='param_filename', type=str,\n",
    "                        required=False, default='params.json',\n",
    "                        help=\"Input parameter file (JSON)\")\n",
    "    parser.add_argument('-o', '--outfile', dest='output_filename', type=str,\n",
    "                        required=False, default='output.json',\n",
    "                        help=\"Output file (JSON)\")\n",
    "    #args = parser.parse_args()\n",
    "    args = parser.parse_known_args()[0]\n",
    "\n",
    "    #run(exp_dir=args.dir, param_filename=args.param_filename,output_filename=args.output_filename)\n",
    "    run ('.','params.json','penalty10_decay0.3+s032_10400-10450-2.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
