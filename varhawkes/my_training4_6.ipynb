{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Experiment parameters\n",
      "=====================\n",
      "        exp_dir = .\n",
      " param_filename = params.json\n",
      "output_filename = penalty10+decay0.1+s036_12200-12250.json\n",
      "\n",
      "\n",
      "Start time is:  2020-03-15 07:47:17.255281\n",
      "\n",
      "Number of jumps: 1100\n",
      "\n",
      "per node: [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n",
      "\n",
      "INFERENCE\n",
      "=========\n",
      "\n",
      "Run VI (vi_exp)\n",
      "------\n",
      "vi random seed: 6794\n",
      "end_iter is: 38101\n",
      "Converged!\n",
      "\n",
      "\n",
      "\n",
      "Save results...\n",
      "\n",
      "coeffs: [-0.7998364483252393, -0.8784089731240399, -3.408370953792614, -3.5929555786664475, -4.032653427547811, -4.287973069938819, -4.708150060426647, -5.130994641203152, -5.236940565916649, -5.325504792190391, -5.487421631290582, -4.121420065135837, -4.323369072200397, -4.304818722194439, -4.261416147682602, -4.165796993143543, -4.029615207927428, -3.874485335735379, -3.7989748499104077, -3.69058469067119, -3.4403312780830158, -2.9354721612887533, -1.8606055916233728, -4.039266999984677, -4.3122292404330045, -4.2482235091145935, -4.168891989467666, -4.039063344172243, -3.892006083307918, -3.782389043391609, -3.6832803844829134, -3.442856801262748, -2.9203984532676137, -2.4739909964679407, 0.7457833154268718, -4.019971437145865, -4.247280392846519, -4.190720446102145, -4.040435160420281, -3.8684959243407784, -3.794412297003938, -3.693617490394964, -3.4307466716178694, -2.936923280403816, -2.730554974697301, -1.7684323012200927, 0.7034315014654411, -3.9241755290546885, -4.155001934825032, -4.039931445810937, -3.8608778027088206, -3.8104066786582607, -3.6677843762935254, -3.4339147332784834, -2.9204812531181985, -3.103614791173922, -2.5160151117967593, -2.1629608182698794, 0.7860939638198033, -3.8602883616676014, -4.051364170364674, -3.856263804517524, -3.7956715386490067, -3.680030975907009, -3.439855481450037, -2.9087556172834548, -3.337674472642318, -2.961558668536855, -2.7302013695432437, -2.1843068299173654, 0.8635002792585457, -3.676407006824696, -3.879825953125455, -3.796432394203578, -3.6743909872688887, -3.4301699986367202, -2.9159006225681297, -3.6374822268209104, -3.3739625568143774, -3.24242294600914, -2.952408604725897, -2.5267006214521017, 1.0331645827209655, -3.485903923848075, -3.7899422750660894, -3.7032719649485832, -3.4452761679992365, -2.930572495753473, -3.8377847334372057, -3.6733049105003714, -3.5785261907497263, -3.397436629371874, -3.1265137734566975, -2.516763841882078, 1.209526175255071, -3.432279767318243, -3.66978765920083, -3.445054442911398, -2.925272966998134, -3.9133842544339967, -3.7570557260804565, -3.679313830898834, -3.5203399797419777, -3.319122796638294, -2.8214901370360184, -1.7931865432382073, 1.245494161506511, -3.336686941486997, -3.420616548978891, -2.9239320523825594, -4.016774162051861, -3.8642462747323982, -3.7958164406235717, -3.658302959112632, -3.4695422678566694, -3.0891069096282764, -2.425659707924409, -1.8989027345428557, 1.357872976686119, -3.0164886132450635, -2.9190721492243186, -4.134280185791882, -4.0095386519176515, -3.9689880235142008, -3.862422637545702, -3.7014256480997543, -3.431028162843654, -3.0241732544642996, -2.772702291538906, -2.3595655592669824, 1.6265919772605066, -2.3239627738507487, -2.415462108334472, -2.337413366154711, -0.3936916595266675, -0.35006831587051157, -0.18342392745855637, -0.14087516592030425, -0.05211493341355602, -0.018117125715410333, 9.899169646988703e-05, -0.00656836159667503, 0.019108043941275018, 0.011162896436800991, -0.006683010621994948, -0.008133355138010128, 0.004652493482906467, 0.023355901710294828, -0.0023099163402715162, 0.006142389790598839, 0.014377997578991315, 0.000713578873694877, -0.017980988791283146, 0.01084191450684703, -0.3663772517952893, 0.004062588755226434, -0.00011246693218520917, 0.004626478913614425, 0.02081127940702391, 0.002293540576392697, 0.0007597520806408944, 0.021181478845714915, 0.0009832383344532659, 0.013231214561272615, -0.009205293511514494, -0.17178839517830272, -2.294198237118011, 0.0002937493675199213, 0.03404239400686729, 0.0030025231382403497, -0.007395480693238313, -0.006848653721500491, -0.004735481532457107, 0.0012681195261347734, 0.005134556337061015, -0.006279255129832614, -0.10140945813361348, -0.39420407306396016, -2.2181249986824385, -0.006842058442469383, 2.6703345940145926e-05, -0.005920101677026777, 0.006531210220733835, -0.006394872983660171, 0.0009354104780239933, 0.0006281562311212067, 0.008225071439763351, -0.06197069309331603, -0.15330734296965873, -0.22597145200421997, -2.2365029249029575, -0.0125440554411484, 0.0018396649145636372, 0.0006534291799149476, 0.0007140184298350602, -0.007616798947324523, -0.0041486983833934985, 0.006291666025504187, -0.03361501732697915, -0.07234149138980378, -0.0825841721678254, -0.2134096459108501, -2.237468441994086, -0.013411130611385371, 0.012587981685062671, 0.00477511910659414, 0.012626751455735954, 0.007456098781631233, 0.008904421768624647, -0.018045586723919798, -0.022699833912645306, -0.03883523485194883, -0.06987799355899624, -0.09527277541075764, -2.2744796494490793, 0.009556667460984616, -0.006606633755692582, 0.001337520030903091, 0.010410095547460422, 0.00867720707137256, 0.020560447440049503, -0.018110390149334205, -0.009838228779832642, -0.03234356972449988, -0.022816359523748227, -0.08222915689289222, -2.27927350925376, 0.003080090350180748, 0.021233042503010915, 0.00039097001014133605, 0.013147688823470678, 0.003875496862265083, -0.014876476626055833, -0.008584721900764659, -0.003185171177971563, -0.008213530387590035, -0.05005476743189911, -0.22585542070965378, -2.2343317926314, 0.008187425412420063, 0.02067740898253329, 0.011034275706558808, 0.01373465626187543, -0.0032027239367895515, -0.005435564374603897, -0.026036157849616135, 0.002982470431842927, -0.03606608176482318, -0.09153361857322827, -0.18133057139666184, -2.226578318218212, -0.012045784014040575, 0.011128069067598131, -0.0015483781250066097, 0.012801912954952662, -0.003782398715025582, -0.01162637208417517, -0.005522421925537684, 0.00026833711745541405, -0.004779831546428679, -0.015380080529786606, -0.055342949231630446, -2.2492636964186254, 0.012919047034016851]\n",
      "\n",
      "adjacency: [0.005834323585560974, 0.0049414721822887125, 0.005048401601351311, 0.0051396794738745736, 0.005441954603312744, 0.006571546866677581, 0.007545183372853893, 0.008001323684374057, 0.009168213174219007, 0.012216005629701583, 0.019112880623587278, 0.09621317386869226, 0.00642585697139227, 0.00493203137657474, 0.00520820814801621, 0.0054540713572878595, 0.006450091500915605, 0.0074949430751438655, 0.00802124110830401, 0.009230437831117053, 0.011451065810424302, 0.020198310719341115, 0.041451964106234244, 2.0867632130816482, 0.006600835094448182, 0.004903841216086644, 0.005534558070074159, 0.0065666396378242274, 0.0077901746610000485, 0.008354240353487452, 0.009130297971112904, 0.011783339021457775, 0.019753130395547682, 0.028811489102566517, 0.10828375606149106, 1.996890548762293, 0.0073681795304692405, 0.0057701607285835154, 0.0065508461017720334, 0.007642535117003644, 0.008248710664681278, 0.009375485251296192, 0.011853028964653985, 0.019505331420911057, 0.018554435428818433, 0.0386987018343449, 0.060849521553182545, 2.1698998300490606, 0.007942617945060525, 0.00637704613401281, 0.007769328680906925, 0.008253643038833436, 0.009420069407599338, 0.011895531981970228, 0.019812971043140667, 0.013944716730933341, 0.02177799479453168, 0.027932836476922643, 0.058607752361010935, 2.344587166985093, 0.009562163521319375, 0.007407061274828725, 0.008180284234609817, 0.009095585790546633, 0.011734829983549128, 0.01956781823195873, 0.010031405324275858, 0.013173104925719005, 0.015487961618728514, 0.021884448673944193, 0.034971958294625856, 2.780376569854865, 0.011051367667267121, 0.00842277510968852, 0.009041315582556194, 0.01148958149351746, 0.019291737710069777, 0.007598816244058562, 0.00967962368544533, 0.01047208586172819, 0.013104529960241055, 0.01687526111617429, 0.034557973887016154, 3.3169606742786466, 0.01181413053531276, 0.00897629263562305, 0.011727289833768311, 0.019217823593093014, 0.007290629650566462, 0.008846432269266527, 0.009444800107998063, 0.010954665011468762, 0.01353021529853879, 0.024083496893467667, 0.08806106833424095, 3.435050190501821, 0.012865620600451134, 0.011529591346484867, 0.019327121402310708, 0.006443881296923013, 0.007767077604654466, 0.008354088752194276, 0.009976098698517712, 0.011384243435657318, 0.017961677269137704, 0.03845095012819833, 0.07466641304965367, 3.8429150898512408, 0.018450110293638272, 0.019417553491851973, 0.005909534475924072, 0.006503120949523958, 0.007002754081080456, 0.007911497837542346, 0.009182630444516126, 0.011895858304142047, 0.018049105726065346, 0.02369691494301606, 0.03858909891273501, 5.03023453108615, 0.035079528050551985]\n",
      "\n",
      "mu: [0.4458308799883867, 0.41158648361062217, 0.020996387681920924, 0.01674805682684812, 0.0088656724469568, 0.006458003297075747, 0.003664115829349468, 0.002253188414439897, 0.0019554428901809445, 0.0018135772931988372, 0.0014643009089620775]\n",
      "\n",
      "\n",
      "Finished.\n",
      "\n",
      "End time is:  2020-03-15 13:03:35.412452\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import argparse\n",
    "import json\n",
    "import sys\n",
    "import os\n",
    "import math\n",
    "from scipy.optimize import fsolve\n",
    "from scipy import log\n",
    "import random\n",
    "import datetime\n",
    "\n",
    "\n",
    "# External libraries\n",
    "import torch\n",
    "from torch import optim\n",
    "\n",
    "# Internal libraries\n",
    "\n",
    "import models\n",
    "import posteriors\n",
    "import priors\n",
    "import hawkes_model, excitation_kernels\n",
    "import learners\n",
    "import utils\n",
    "\n",
    "from make_data_for_samples import make_data              #多个样本数据\n",
    "from make_data_for_estimate import make_estimate_data    #单个样本数据\n",
    "\n",
    "def make_object(module, name, args):\n",
    "    return getattr(module, name)(**args)\n",
    "\n",
    "#def learn_vi(events, end_time, vi_seed, adjacency_true, inference_param_dict, return_learner=False):\n",
    "def learn_vi(events, vi_seed, inference_param_dict, return_learner=False):\n",
    "    # Extract some parameters for easier access\n",
    "    #n_nodes = len(events)\n",
    "    n_events = len(events)\n",
    "    n_nodes = len(events[0])\n",
    "    M = inference_param_dict['excitation']['args'].get('M', 1)\n",
    "    n_params = n_nodes * (n_nodes * M + 1)\n",
    "    n_edges = M * n_nodes ** 2\n",
    "    # Set seed\n",
    "    np.random.seed(vi_seed)\n",
    "    # Set starting pointM * n_nodes ** 2\n",
    "    x0 = torch.tensor(\n",
    "        np.hstack((\n",
    "            np.hstack((  # alpha, the mean of the parameters\n",
    "                np.random.normal(loc=0.1, scale=0.1, size=n_nodes),\n",
    "                np.random.normal(loc=0.1, scale=0.1, size=n_edges),)),\n",
    "            np.hstack((  # beta=log(sigma), log of the variance of the parameters\n",
    "                np.log(np.clip(np.random.normal(loc=0.2, scale=0.1, size=n_nodes), 1e-1, 2.0)),\n",
    "                np.log(np.clip(np.random.normal(loc=0.2, scale=0.1, size=n_edges), 1e-1, 2.0)),))\n",
    "        )),\n",
    "        dtype=torch.float64, requires_grad=True\n",
    "    )\n",
    "    # Init Hawkes process model object\n",
    "    excitation_obj = make_object(excitation_kernels, **inference_param_dict['excitation'])\n",
    "    hawkes_model_obj = hawkes_model.HawkesModel(excitation=excitation_obj, verbose=False)\n",
    "    # Init the posterior object\n",
    "    posterior_obj = make_object(posteriors, **inference_param_dict['posterior'])\n",
    "    # Init the prior object\n",
    "    prior_type = inference_param_dict['prior']['name']\n",
    "    prior_args = inference_param_dict['prior']['args']\n",
    "    prior_args['C'] = torch.tensor(prior_args['C'], dtype=torch.float64)  # cast to tensor\n",
    "    prior_obj = make_object(priors, prior_type, prior_args)\n",
    "    # Init the variational inference model object\n",
    "    model = models.ModelHawkesVariational(\n",
    "        model=hawkes_model_obj, posterior=posterior_obj, prior=prior_obj,\n",
    "        **inference_param_dict['model']['args'])\n",
    "   \n",
    "    # Init the optimizer\n",
    "    opt_type = inference_param_dict['optimizer']['name']\n",
    "    opt_args = inference_param_dict['optimizer']['args']\n",
    "    opt = getattr(optim, opt_type)([x0], **opt_args)\n",
    "    # Init learner\n",
    "    learner = learners.VariationalInferenceLearner(\n",
    "        model=model, optimizer=opt, **inference_param_dict['learner']['args'])\n",
    "    # Fit the model\n",
    "    events_t = [torch.tensor(events_i) for events_i in events]  # cast to tensor\n",
    "    #learner.fit(events_t, end_time, x0, callback=callback)\n",
    "    learner.fit(events_t, x0=x0, callback=None)\n",
    "    print()\n",
    "    if return_learner:\n",
    "        return learner\n",
    "    # Extract the mode of the posterior\n",
    "    z_est_mode = learner.model.posterior.mode(learner.coeffs[:n_params], learner.coeffs[n_params:])\n",
    "    adj_est_ora = z_est_mode[n_nodes:].detach()\n",
    "    mu_est_ora = z_est_mode[:n_nodes].detach()\n",
    "    adj_est_ora = adj_est_ora.view(n_nodes, n_nodes, M)\n",
    "    adj_est = z_est_mode[n_nodes:].detach().numpy()\n",
    "    adj_est = np.reshape(adj_est, (n_nodes, n_nodes, M)).sum(-1).ravel()\n",
    "    mu_est = z_est_mode[:n_nodes].detach().numpy()\n",
    "    #mu_est = np.reshape(mu_est,n_nodes).ravel()\n",
    "    coeffs_est = learner.coeffs.detach().numpy()\n",
    "    #log_like_sum,min_intens,log_like,end_time = hawkes_model_obj.log_likelihood(mu_est_ora,adj_est_ora)\n",
    "    log_like_sum,intens_sum,integral_instesity,end_time = hawkes_model_obj.log_likelihood(mu_est_ora,adj_est_ora)\n",
    "    \n",
    "    return coeffs_est, adj_est,mu_est,intens_sum,integral_instesity,end_time\n",
    "\n",
    "\n",
    "def run(exp_dir, param_filename, output_filename, stdout=None, stderr=None):\n",
    "    # Reset random seed\n",
    "    np.random.seed(None)\n",
    "\n",
    "    if stdout is not None:\n",
    "        sys.stdout = open(stdout, 'w')\n",
    "    if stderr is not None:\n",
    "        sys.stderr = open(stderr, 'w')\n",
    "\n",
    "    print('\\nExperiment parameters')\n",
    "    print('=====================')\n",
    "    print(f'        exp_dir = {exp_dir:s}')\n",
    "    print(f' param_filename = {param_filename:s}')\n",
    "    print(f'output_filename = {output_filename:s}')\n",
    "    print(flush=True)\n",
    "    print('\\nStart time is: ', datetime.datetime.today())\n",
    "\n",
    "    result_dict = {}\n",
    "    \n",
    "    data_fileName = \"./data/DSL-StrongPasswordData.xls\"\n",
    "    global events\n",
    "    events = make_data('s036',12200,12250,data_fileName)\n",
    "    n_jumps_per_dim = list(map(len, events[0]))\n",
    "    print('\\nNumber of jumps:', len(events)*sum(n_jumps_per_dim))\n",
    "    print('\\nper node:', n_jumps_per_dim)\n",
    "    \n",
    "    C_list = [1.0]*132\n",
    "    \n",
    "    param_dict={'inference':{'vi_exp':{'excitation': {'name': 'ExponentialKernel','args': {'decay': 0.1, 'cut_off': 1000.0}}, \n",
    "                          'posterior': {'name': 'LogNormalPosterior', 'args': {}},\n",
    "                          'prior': {'name': 'GaussianLaplacianPrior', 'args': {'dim': 11, 'n_params': 132, 'C': C_list}}, \n",
    "                          'model': {'args': {'n_samples': 1, 'n_weights': 1, 'weight_temp': 1.0}}, \n",
    "                          'optimizer': {'name': 'Adam', 'args': {'lr': 0.01}}, \n",
    "                          'learner': {'args': {'tol': 1e-04, 'lr_gamma': 0.9999, 'max_iter': 40000, 'hyperparam_momentum': 0.5, 'hyperparam_interval': 100, 'hyperparam_offset': 0}}}}\n",
    "               }\n",
    "    \n",
    "\n",
    "    print('\\nINFERENCE')\n",
    "    print('=========')\n",
    "\n",
    "    for key, inference_param_dict in param_dict['inference'].items():\n",
    "        if key.startswith('vi'):\n",
    "            print(f'\\nRun VI ({key:s})')\n",
    "            print('------')\n",
    "            # Set random seed (for reproducibility)\n",
    "            np.random.seed()  # Reset random number generator to avoid dependency on simulation seed\n",
    "            #vi_seed = np.random.randint(2**32 - 1)\n",
    "            vi_seed = np.random.randint(2**16 - 1)\n",
    "            print(f'vi random seed: {vi_seed}')\n",
    "            # Run inference\n",
    "            global intens_sum\n",
    "            global integral_instesity\n",
    "            #coeffs_var, adj_var, mu_var, nu, varsigma = learn_vi(events, vi_seed, inference_param_dict)\n",
    "            coeffs_var, adj_var, mu_var,intens_sum,integral_instesity,end_time  = learn_vi(events, vi_seed, inference_param_dict)\n",
    "            #模型参数\n",
    "            adj_var = adj_var.ravel()\n",
    "            mu_var = mu_var.ravel()            \n",
    "          \n",
    "            global  end_time_result\n",
    "            end_time_result = [0.0]*len(end_time)\n",
    "            \n",
    "            for i in range(len(end_time)):\n",
    "                end_time_result[i]=end_time[i].tolist()\n",
    "                \n",
    "            expresion_temp = ''\n",
    "            events_n = len(events)\n",
    "            dim = len(events[0])\n",
    "            \n",
    "            for i in range(events_n):\n",
    "                temp = ''                  \n",
    "                for j in range(dim):\n",
    "                    temp += 'log('+str(intens_sum[i][j].detach().numpy())+ '-'+ 'epsilon_noise['+str(i)+'])'+ '+'   \n",
    "                #print(intens)\n",
    "                expresion_temp += temp[:-1] + '-' + str(integral_instesity[i].detach().numpy()) + '+' + str(dim) +'*'+ str(end_time_result[i])+'*'+ 'epsilon_noise['+str(i)+'],'\n",
    "\n",
    "            expresion = expresion_temp[:-1]\n",
    "            expresion = '['+expresion+']'\n",
    "         \n",
    "            result_dict.update({\n",
    "                key: {\n",
    "                    'vi_seed': vi_seed,             # VI random seed\n",
    "                    'coeffs': coeffs_var.tolist(),  # VI parameters\n",
    "                    'adjacency': adj_var.tolist(),  # VI Estimator\n",
    "                    'mu':  mu_var.tolist(),\n",
    "                    'expresion': expresion,\n",
    "                }\n",
    "            })\n",
    " \n",
    "\n",
    "    print('\\n\\nSave results...')\n",
    "    \n",
    "    print('\\ncoeffs:',  coeffs_var.tolist())\n",
    "    print( '\\nadjacency:', adj_var.tolist())\n",
    "    print('\\nmu:', mu_var.tolist())\n",
    "    #print('\\nnu:',nu)\n",
    "    #print('\\nvarsigma:',varsigma)\n",
    "\n",
    "    with open(os.path.join(exp_dir, output_filename), 'w') as output_file:\n",
    "        json.dump(result_dict, output_file)\n",
    "\n",
    "    # Log that the run is finished\n",
    "    print('\\n\\nFinished.')\n",
    "    print('\\nEnd time is: ', datetime.datetime.today())\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('-d', '--dir', dest='dir', type=str,\n",
    "                        #required=True, help=\"Working directory\")\n",
    "                        required=False, default=\".\")\n",
    "    parser.add_argument('-p', '--params', dest='param_filename', type=str,\n",
    "                        required=False, default='params.json',\n",
    "                        help=\"Input parameter file (JSON)\")\n",
    "    parser.add_argument('-o', '--outfile', dest='output_filename', type=str,\n",
    "                        required=False, default='output.json',\n",
    "                        help=\"Output file (JSON)\")\n",
    "    #args = parser.parse_args()\n",
    "    args = parser.parse_known_args()[0]\n",
    "\n",
    "    #run(exp_dir=args.dir, param_filename=args.param_filename,output_filename=args.output_filename)\n",
    "    run ('.','params.json','penalty10+decay0.1+s036_12200-12250.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
