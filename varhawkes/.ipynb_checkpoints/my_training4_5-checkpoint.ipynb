{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\jw\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow_core\\python\\compat\\v2_compat.py:65: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n",
      "\n",
      "Experiment parameters\n",
      "=====================\n",
      "        exp_dir = .\n",
      " param_filename = params.json\n",
      "output_filename = penalty10_decay0.1+s036_12150-1200.json\n",
      "\n",
      "\n",
      "Start time is:  2020-03-14 20:05:20.757450\n",
      "\n",
      "Number of jumps: 1100\n",
      "\n",
      "per node: [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n",
      "\n",
      "INFERENCE\n",
      "=========\n",
      "\n",
      "Run VI (vi_exp)\n",
      "------\n",
      "vi random seed: 31746\n",
      "end_iter is: 38987\n",
      "Converged!\n",
      "\n",
      "\n",
      "\n",
      "Save results...\n",
      "\n",
      "coeffs: [-0.9046972157725782, -1.0189496816165975, -4.099159847852379, -4.03956783118823, -4.518593032934983, -4.671070752984045, -5.0099943213897085, -5.292664631419599, -5.3838157549976655, -5.530018437142235, -5.6686427908815595, -4.187347558065229, -4.397106824419957, -4.369126446450285, -4.289309257517795, -4.207350789750518, -4.09523997226105, -3.9318703607929564, -3.8380871083514276, -3.7177257965391117, -3.496641965203678, -2.922896721840979, -1.4870566620471541, -4.071443152570066, -4.3668149717014035, -4.276781126751256, -4.214620607066901, -4.086468940737687, -3.921419639937043, -3.839667388272305, -3.735817524545135, -3.4772887554692296, -2.9175431396495073, -2.7052023362112343, 0.7413087028816002, -4.06022250442926, -4.2896996516529455, -4.202001868753947, -4.071502666049638, -3.945627520007562, -3.866780727226228, -3.7219072065728875, -3.4790867354395707, -2.914308775684084, -2.9353945064812863, -1.7855793457035545, 0.6881199083236135, -3.9609061403421584, -4.207449044369475, -4.098533167221579, -3.923981946528065, -3.834766464551952, -3.717845361474229, -3.493917325789636, -2.9229321535828467, -3.3335545136360207, -2.722573200827226, -2.441055437331257, 0.7959594202461934, -3.886477881860958, -4.095818773574325, -3.8962183776195327, -3.8401576966843747, -3.713155609957678, -3.48044185929296, -2.93819107040169, -3.5210848317622117, -3.0930966492857253, -2.903040978277346, -2.199312169662945, 0.8496053899601389, -3.7197625213317416, -3.9297134814262797, -3.8591999991964316, -3.7260013286043745, -3.4986276603414668, -2.9209801629991663, -3.7669819886169935, -3.476222391989377, -3.3701416704463965, -2.982135947831354, -2.5802494080911944, 1.0004954693755783, -3.556572805444486, -3.835643251324872, -3.723372686058405, -3.480944252119365, -2.9242141940430635, -3.9558337928796, -3.740936399330639, -3.63915073012589, -3.4150419419523623, -3.155572403277527, -2.5074935100329703, 1.1604389335383227, -3.51815246108161, -3.713708557593278, -3.488187087478359, -2.928019222888065, -4.005208844455174, -3.8504470667963906, -3.7642182994353277, -3.527532360096762, -3.3255033874571933, -2.85090478346335, -1.832728468670589, 1.2040528973331792, -3.385872806227088, -3.4818540722764832, -2.9004403880432426, -4.13203602148817, -3.9264295856318014, -3.89119972446537, -3.677201616909242, -3.5132622013486126, -3.1549051715684957, -2.528930902993205, -2.0322202541478824, 1.319128033872584, -3.0755889227426696, -2.921220152621242, -4.222169897412288, -4.072399239523165, -4.0232951414758364, -3.8706354365912095, -3.7459061207366555, -3.49424788066658, -3.0985169456584885, -2.8532501571393887, -2.399680611568386, 1.5816198644304533, -2.2811345664602993, -2.4463578044624312, -2.330114891422858, -0.20280549913601664, -0.21585024684469412, -0.09432818253561492, -0.08278345293264801, -0.03410472027396279, -0.02331485333639317, 0.016339098670398233, -0.0006481425802636382, 0.0066232514364219655, -0.0030500170410753874, -0.01661188775042716, -0.013017466270437773, 0.009187747618011508, 0.004236918066473266, 0.0166632218817251, -0.012357010258805099, 0.009075775525395485, 0.00574139639365379, 0.015634133879612638, -0.0041000602350867305, -0.5507430735013907, 0.011846116237182156, 0.02203189627752367, 0.011110169574653434, 0.0034038590508538974, 0.008758857871893488, 0.012993118640183524, -0.004928740162405792, 0.003943343501721493, 0.021304873425668367, -0.01886378567039638, -0.14829239601682362, -2.3308263926081674, 0.012909394410107631, 0.0015306598787395318, 0.017811999116293956, 0.015950686355306463, 0.00073820859437863, -0.0006837908843304548, 0.004182832495812063, 0.001496179787299758, 0.01749669637686564, -0.09707195439365297, -0.37514351047309036, -2.275756751119538, 0.005403391267168513, 0.013924125160613716, -0.0056634579242387986, -0.004350471451018797, -0.0139505350819714, -0.013283043867960129, 0.005455302620035657, 0.015677675461091493, -0.020345756958107163, -0.1098737708453171, -0.16942042869506357, -2.290526057432447, -0.0003157880326490733, 0.006492280101252636, 0.011489303255235646, 0.00991698069067858, 0.02281338817986727, 0.011796373476115715, 0.010123699028828774, -0.02437642809805293, -0.05238885960761709, -0.06456486359093748, -0.21137345610645267, -2.2428748461010057, -0.007406161312156119, 0.01395171718747122, 0.023241054378894888, -0.013920342834821096, 0.009203511447398824, -0.001087342820048217, -0.000152461611875054, -0.012760679808143152, -0.0144391993161715, -0.03934229455284822, -0.12290542529524834, -2.261644981900409, 0.0009454547616669222, 0.013910507887211713, 0.010455434586285691, 0.013478174423517137, 0.003892682172889815, -0.00998160315350387, 0.006023108034563199, 0.0015170907183739795, -0.004536637858824366, -0.028294200237980124, -0.09035172847709491, -2.2787805601534887, -0.004313580344797299, 0.02349231460252415, 0.01570902586105758, -0.007199871771711726, 0.005132335222123112, -0.014575348355115425, 0.005812650318800574, 0.01584953971326852, -0.009091947809513131, -0.042835979078227115, -0.19371735605734083, -2.266002262460549, -0.005161573463294863, 0.0033881065045109613, 0.028188005649927673, 0.024919763714466244, 0.0041780258379306495, -0.01740899601746717, 0.008463357138678634, -0.012864207268385731, -0.0171720654586415, -0.07731491391850907, -0.14000362376197797, -2.24039855477191, -0.02003904777114048, -0.009628923677115403, 0.0023968743590288125, -0.016521992809243716, -0.001040489385548703, 0.0007424847782079172, -0.01240544723042851, -0.004895573550915295, -0.0074546058302418505, -0.02561779068986879, -0.05277736128415456, -2.2641715703323917, 0.00081580604856875]\n",
      "\n",
      "adjacency: [0.0056208853526922686, 0.004680132315982598, 0.00477946099851808, 0.004952540404388581, 0.005429758449522194, 0.005921722185339439, 0.007391243935465821, 0.007778401690756963, 0.008832874586056713, 0.010797893388319303, 0.01994593071478566, 0.1621175778524258, 0.006124744267487919, 0.0044633128785332415, 0.00499533812557932, 0.00539948580978913, 0.00607155219037892, 0.007099389651092023, 0.007987652767358067, 0.008706064794364206, 0.010880105621384693, 0.020640122839410618, 0.03179154419334654, 2.0789394286154748, 0.006180367858228774, 0.005027835718913511, 0.005309444813531482, 0.00607290416938134, 0.0071039449133503164, 0.007708635537376792, 0.008823753244781844, 0.011309823704068304, 0.01925621059611921, 0.02330857669444277, 0.10457922730487963, 1.9690844437013921, 0.006930858948502413, 0.005323157259046811, 0.006174853265865183, 0.007333380024888664, 0.008170288698396469, 0.009171732786499886, 0.01105483192027441, 0.019162802249756933, 0.013654586817805524, 0.029443131352407143, 0.042695946979748683, 2.1939757471134227, 0.007552727632046426, 0.006042798785790188, 0.00730305134162335, 0.007749014089619136, 0.008566985993749424, 0.011061163198536929, 0.01908896542185956, 0.01140730526370008, 0.018432841910257732, 0.022779348422950832, 0.05758134610024216, 2.312517952149082, 0.009049377017286137, 0.007026898417029116, 0.007396270919373856, 0.00910852379457995, 0.010919499569077118, 0.019864762603561292, 0.00850860638478193, 0.011666614829627057, 0.013014693797999322, 0.02011142192165904, 0.03465478224529516, 2.6902717513948478, 0.010478125256138589, 0.007720664175018003, 0.008699378267458006, 0.011017534718132063, 0.01960383745991184, 0.007182781811863474, 0.008625300610502783, 0.009636575044294316, 0.012203777986081311, 0.01656347436902462, 0.035359918311009104, 3.1580391970808224, 0.011003274072057628, 0.008550081564868568, 0.010887892403457645, 0.019966035784440967, 0.006634139057468753, 0.008052947117262592, 0.00843039681340029, 0.010464787737396347, 0.013467393366090095, 0.02307974067407556, 0.08114444680289225, 3.2979260781778965, 0.012580556898830437, 0.011235764877676848, 0.019092955857375644, 0.005610370991602515, 0.007191750695512926, 0.007773918699603294, 0.009147520685585622, 0.011244659859983347, 0.016225939618537005, 0.033855183488693735, 0.061544270471877195, 3.698042594272281, 0.017662644824597326, 0.020198507711431134, 0.005369743405704396, 0.006474426529015747, 0.006596498332408551, 0.007657103428317238, 0.008902701698219767, 0.011282476481382484, 0.01684471491973474, 0.022296958809339223, 0.03690139800569234, 4.810597570769189, 0.03752426418331409]\n",
      "\n",
      "mu: [0.4016403507350679, 0.35757363392438063, 0.008516675093882115, 0.009196137874650784, 0.004764017067641462, 0.004011925744590104, 0.0026213675193460773, 0.0019360501498292607, 0.0016334944109667627, 0.0014608702023695534, 0.0012532972289483475]\n",
      "\n",
      "\n",
      "Finished.\n",
      "\n",
      "End time is:  2020-03-15 01:28:54.934701\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import argparse\n",
    "import json\n",
    "import sys\n",
    "import os\n",
    "import math\n",
    "from scipy.optimize import fsolve\n",
    "from scipy import log\n",
    "import random\n",
    "import datetime\n",
    "\n",
    "\n",
    "# External libraries\n",
    "import torch\n",
    "from torch import optim\n",
    "\n",
    "# Internal libraries\n",
    "\n",
    "import models\n",
    "import posteriors\n",
    "import priors\n",
    "import hawkes_model, excitation_kernels\n",
    "import learners\n",
    "import utils\n",
    "\n",
    "from make_data_for_samples import make_data              #多个样本数据\n",
    "from make_data_for_estimate import make_estimate_data    #单个样本数据\n",
    "\n",
    "def make_object(module, name, args):\n",
    "    return getattr(module, name)(**args)\n",
    "\n",
    "#def learn_vi(events, end_time, vi_seed, adjacency_true, inference_param_dict, return_learner=False):\n",
    "def learn_vi(events, vi_seed, inference_param_dict, return_learner=False):\n",
    "    # Extract some parameters for easier access\n",
    "    #n_nodes = len(events)\n",
    "    n_events = len(events)\n",
    "    n_nodes = len(events[0])\n",
    "    M = inference_param_dict['excitation']['args'].get('M', 1)\n",
    "    n_params = n_nodes * (n_nodes * M + 1)\n",
    "    n_edges = M * n_nodes ** 2\n",
    "    # Set seed\n",
    "    np.random.seed(vi_seed)\n",
    "    # Set starting pointM * n_nodes ** 2\n",
    "    x0 = torch.tensor(\n",
    "        np.hstack((\n",
    "            np.hstack((  # alpha, the mean of the parameters\n",
    "                np.random.normal(loc=0.1, scale=0.1, size=n_nodes),\n",
    "                np.random.normal(loc=0.1, scale=0.1, size=n_edges),)),\n",
    "            np.hstack((  # beta=log(sigma), log of the variance of the parameters\n",
    "                np.log(np.clip(np.random.normal(loc=0.2, scale=0.1, size=n_nodes), 1e-1, 2.0)),\n",
    "                np.log(np.clip(np.random.normal(loc=0.2, scale=0.1, size=n_edges), 1e-1, 2.0)),))\n",
    "        )),\n",
    "        dtype=torch.float64, requires_grad=True\n",
    "    )\n",
    "    # Init Hawkes process model object\n",
    "    excitation_obj = make_object(excitation_kernels, **inference_param_dict['excitation'])\n",
    "    hawkes_model_obj = hawkes_model.HawkesModel(excitation=excitation_obj, verbose=False)\n",
    "    # Init the posterior object\n",
    "    posterior_obj = make_object(posteriors, **inference_param_dict['posterior'])\n",
    "    # Init the prior object\n",
    "    prior_type = inference_param_dict['prior']['name']\n",
    "    prior_args = inference_param_dict['prior']['args']\n",
    "    prior_args['C'] = torch.tensor(prior_args['C'], dtype=torch.float64)  # cast to tensor\n",
    "    prior_obj = make_object(priors, prior_type, prior_args)\n",
    "    # Init the variational inference model object\n",
    "    model = models.ModelHawkesVariational(\n",
    "        model=hawkes_model_obj, posterior=posterior_obj, prior=prior_obj,\n",
    "        **inference_param_dict['model']['args'])\n",
    "   \n",
    "    # Init the optimizer\n",
    "    opt_type = inference_param_dict['optimizer']['name']\n",
    "    opt_args = inference_param_dict['optimizer']['args']\n",
    "    opt = getattr(optim, opt_type)([x0], **opt_args)\n",
    "    # Init learner\n",
    "    learner = learners.VariationalInferenceLearner(\n",
    "        model=model, optimizer=opt, **inference_param_dict['learner']['args'])\n",
    "    # Fit the model\n",
    "    events_t = [torch.tensor(events_i) for events_i in events]  # cast to tensor\n",
    "    #learner.fit(events_t, end_time, x0, callback=callback)\n",
    "    learner.fit(events_t, x0=x0, callback=None)\n",
    "    print()\n",
    "    if return_learner:\n",
    "        return learner\n",
    "    # Extract the mode of the posterior\n",
    "    z_est_mode = learner.model.posterior.mode(learner.coeffs[:n_params], learner.coeffs[n_params:])\n",
    "    adj_est_ora = z_est_mode[n_nodes:].detach()\n",
    "    mu_est_ora = z_est_mode[:n_nodes].detach()\n",
    "    adj_est_ora = adj_est_ora.view(n_nodes, n_nodes, M)\n",
    "    adj_est = z_est_mode[n_nodes:].detach().numpy()\n",
    "    adj_est = np.reshape(adj_est, (n_nodes, n_nodes, M)).sum(-1).ravel()\n",
    "    mu_est = z_est_mode[:n_nodes].detach().numpy()\n",
    "    #mu_est = np.reshape(mu_est,n_nodes).ravel()\n",
    "    coeffs_est = learner.coeffs.detach().numpy()\n",
    "    #log_like_sum,min_intens,log_like,end_time = hawkes_model_obj.log_likelihood(mu_est_ora,adj_est_ora)\n",
    "    log_like_sum,intens_sum,integral_instesity,end_time = hawkes_model_obj.log_likelihood(mu_est_ora,adj_est_ora)\n",
    "    \n",
    "    return coeffs_est, adj_est,mu_est,intens_sum,integral_instesity,end_time\n",
    "\n",
    "\n",
    "def run(exp_dir, param_filename, output_filename, stdout=None, stderr=None):\n",
    "    # Reset random seed\n",
    "    np.random.seed(None)\n",
    "\n",
    "    if stdout is not None:\n",
    "        sys.stdout = open(stdout, 'w')\n",
    "    if stderr is not None:\n",
    "        sys.stderr = open(stderr, 'w')\n",
    "\n",
    "    print('\\nExperiment parameters')\n",
    "    print('=====================')\n",
    "    print(f'        exp_dir = {exp_dir:s}')\n",
    "    print(f' param_filename = {param_filename:s}')\n",
    "    print(f'output_filename = {output_filename:s}')\n",
    "    print(flush=True)\n",
    "    print('\\nStart time is: ', datetime.datetime.today())\n",
    "\n",
    "    result_dict = {}\n",
    "    \n",
    "    data_fileName = \"./data/DSL-StrongPasswordData.xls\"\n",
    "    global events\n",
    "    events = make_data('s036',12250,12300,data_fileName)\n",
    "    n_jumps_per_dim = list(map(len, events[0]))\n",
    "    print('\\nNumber of jumps:', len(events)*sum(n_jumps_per_dim))\n",
    "    print('\\nper node:', n_jumps_per_dim)\n",
    "    \n",
    "    C_list = [1.0]*132\n",
    "    \n",
    "    param_dict={'inference':{'vi_exp':{'excitation': {'name': 'ExponentialKernel','args': {'decay': 0.1, 'cut_off': 1000.0}}, \n",
    "                          'posterior': {'name': 'LogNormalPosterior', 'args': {}},\n",
    "                          'prior': {'name': 'GaussianLaplacianPrior', 'args': {'dim': 11, 'n_params': 132, 'C': C_list}}, \n",
    "                          'model': {'args': {'n_samples': 1, 'n_weights': 1, 'weight_temp': 1.0}}, \n",
    "                          'optimizer': {'name': 'Adam', 'args': {'lr': 0.01}}, \n",
    "                          'learner': {'args': {'tol': 1e-04, 'lr_gamma': 0.9999, 'max_iter': 40000, 'hyperparam_momentum': 0.5, 'hyperparam_interval': 100, 'hyperparam_offset': 0}}}}\n",
    "               }\n",
    "    \n",
    "\n",
    "    print('\\nINFERENCE')\n",
    "    print('=========')\n",
    "\n",
    "    for key, inference_param_dict in param_dict['inference'].items():\n",
    "        if key.startswith('vi'):\n",
    "            print(f'\\nRun VI ({key:s})')\n",
    "            print('------')\n",
    "            # Set random seed (for reproducibility)\n",
    "            np.random.seed()  # Reset random number generator to avoid dependency on simulation seed\n",
    "            #vi_seed = np.random.randint(2**32 - 1)\n",
    "            vi_seed = np.random.randint(2**16 - 1)\n",
    "            print(f'vi random seed: {vi_seed}')\n",
    "            # Run inference\n",
    "            global intens_sum\n",
    "            global integral_instesity\n",
    "            #coeffs_var, adj_var, mu_var, nu, varsigma = learn_vi(events, vi_seed, inference_param_dict)\n",
    "            coeffs_var, adj_var, mu_var,intens_sum,integral_instesity,end_time  = learn_vi(events, vi_seed, inference_param_dict)\n",
    "            #模型参数\n",
    "            adj_var = adj_var.ravel()\n",
    "            mu_var = mu_var.ravel()            \n",
    "          \n",
    "            global  end_time_result\n",
    "            end_time_result = [0.0]*len(end_time)\n",
    "            \n",
    "            for i in range(len(end_time)):\n",
    "                end_time_result[i]=end_time[i].tolist()\n",
    "                \n",
    "            expresion_temp = ''\n",
    "            events_n = len(events)\n",
    "            dim = len(events[0])\n",
    "            \n",
    "            for i in range(events_n):\n",
    "                temp = ''                  \n",
    "                for j in range(dim):\n",
    "                    temp += 'log('+str(intens_sum[i][j].detach().numpy())+ '-'+ 'epsilon_noise['+str(i)+'])'+ '+'   \n",
    "                #print(intens)\n",
    "                expresion_temp += temp[:-1] + '-' + str(integral_instesity[i].detach().numpy()) + '+' + str(dim) +'*'+ str(end_time_result[i])+'*'+ 'epsilon_noise['+str(i)+'],'\n",
    "\n",
    "            expresion = expresion_temp[:-1]\n",
    "            expresion = '['+expresion+']'\n",
    "         \n",
    "            result_dict.update({\n",
    "                key: {\n",
    "                    'vi_seed': vi_seed,             # VI random seed\n",
    "                    'coeffs': coeffs_var.tolist(),  # VI parameters\n",
    "                    'adjacency': adj_var.tolist(),  # VI Estimator\n",
    "                    'mu':  mu_var.tolist(),\n",
    "                    'expresion': expresion,\n",
    "                }\n",
    "            })\n",
    " \n",
    "\n",
    "    print('\\n\\nSave results...')\n",
    "    \n",
    "    print('\\ncoeffs:',  coeffs_var.tolist())\n",
    "    print( '\\nadjacency:', adj_var.tolist())\n",
    "    print('\\nmu:', mu_var.tolist())\n",
    "    #print('\\nnu:',nu)\n",
    "    #print('\\nvarsigma:',varsigma)\n",
    "\n",
    "    with open(os.path.join(exp_dir, output_filename), 'w') as output_file:\n",
    "        json.dump(result_dict, output_file)\n",
    "\n",
    "    # Log that the run is finished\n",
    "    print('\\n\\nFinished.')\n",
    "    print('\\nEnd time is: ', datetime.datetime.today())\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('-d', '--dir', dest='dir', type=str,\n",
    "                        #required=True, help=\"Working directory\")\n",
    "                        required=False, default=\".\")\n",
    "    parser.add_argument('-p', '--params', dest='param_filename', type=str,\n",
    "                        required=False, default='params.json',\n",
    "                        help=\"Input parameter file (JSON)\")\n",
    "    parser.add_argument('-o', '--outfile', dest='output_filename', type=str,\n",
    "                        required=False, default='output.json',\n",
    "                        help=\"Output file (JSON)\")\n",
    "    #args = parser.parse_args()\n",
    "    args = parser.parse_known_args()[0]\n",
    "\n",
    "    #run(exp_dir=args.dir, param_filename=args.param_filename,output_filename=args.output_filename)\n",
    "    run ('.','params.json','penalty10+decay0.1+s036_12250-12300.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
