{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Experiment parameters\n",
      "=====================\n",
      "        exp_dir = .\n",
      " param_filename = params.json\n",
      "output_filename = penalty10_decay0.1+s002_100-150.json\n",
      "\n",
      "\n",
      "Start time is:  2020-03-13 08:07:14.763460\n",
      "\n",
      "Number of jumps: 1100\n",
      "\n",
      "per node: [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n",
      "\n",
      "INFERENCE\n",
      "=========\n",
      "\n",
      "Run VI (vi_exp)\n",
      "------\n",
      "vi random seed: 39866\n",
      "end_iter is: 39299\n",
      "Converged!\n",
      "\n",
      "\n",
      "\n",
      "Save results...\n",
      "\n",
      "coeffs: [-0.24807173686739586, -0.2758678470385518, -0.3111629957171741, -0.34921823334397434, -0.3673350753475738, -2.5068351320212745, -3.9404202479562334, -4.240106569115206, -4.292283792099217, -4.501476997376635, -4.659038267356749, -3.821392952221646, -4.000168772750195, -3.9822587351971865, -3.91868158711925, -3.7083976230678823, -3.535200467682586, -3.42025785763145, -3.3385977396371627, -3.2836958988807536, -3.1292254859014257, -2.9347154573820657, -2.5516066147319076, -3.7626526246509164, -3.947766818668363, -3.914904882415634, -3.723493492649342, -3.5367723508720506, -3.4013324450954414, -3.3354708818471397, -3.2496812689483185, -3.153354652357397, -2.9337094042289906, -2.581588252928895, -2.332854298923556, -3.7335119573121336, -3.934746354431575, -3.7172812060863145, -3.5202372879023103, -3.427116356539773, -3.3318579687217653, -3.2476821578552286, -3.1404022095827973, -2.94900748172603, -2.6421670614076143, -2.394335731320783, -2.152850787576784, -3.676297545400233, -3.7294868531621033, -3.5286486961986387, -3.413669839926816, -3.3438275190056794, -3.27980888183197, -3.143622943382824, -2.937639688209736, -2.8152802456905754, -2.6150448345458996, -2.44344145383325, -2.16459723348097, -3.4234219378655157, -3.540873914960588, -3.4305730609249934, -3.353001905755619, -3.2619023973897843, -3.1506115571906026, -2.9532280206780315, -3.0015765991369197, -2.8357972468958907, -2.6978022611182046, -2.5186868830903855, 1.231596328452121, -3.1574522527790196, -3.4084840066817814, -3.3314562843301396, -3.2510046003676933, -3.1332575382986185, -2.9503793884037286, -3.3302199794403164, -3.2094977314116075, -3.142386400511801, -3.020915549278203, -2.2323798169541216, 1.5235808809356637, -3.09161477776958, -3.329092800431872, -3.251216431111801, -3.14849150516414, -2.936846494666135, -3.434138152315946, -3.3409736614163115, -3.2707760407179434, -3.1899028407305687, -2.5693965851272527, -1.531103255734225, 1.5849975419989704, -3.0154987715405515, -3.2001715603161194, -3.108587088785642, -2.9597317666160854, -3.474776857414683, -3.38367012253366, -3.316964366864506, -3.1999844192166704, -2.647861094626327, -1.7215752042053745, -0.5889238853938842, 1.576973391949104, -2.949818035931046, -3.1489084152273596, -2.937997688601773, -3.5592699663742597, -3.495996855978416, -3.4265742510221013, -3.352843426427946, -2.88665879369403, -2.249199097765883, -1.7475675994476525, -0.9853649399944431, 1.6792393647637531, -2.8036047927149643, -2.9530791533254064, -3.6640754589298057, -3.579852256995392, -3.52987566328334, -3.454849368882801, -3.0444910381633563, -2.5534791235302134, -2.2071329381953535, -1.7823932557641233, -1.3778380471398668, 1.838995297890321, -2.551875001143951, -2.3589247468516676, -2.3472519176675153, -2.3161030059578285, -2.2641830748413536, -2.2506031682017045, -0.5203690018643592, -0.05852607998180821, -0.031259036897212954, -0.04834252993185994, -0.000586725235070353, -0.012348541874852086, 0.002675985798504023, 0.012072535552767522, 0.0045606899577268975, 0.0010859257715560373, 0.002501756917200935, -0.0026774324491289545, 0.005399187738129059, 0.01851294203247681, -0.0019392976732326625, 0.00910519991503591, -0.0029806427744991045, -0.0949472879840308, -0.009839599787255376, 0.008070263512361365, 0.012145970730155876, 0.015858524803271032, 0.010387815848887132, 0.03325127162416495, 0.020905480300511228, 0.0035879591367322335, 0.00647576135818889, 0.008765743562701113, -0.08542128661691015, -0.1104824062556244, 0.016414915213641624, 0.025445709945366678, 0.01014051073573991, -0.009517854324657904, 0.009241015168203198, 0.0009740619645366755, 0.011620046123134909, 0.008715717985467067, 0.005779829438662263, -0.08046873226803396, -0.10260493797444736, -0.11934366887478001, 0.0034794883795870256, -0.0021603809162323486, 0.0016857439651671283, 0.0173028640217981, 0.009012922102854393, 0.011899302779516795, 0.011530475654136788, -0.0024599607455097158, -0.05235612750968094, -0.07712891740276157, -0.09195883877245846, -0.13983963009541436, -0.0001244707111828305, -0.00015923770249838613, 0.01969839219969675, 0.0071368720094781, 0.018630568352071854, -0.006998624956292043, -0.00782645584726593, -0.04341893942352902, -0.03179597767063765, -0.04960717158591661, -0.06342614018383588, -2.1423997114009987, -0.007690113235166833, 0.010774690210177792, 0.010614246437976614, 0.017604068775866243, -0.01426806754277731, 0.012793292083884243, -0.027146934168244832, 0.01066397939121463, -0.01952223151745022, -0.028605541010850135, -0.07861371830696505, -2.221564915125829, 0.015136405363864106, 0.0001858653204760466, 0.02326912197259281, -0.0014109813638425752, 0.012146235194616366, -0.004737932056008815, -0.009114242400002212, 0.008289025010947672, -0.004976671449878575, -0.050649022640795675, -0.1969858365982088, -2.217485445709856, -0.00030866807110625734, 0.012944062928527112, 0.016036623695158334, -0.00773732040834252, -0.013090160706654455, -0.00296131069457098, 0.012703681690922517, 0.005778546870920632, -0.04509238159522188, -0.13265664817327766, -0.4917117858407476, -2.107611617553956, 0.00844257973836577, 0.018541751132856544, 0.001994367117796318, 0.014820122519543991, -0.00916121843935087, -0.009280177213548875, -0.003714414119416034, -0.016175107856990983, -0.05003542983865661, -0.11581832493639732, -0.29305034834317256, -2.145296596461072, 0.012179594140395579, -0.0014653842759982624, -0.013372076773788856, 0.012494121306044595, -0.0004991280934575593, -0.009923397152133763, -0.006756261060202871, -0.030521173845239207, -0.030762287269932874, -0.08287750968356998, -0.16045535218265405, -2.18764035708509, 0.013793963356608726]\n",
      "\n",
      "adjacency: [0.008012445399265428, 0.006574165058064139, 0.006795994790885639, 0.007292886931223874, 0.008974090602385722, 0.010782186394751323, 0.011901215443285216, 0.012571566770188449, 0.013845087317771548, 0.01580225375901568, 0.0196678116678386, 0.03409334978644501, 0.008711025153861598, 0.006984664578743886, 0.007158217533970329, 0.008602358337298041, 0.010485464666426645, 0.01144621550384421, 0.012548323210126463, 0.014166390361278303, 0.01550813724436516, 0.0192278511579045, 0.032564175056415096, 0.043517192455544834, 0.008506823841631239, 0.006826419374434913, 0.008758161373943269, 0.011093658788955248, 0.011728069162102327, 0.013117500930375744, 0.013965093207265867, 0.01563901602783283, 0.01905102807545038, 0.030393929739692262, 0.040404581749911204, 0.05283867352009849, 0.009248621254790907, 0.008869158013252623, 0.010758857889431764, 0.011691638937115435, 0.01275264204857127, 0.013515840187928287, 0.015499432722654053, 0.019590082225615358, 0.02433441027961369, 0.031051882342748218, 0.037800016211657815, 0.0539000742374949, 0.01199610785254871, 0.010667479226542691, 0.011438662763760729, 0.012684455569573405, 0.013570371440241008, 0.01597529498759871, 0.019493056005711495, 0.019872819809762528, 0.022955790327275225, 0.02723231797384106, 0.03338826904299201, 3.3798115178127395, 0.01588802341467217, 0.01191130592871845, 0.012869286414092192, 0.013748302968602608, 0.01648796244181741, 0.01875497705276969, 0.013879064760369321, 0.014537049408765091, 0.016504959817363805, 0.01896215263761278, 0.04564370826871247, 4.534985127123279, 0.016206377050258194, 0.01317459928032023, 0.01358410968014712, 0.01583276866623943, 0.019035751101471574, 0.011977719746942775, 0.013261233020945245, 0.013739336690811612, 0.015298524878347408, 0.031021950476430096, 0.11019801286101319, 4.821775064941186, 0.01804509049547416, 0.014604907243126644, 0.015904070025379493, 0.019363290594918113, 0.011690996429273614, 0.012553384037962492, 0.013001412828526019, 0.014822506346966831, 0.02839269359616717, 0.08303103470137192, 0.3817641471973531, 4.769323006717899, 0.018933043399213662, 0.015196531174143265, 0.01940946610377301, 0.010159420703069435, 0.011357905536791283, 0.012177259046395071, 0.012965774503755446, 0.02117728256584147, 0.04268223866579427, 0.07880318279148246, 0.21398316514897037, 5.28854185829596, 0.021747356049766582, 0.019251762282743123, 0.009680073707279326, 0.010000148635354672, 0.010792779802926537, 0.011852716161638244, 0.017755332238865523, 0.030371138211971533, 0.042960990381345175, 0.07210390860333199, 0.12204980520729349, 6.21155140752011, 0.02787996360583892]\n",
      "\n",
      "mu: [0.7733634898974604, 0.75200428951433, 0.7254985107204659, 0.6976647881175145, 0.6849354499712391, 0.05726709609740761, 0.007986848387799695, 0.005630806180858936, 0.005515871202862911, 0.004085528288137685, 0.0035719498302209923]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Finished.\n",
      "\n",
      "End time is:  2020-03-13 13:33:35.786445\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import argparse\n",
    "import json\n",
    "import sys\n",
    "import os\n",
    "import math\n",
    "from scipy.optimize import fsolve\n",
    "from scipy import log\n",
    "import random\n",
    "import datetime\n",
    "\n",
    "\n",
    "# External libraries\n",
    "import torch\n",
    "from torch import optim\n",
    "\n",
    "# Internal libraries\n",
    "\n",
    "import models\n",
    "import posteriors\n",
    "import priors\n",
    "import hawkes_model, excitation_kernels\n",
    "import learners\n",
    "import utils\n",
    "\n",
    "from make_data_for_samples import make_data              #多个样本数据\n",
    "from make_data_for_estimate import make_estimate_data    #单个样本数据\n",
    "\n",
    "def make_object(module, name, args):\n",
    "    return getattr(module, name)(**args)\n",
    "\n",
    "#def learn_vi(events, end_time, vi_seed, adjacency_true, inference_param_dict, return_learner=False):\n",
    "def learn_vi(events, vi_seed, inference_param_dict, return_learner=False):\n",
    "    # Extract some parameters for easier access\n",
    "    #n_nodes = len(events)\n",
    "    n_events = len(events)\n",
    "    n_nodes = len(events[0])\n",
    "    M = inference_param_dict['excitation']['args'].get('M', 1)\n",
    "    n_params = n_nodes * (n_nodes * M + 1)\n",
    "    n_edges = M * n_nodes ** 2\n",
    "    # Set seed\n",
    "    np.random.seed(vi_seed)\n",
    "    # Set starting pointM * n_nodes ** 2\n",
    "    x0 = torch.tensor(\n",
    "        np.hstack((\n",
    "            np.hstack((  # alpha, the mean of the parameters\n",
    "                np.random.normal(loc=0.1, scale=0.1, size=n_nodes),\n",
    "                np.random.normal(loc=0.1, scale=0.1, size=n_edges),)),\n",
    "            np.hstack((  # beta=log(sigma), log of the variance of the parameters\n",
    "                np.log(np.clip(np.random.normal(loc=0.2, scale=0.1, size=n_nodes), 1e-1, 2.0)),\n",
    "                np.log(np.clip(np.random.normal(loc=0.2, scale=0.1, size=n_edges), 1e-1, 2.0)),))\n",
    "        )),\n",
    "        dtype=torch.float64, requires_grad=True\n",
    "    )\n",
    "    # Init Hawkes process model object\n",
    "    excitation_obj = make_object(excitation_kernels, **inference_param_dict['excitation'])\n",
    "    hawkes_model_obj = hawkes_model.HawkesModel(excitation=excitation_obj, verbose=False)\n",
    "    # Init the posterior object\n",
    "    posterior_obj = make_object(posteriors, **inference_param_dict['posterior'])\n",
    "    # Init the prior object\n",
    "    prior_type = inference_param_dict['prior']['name']\n",
    "    prior_args = inference_param_dict['prior']['args']\n",
    "    prior_args['C'] = torch.tensor(prior_args['C'], dtype=torch.float64)  # cast to tensor\n",
    "    prior_obj = make_object(priors, prior_type, prior_args)\n",
    "    # Init the variational inference model object\n",
    "    model = models.ModelHawkesVariational(\n",
    "        model=hawkes_model_obj, posterior=posterior_obj, prior=prior_obj,\n",
    "        **inference_param_dict['model']['args'])\n",
    "   \n",
    "    # Init the optimizer\n",
    "    opt_type = inference_param_dict['optimizer']['name']\n",
    "    opt_args = inference_param_dict['optimizer']['args']\n",
    "    opt = getattr(optim, opt_type)([x0], **opt_args)\n",
    "    # Init learner\n",
    "    learner = learners.VariationalInferenceLearner(\n",
    "        model=model, optimizer=opt, **inference_param_dict['learner']['args'])\n",
    "    # Fit the model\n",
    "    events_t = [torch.tensor(events_i) for events_i in events]  # cast to tensor\n",
    "    #learner.fit(events_t, end_time, x0, callback=callback)\n",
    "    learner.fit(events_t, x0=x0, callback=None)\n",
    "    print()\n",
    "    if return_learner:\n",
    "        return learner\n",
    "    # Extract the mode of the posterior\n",
    "    z_est_mode = learner.model.posterior.mode(learner.coeffs[:n_params], learner.coeffs[n_params:])\n",
    "    adj_est_ora = z_est_mode[n_nodes:].detach()\n",
    "    mu_est_ora = z_est_mode[:n_nodes].detach()\n",
    "    adj_est_ora = adj_est_ora.view(n_nodes, n_nodes, M)\n",
    "    adj_est = z_est_mode[n_nodes:].detach().numpy()\n",
    "    adj_est = np.reshape(adj_est, (n_nodes, n_nodes, M)).sum(-1).ravel()\n",
    "    mu_est = z_est_mode[:n_nodes].detach().numpy()\n",
    "    #mu_est = np.reshape(mu_est,n_nodes).ravel()\n",
    "    coeffs_est = learner.coeffs.detach().numpy()\n",
    "    #log_like_sum,min_intens,log_like,end_time = hawkes_model_obj.log_likelihood(mu_est_ora,adj_est_ora)\n",
    "    log_like_sum,intens_sum,integral_instesity,end_time = hawkes_model_obj.log_likelihood(mu_est_ora,adj_est_ora)\n",
    "    \n",
    "    return coeffs_est, adj_est,mu_est,intens_sum,integral_instesity,end_time\n",
    "\n",
    "\n",
    "def run(exp_dir, param_filename, output_filename, stdout=None, stderr=None):\n",
    "    # Reset random seed\n",
    "    np.random.seed(None)\n",
    "\n",
    "    if stdout is not None:\n",
    "        sys.stdout = open(stdout, 'w')\n",
    "    if stderr is not None:\n",
    "        sys.stderr = open(stderr, 'w')\n",
    "\n",
    "    print('\\nExperiment parameters')\n",
    "    print('=====================')\n",
    "    print(f'        exp_dir = {exp_dir:s}')\n",
    "    print(f' param_filename = {param_filename:s}')\n",
    "    print(f'output_filename = {output_filename:s}')\n",
    "    print(flush=True)\n",
    "    print('\\nStart time is: ', datetime.datetime.today())\n",
    "\n",
    "    result_dict = {}\n",
    "    \n",
    "    data_fileName = \"./data/DSL-StrongPasswordData.xls\"\n",
    "    global events\n",
    "    events = make_data('s032',10400,10600,data_fileName)\n",
    "    n_jumps_per_dim = list(map(len, events[0]))\n",
    "    print('\\nNumber of jumps:', len(events)*sum(n_jumps_per_dim))\n",
    "    print('\\nper node:', n_jumps_per_dim)\n",
    "    \n",
    "    C_list = [1.0]*132\n",
    "    \n",
    "    param_dict={'inference':{'vi_exp':{'excitation': {'name': 'ExponentialKernel','args': {'decay': 1.0, 'cut_off': 1000.0}}, \n",
    "                          'posterior': {'name': 'LogNormalPosterior', 'args': {}},\n",
    "                          'prior': {'name': 'GaussianLaplacianPrior', 'args': {'dim': 11, 'n_params': 132, 'C': C_list}}, \n",
    "                          'model': {'args': {'n_samples': 1, 'n_weights': 1, 'weight_temp': 1.0}}, \n",
    "                          'optimizer': {'name': 'Adam', 'args': {'lr': 0.01}}, \n",
    "                          'learner': {'args': {'tol': 1e-04, 'lr_gamma': 0.9999, 'max_iter': 40000, 'hyperparam_momentum': 0.5, 'hyperparam_interval': 100, 'hyperparam_offset': 0}}}}\n",
    "               }\n",
    "    \n",
    "\n",
    "    print('\\nINFERENCE')\n",
    "    print('=========')\n",
    "\n",
    "    for key, inference_param_dict in param_dict['inference'].items():\n",
    "        if key.startswith('vi'):\n",
    "            print(f'\\nRun VI ({key:s})')\n",
    "            print('------')\n",
    "            # Set random seed (for reproducibility)\n",
    "            np.random.seed()  # Reset random number generator to avoid dependency on simulation seed\n",
    "            #vi_seed = np.random.randint(2**32 - 1)\n",
    "            vi_seed = np.random.randint(2**16 - 1)\n",
    "            print(f'vi random seed: {vi_seed}')\n",
    "            # Run inference\n",
    "            global intens_sum\n",
    "            global integral_instesity\n",
    "            #coeffs_var, adj_var, mu_var, nu, varsigma = learn_vi(events, vi_seed, inference_param_dict)\n",
    "            coeffs_var, adj_var, mu_var,intens_sum,integral_instesity,end_time  = learn_vi(events, vi_seed, inference_param_dict)\n",
    "            #模型参数\n",
    "            adj_var = adj_var.ravel()\n",
    "            mu_var = mu_var.ravel()            \n",
    "          \n",
    "            global  end_time_result\n",
    "            end_time_result = [0.0]*len(end_time)\n",
    "            \n",
    "            for i in range(len(end_time)):\n",
    "                end_time_result[i]=end_time[i].tolist()\n",
    "                \n",
    "            expresion_temp = ''\n",
    "            events_n = len(events)\n",
    "            dim = len(events[0])\n",
    "            \n",
    "            for i in range(events_n):\n",
    "                temp = ''                  \n",
    "                for j in range(dim):\n",
    "                    temp += 'log('+str(intens_sum[i][j].detach().numpy())+ '-'+ 'epsilon_noise['+str(i)+'])'+ '+'   \n",
    "                #print(intens)\n",
    "                expresion_temp += temp[:-1] + '-' + str(integral_instesity[i].detach().numpy()) + '+' + str(dim) +'*'+ str(end_time_result[i])+'*'+ 'epsilon_noise['+str(i)+'],'\n",
    "\n",
    "            expresion = expresion_temp[:-1]\n",
    "            expresion = '['+expresion+']'\n",
    "         \n",
    "            result_dict.update({\n",
    "                key: {\n",
    "                    'vi_seed': vi_seed,             # VI random seed\n",
    "                    'coeffs': coeffs_var.tolist(),  # VI parameters\n",
    "                    'adjacency': adj_var.tolist(),  # VI Estimator\n",
    "                    'mu':  mu_var.tolist(),\n",
    "                    'expresion': expresion,\n",
    "                }\n",
    "            })\n",
    " \n",
    "\n",
    "    print('\\n\\nSave results...')\n",
    "    \n",
    "    print('\\ncoeffs:',  coeffs_var.tolist())\n",
    "    print( '\\nadjacency:', adj_var.tolist())\n",
    "    print('\\nmu:', mu_var.tolist())\n",
    "    #print('\\nnu:',nu)\n",
    "    #print('\\nvarsigma:',varsigma)\n",
    "\n",
    "    with open(os.path.join(exp_dir, output_filename), 'w') as output_file:\n",
    "        json.dump(result_dict, output_file)\n",
    "\n",
    "    # Log that the run is finished\n",
    "    print('\\n\\nFinished.')\n",
    "    print('\\nEnd time is: ', datetime.datetime.today())\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('-d', '--dir', dest='dir', type=str,\n",
    "                        #required=True, help=\"Working directory\")\n",
    "                        required=False, default=\".\")\n",
    "    parser.add_argument('-p', '--params', dest='param_filename', type=str,\n",
    "                        required=False, default='params.json',\n",
    "                        help=\"Input parameter file (JSON)\")\n",
    "    parser.add_argument('-o', '--outfile', dest='output_filename', type=str,\n",
    "                        required=False, default='output.json',\n",
    "                        help=\"Output file (JSON)\")\n",
    "    #args = parser.parse_args()\n",
    "    args = parser.parse_known_args()[0]\n",
    "\n",
    "    #run(exp_dir=args.dir, param_filename=args.param_filename,output_filename=args.output_filename)\n",
    "    run ('.','params.json','penalty10_decay1.0+s032_10400-10600.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
