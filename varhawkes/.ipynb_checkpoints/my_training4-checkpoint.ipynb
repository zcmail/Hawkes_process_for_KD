{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Experiment parameters\n",
      "=====================\n",
      "        exp_dir = .\n",
      " param_filename = params.json\n",
      "output_filename = penalty10_decay0.3+s032_10400-10410.json\n",
      "\n",
      "\n",
      "Start time is:  2020-03-18 00:27:53.646581\n",
      "\n",
      "Number of jumps: 220\n",
      "\n",
      "per node: [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n",
      "\n",
      "INFERENCE\n",
      "=========\n",
      "\n",
      "Run VI (vi_exp)\n",
      "------\n",
      "vi random seed: 43783\n",
      "\n",
      "\n",
      "\n",
      "Save results...\n",
      "\n",
      "coeffs: [-0.4829117328711559, -0.6295551127404918, -0.8089535269319216, -0.964832610266005, -0.917442457264665, -0.9780904224973594, -2.1488496582184844, -2.4919271099104705, -2.645895568522244, -2.7087961215983265, -2.646411579348976, -3.421157899087408, -3.6229941894838578, -3.5999110453722545, -3.575422667486254, -3.502952473923312, -3.385516610362957, -3.3268666883447704, -3.2766317382927688, -3.2391286928066103, -3.146020333363928, -2.9250938976153136, -2.1156511289266655, -3.3712462791712237, -3.596950249873206, -3.570380735123427, -3.492699402153418, -3.383212967109542, -3.3171921215312636, -3.2848335434603397, -3.2248751467073444, -3.1471897212679263, -2.922121169629151, -2.3005981117528984, -1.8164124257309666, -3.351604636804798, -3.582266451000088, -3.48798893862366, -3.3802355884996373, -3.3268452329755736, -3.2763966086550163, -3.2224635430751407, -3.1393763580365173, -2.915321289340784, -2.482425430071289, -2.12851457053812, -1.8370588500544078, -3.3213744574477655, -3.499279894059696, -3.3757640796927, -3.3223704242483465, -3.28814879509899, -3.2293500626294653, -3.1384023377408408, -2.9157304616028705, -2.7687751337031226, -2.5575235598929043, -2.3741599406252485, -2.0700620677631703, -3.2126190779967865, -3.3739252573062517, -3.318927419916707, -3.2748277460815376, -3.2249360868054757, -3.1474017158193384, -2.9162854313156363, -2.9926636369229844, -2.837661408069133, -2.716728296845593, -2.5259186955328805, -1.7611464073048704, -3.0507672198065454, -3.3339984113160814, -3.2716201011144697, -3.247717419946431, -3.147399134046563, -2.9223690436068166, -3.1248428101123507, -3.000417060906167, -2.9212939884034665, -2.783574997022184, -2.303599543151632, -0.40278678057763734, -3.005084005727749, -3.283030772556109, -3.2281028428571354, -3.146811418624934, -2.9207244164982624, -3.2102600407091617, -3.1226398245995624, -3.0441654894820305, -2.9205332192560456, -2.548468216892709, -1.648913918405437, -0.44689367509214806, -2.9871438099522307, -3.2299014246173114, -3.1446880627066793, -2.907275181640715, -3.2701204515658557, -3.1697171541206286, -3.1079422662707867, -2.995727387718382, -2.667095455899356, -1.9827414313692853, -1.446965822185365, -0.613805216851645, -2.937445648797183, -3.1499916762825197, -2.9056288992375316, -3.3074544676034416, -3.2191129780701453, -3.1695711271734153, -3.0816797939706233, -2.791068295858682, -2.218781917039244, -1.8520792796708043, -1.4773385046069436, -0.7072234290689512, -2.8323509715911808, -2.922537393847826, -3.371848384197326, -3.287092967784837, -3.2402244522268573, -3.1659063844612945, -2.9341329169198755, -2.4803707792722136, -2.2349674213444177, -2.0139070761959137, -1.6809334993319305, -0.548848921239456, -2.4836873979468583, -1.6079332647732179, -1.4716096098216698, -1.3099238205045747, -1.183608707178888, -1.2127915326508947, -1.1601599673638798, -0.390467015081967, -0.24597399229285288, -0.19492202037397355, -0.18762609132876262, -0.20743068978762602, 0.00013877272761289992, 0.004643212271688181, 0.0006176252280263799, 0.010010496928587161, 0.01255975554160014, 0.009333640496423847, 0.0039491141323424435, 0.001428871331583789, 0.0011282119302828742, 0.006179463010251382, 0.002004286075505563, -0.2312729419962161, -0.0012214565063673303, 0.015129369644908842, 0.014090910104487289, 0.00834132193729721, -0.004164970170193687, 0.0037568566275055014, 0.00655621317700135, -0.0047090426943124, 0.00024246543421049346, 0.0005487313266449077, -0.17493693670573537, -0.3274114478706645, -0.0037089331091535232, 0.0004926227453689278, 0.002605065465605741, -9.457154739508985e-05, 0.004812646454026471, 0.00821049647073392, 0.005090810953565224, -0.0005104642776111632, 0.012468510380933159, -0.12216920315021704, -0.2140924420065627, -0.3193554099273715, -0.0033778653776870993, 0.00827697495938854, -0.0037179612201526267, -0.0031480812206948657, 0.008239245777254984, 0.005290119965838478, 0.012822045514977126, 0.01739856937465448, -0.07300153614488963, -0.10265090547722873, -0.141167908874052, -0.21692865973211695, -0.008587612863282714, 0.01221420902983048, 0.011870732028764678, 0.0014986869991648745, 0.003930770316608904, 0.0011502681390522145, 0.002639805551683755, -0.0329309092726534, -0.049698749871474934, -0.06799755660589138, -0.10349789333925007, -0.30268092877845537, -0.005739426914155297, 0.006317921980328498, -0.0035326951663109474, 0.00475512050841894, 0.018488682066140995, 0.00427913601337144, -0.011666363088942582, -0.025934503315336806, -0.03955279712708614, -0.043474782013598924, -0.13066461776843386, -1.0532895189732818, -0.004555252960922028, 0.018702324206235427, 0.009030840033604234, 0.015207223239110482, 0.011621190469807025, -0.007252729598670708, -0.026010958903140566, -0.021438835430391313, -0.04135169832616616, -0.07296704900101991, -0.3097342569390051, -0.9606801571520704, -0.008817833637508493, 0.007838474750620626, 0.008831916855606636, 0.011892234446693089, -0.007651959833791264, -0.0057602667986461345, -0.027369321530674992, -0.024418578831957506, -0.0664351899282741, -0.19183907956375187, -0.3592527116417496, -0.8091851727423263, -0.002035983908746323, 0.01007091710322939, -0.0046648205830869625, -0.009369065015340985, -0.011027830996960844, -0.00951376620978366, -0.009075262577729563, -0.030687516409095363, -0.11088556076333714, -0.20430810740376878, -0.32765234101122426, -0.7130707976136658, 0.001389155045901928, 0.002806043172979917, -0.0030008523318139973, -0.005587801276100576, -0.003173787547158888, -0.010184821247593094, -0.02774481629969864, -0.07214599762224758, -0.10867523459098656, -0.14228319225167269, -0.24629716829297163, -0.7674615961189253, -0.019896405362681214]\n",
      "\n",
      "adjacency: [0.012016969741124383, 0.009732116662168413, 0.010040312305625097, 0.010095702651779573, 0.0107980454477449, 0.012223936829922248, 0.013104544639462219, 0.013849674226261413, 0.014387612807460558, 0.015631675438861382, 0.019661153081514643, 0.06422712539294946, 0.01266635076750753, 0.009777500136280632, 0.010062260682128505, 0.01100371893418571, 0.012589179238528078, 0.01323706892112034, 0.01359528395135523, 0.014764918662871006, 0.01580111503293825, 0.01977732430446734, 0.04952017647098264, 0.09671889554218137, 0.012981705069400735, 0.010221599679885653, 0.011184653473379977, 0.01252477666520835, 0.013082013624188068, 0.013664512065414715, 0.014513193103090849, 0.015949050992064416, 0.01943709668984536, 0.03817219255485462, 0.062025760582388616, 0.09394634219718553, 0.013371342315486505, 0.0109329772673382, 0.012672059667328033, 0.01335193392803044, 0.013504074748725028, 0.014407786761607394, 0.015539376342307587, 0.019232761910549786, 0.026438600886413168, 0.03432349946079886, 0.04379741992334549, 0.06600222837212968, 0.01506184573044464, 0.012293870259844629, 0.012998088690025092, 0.013872738596113602, 0.014511285666149478, 0.015769069244941335, 0.019809790295342064, 0.019664823153871868, 0.023681901907639295, 0.02761005682967311, 0.03547447798549769, 0.09955716586070827, 0.017608844114276684, 0.012949288623841593, 0.014057775611598664, 0.014160866104638044, 0.015221160728763651, 0.019624744346249428, 0.0165431991821266, 0.019257199432363713, 0.021381347595901466, 0.024716151866966338, 0.04625309489297187, 0.5918866051937398, 0.018388774635038886, 0.013284680108690506, 0.014316699561757767, 0.015333840289611862, 0.019365948125950588, 0.015057798054120601, 0.017044156104668955, 0.0182754971992251, 0.021468739337865028, 0.032952673881064376, 0.11223680133945628, 0.5525002786435531, 0.01887979944554334, 0.014325674927098407, 0.015568450372990978, 0.019617274342523684, 0.014194041121670895, 0.01563469606338398, 0.017341118303339606, 0.019292022983219803, 0.028935848117029046, 0.06966257079975774, 0.1445042860464408, 0.4439573918867938, 0.01957735064656152, 0.015447042374749004, 0.020316078864832766, 0.01372013516713006, 0.01503613817313704, 0.015753015439713098, 0.017185436009040034, 0.02395594495831011, 0.048807044860853625, 0.08072971830822442, 0.13579317448519376, 0.3877255691468284, 0.021598462556539993, 0.019679746718200265, 0.01270366615204412, 0.013898427422752265, 0.014495790523476392, 0.01583167179085043, 0.020647629748319535, 0.035224770758592656, 0.04785329334905969, 0.06289758651154187, 0.10106690109604147, 0.46564992470451366, 0.03191510331810011]\n",
      "\n",
      "mu: [0.5927205221217818, 0.5054779160948845, 0.4140504375381783, 0.3469502722619585, 0.3657266791554382, 0.3408432543642063, 0.07376818747173905, 0.04489803366177186, 0.036042443656227816, 0.033509975786614805, 0.03663162271353368]\n",
      "\n",
      "\n",
      "Finished.\n",
      "\n",
      "End time is:  2020-03-18 01:52:20.470055\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import argparse\n",
    "import json\n",
    "import sys\n",
    "import os\n",
    "import math\n",
    "from scipy.optimize import fsolve\n",
    "from scipy import log\n",
    "import random\n",
    "import datetime\n",
    "\n",
    "\n",
    "# External libraries\n",
    "import torch\n",
    "from torch import optim\n",
    "\n",
    "# Internal libraries\n",
    "\n",
    "import models\n",
    "import posteriors\n",
    "import priors\n",
    "import hawkes_model, excitation_kernels\n",
    "import learners\n",
    "import utils\n",
    "\n",
    "from make_data_for_samples import make_data              #多个样本数据\n",
    "from make_data_for_estimate import make_estimate_data    #单个样本数据\n",
    "\n",
    "def make_object(module, name, args):\n",
    "    return getattr(module, name)(**args)\n",
    "\n",
    "#def learn_vi(events, end_time, vi_seed, adjacency_true, inference_param_dict, return_learner=False):\n",
    "def learn_vi(events, vi_seed, inference_param_dict, return_learner=False):\n",
    "    # Extract some parameters for easier access\n",
    "    #n_nodes = len(events)\n",
    "    n_events = len(events)\n",
    "    n_nodes = len(events[0])\n",
    "    M = inference_param_dict['excitation']['args'].get('M', 1)\n",
    "    n_params = n_nodes * (n_nodes * M + 1)\n",
    "    n_edges = M * n_nodes ** 2\n",
    "    # Set seed\n",
    "    np.random.seed(vi_seed)\n",
    "    # Set starting pointM * n_nodes ** 2\n",
    "    x0 = torch.tensor(\n",
    "        np.hstack((\n",
    "            np.hstack((  # alpha, the mean of the parameters\n",
    "                np.random.normal(loc=0.1, scale=0.1, size=n_nodes),\n",
    "                np.random.normal(loc=0.1, scale=0.1, size=n_edges),)),\n",
    "            np.hstack((  # beta=log(sigma), log of the variance of the parameters\n",
    "                np.log(np.clip(np.random.normal(loc=0.2, scale=0.1, size=n_nodes), 1e-1, 2.0)),\n",
    "                np.log(np.clip(np.random.normal(loc=0.2, scale=0.1, size=n_edges), 1e-1, 2.0)),))\n",
    "        )),\n",
    "        dtype=torch.float64, requires_grad=True\n",
    "    )\n",
    "    # Init Hawkes process model object\n",
    "    excitation_obj = make_object(excitation_kernels, **inference_param_dict['excitation'])\n",
    "    hawkes_model_obj = hawkes_model.HawkesModel(excitation=excitation_obj, verbose=False)\n",
    "    # Init the posterior object\n",
    "    posterior_obj = make_object(posteriors, **inference_param_dict['posterior'])\n",
    "    # Init the prior object\n",
    "    prior_type = inference_param_dict['prior']['name']\n",
    "    prior_args = inference_param_dict['prior']['args']\n",
    "    prior_args['C'] = torch.tensor(prior_args['C'], dtype=torch.float64)  # cast to tensor\n",
    "    prior_obj = make_object(priors, prior_type, prior_args)\n",
    "    # Init the variational inference model object\n",
    "    model = models.ModelHawkesVariational(\n",
    "        model=hawkes_model_obj, posterior=posterior_obj, prior=prior_obj,\n",
    "        **inference_param_dict['model']['args'])\n",
    "   \n",
    "    # Init the optimizer\n",
    "    opt_type = inference_param_dict['optimizer']['name']\n",
    "    opt_args = inference_param_dict['optimizer']['args']\n",
    "    opt = getattr(optim, opt_type)([x0], **opt_args)\n",
    "    # Init learner\n",
    "    learner = learners.VariationalInferenceLearner(\n",
    "        model=model, optimizer=opt, **inference_param_dict['learner']['args'])\n",
    "    # Fit the model\n",
    "    events_t = [torch.tensor(events_i) for events_i in events]  # cast to tensor\n",
    "    #learner.fit(events_t, end_time, x0, callback=callback)\n",
    "    learner.fit(events_t, x0=x0, callback=None)\n",
    "    print()\n",
    "    if return_learner:\n",
    "        return learner\n",
    "    # Extract the mode of the posterior\n",
    "    z_est_mode = learner.model.posterior.mode(learner.coeffs[:n_params], learner.coeffs[n_params:])\n",
    "    adj_est_ora = z_est_mode[n_nodes:].detach()\n",
    "    mu_est_ora = z_est_mode[:n_nodes].detach()\n",
    "    adj_est_ora = adj_est_ora.view(n_nodes, n_nodes, M)\n",
    "    adj_est = z_est_mode[n_nodes:].detach().numpy()\n",
    "    adj_est = np.reshape(adj_est, (n_nodes, n_nodes, M)).sum(-1).ravel()\n",
    "    mu_est = z_est_mode[:n_nodes].detach().numpy()\n",
    "    #mu_est = np.reshape(mu_est,n_nodes).ravel()\n",
    "    coeffs_est = learner.coeffs.detach().numpy()\n",
    "    #log_like_sum,min_intens,log_like,end_time = hawkes_model_obj.log_likelihood(mu_est_ora,adj_est_ora)\n",
    "    log_like_sum,intens_sum,integral_instesity,end_time = hawkes_model_obj.log_likelihood(mu_est_ora,adj_est_ora)\n",
    "    \n",
    "    return coeffs_est, adj_est,mu_est,intens_sum,integral_instesity,end_time\n",
    "\n",
    "\n",
    "def run(exp_dir, param_filename, output_filename, stdout=None, stderr=None):\n",
    "    # Reset random seed\n",
    "    np.random.seed(None)\n",
    "\n",
    "    if stdout is not None:\n",
    "        sys.stdout = open(stdout, 'w')\n",
    "    if stderr is not None:\n",
    "        sys.stderr = open(stderr, 'w')\n",
    "\n",
    "    print('\\nExperiment parameters')\n",
    "    print('=====================')\n",
    "    print(f'        exp_dir = {exp_dir:s}')\n",
    "    print(f' param_filename = {param_filename:s}')\n",
    "    print(f'output_filename = {output_filename:s}')\n",
    "    print(flush=True)\n",
    "    print('\\nStart time is: ', datetime.datetime.today())\n",
    "\n",
    "    result_dict = {}\n",
    "    \n",
    "    data_fileName = \"./data/DSL-StrongPasswordData.xls\"\n",
    "    global events\n",
    "    events = make_data('s032',10400,10410,data_fileName)\n",
    "    n_jumps_per_dim = list(map(len, events[0]))\n",
    "    print('\\nNumber of jumps:', len(events)*sum(n_jumps_per_dim))\n",
    "    print('\\nper node:', n_jumps_per_dim)\n",
    "    \n",
    "    C_list = [1.0]*132\n",
    "    \n",
    "    param_dict={'inference':{'vi_exp':{'excitation': {'name': 'ExponentialKernel','args': {'decay': 0.3, 'cut_off': 1000.0}}, \n",
    "                          'posterior': {'name': 'LogNormalPosterior', 'args': {}},\n",
    "                          'prior': {'name': 'GaussianLaplacianPrior', 'args': {'dim': 11, 'n_params': 132, 'C': C_list}}, \n",
    "                          'model': {'args': {'n_samples': 1, 'n_weights': 1, 'weight_temp': 1.0}}, \n",
    "                          'optimizer': {'name': 'Adam', 'args': {'lr': 0.01}}, \n",
    "                          'learner': {'args': {'tol': 1e-04, 'lr_gamma': 0.9999, 'max_iter': 40000, 'hyperparam_momentum': 0.5, 'hyperparam_interval': 100, 'hyperparam_offset': 0}}}}\n",
    "               }\n",
    "    \n",
    "\n",
    "    print('\\nINFERENCE')\n",
    "    print('=========')\n",
    "\n",
    "    for key, inference_param_dict in param_dict['inference'].items():\n",
    "        if key.startswith('vi'):\n",
    "            print(f'\\nRun VI ({key:s})')\n",
    "            print('------')\n",
    "            # Set random seed (for reproducibility)\n",
    "            np.random.seed()  # Reset random number generator to avoid dependency on simulation seed\n",
    "            #vi_seed = np.random.randint(2**32 - 1)\n",
    "            vi_seed = np.random.randint(2**16 - 1)\n",
    "            print(f'vi random seed: {vi_seed}')\n",
    "            # Run inference\n",
    "            global intens_sum\n",
    "            global integral_instesity\n",
    "            #coeffs_var, adj_var, mu_var, nu, varsigma = learn_vi(events, vi_seed, inference_param_dict)\n",
    "            coeffs_var, adj_var, mu_var,intens_sum,integral_instesity,end_time  = learn_vi(events, vi_seed, inference_param_dict)\n",
    "            #模型参数\n",
    "            adj_var = adj_var.ravel()\n",
    "            mu_var = mu_var.ravel()            \n",
    "          \n",
    "            global  end_time_result\n",
    "            end_time_result = [0.0]*len(end_time)\n",
    "            \n",
    "            for i in range(len(end_time)):\n",
    "                end_time_result[i]=end_time[i].tolist()\n",
    "                \n",
    "            expresion_temp = ''\n",
    "            events_n = len(events)\n",
    "            dim = len(events[0])\n",
    "            \n",
    "            for i in range(events_n):\n",
    "                temp = ''                  \n",
    "                for j in range(dim):\n",
    "                    temp += 'log('+str(intens_sum[i][j].detach().numpy())+ '-'+ 'epsilon_noise['+str(i)+'])'+ '+'   \n",
    "                #print(intens)\n",
    "                expresion_temp += temp[:-1] + '-' + str(integral_instesity[i].detach().numpy()) + '+' + str(dim) +'*'+ str(end_time_result[i])+'*'+ 'epsilon_noise['+str(i)+'],'\n",
    "\n",
    "            expresion = expresion_temp[:-1]\n",
    "            expresion = '['+expresion+']'\n",
    "         \n",
    "            result_dict.update({\n",
    "                key: {\n",
    "                    'vi_seed': vi_seed,             # VI random seed\n",
    "                    'coeffs': coeffs_var.tolist(),  # VI parameters\n",
    "                    'adjacency': adj_var.tolist(),  # VI Estimator\n",
    "                    'mu':  mu_var.tolist(),\n",
    "                    'expresion': expresion,\n",
    "                }\n",
    "            })\n",
    " \n",
    "\n",
    "    print('\\n\\nSave results...')\n",
    "    \n",
    "    print('\\ncoeffs:',  coeffs_var.tolist())\n",
    "    print( '\\nadjacency:', adj_var.tolist())\n",
    "    print('\\nmu:', mu_var.tolist())\n",
    "    #print('\\nnu:',nu)\n",
    "    #print('\\nvarsigma:',varsigma)\n",
    "\n",
    "    with open(os.path.join(exp_dir, output_filename), 'w') as output_file:\n",
    "        json.dump(result_dict, output_file)\n",
    "\n",
    "    # Log that the run is finished\n",
    "    print('\\n\\nFinished.')\n",
    "    print('\\nEnd time is: ', datetime.datetime.today())\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('-d', '--dir', dest='dir', type=str,\n",
    "                        #required=True, help=\"Working directory\")\n",
    "                        required=False, default=\".\")\n",
    "    parser.add_argument('-p', '--params', dest='param_filename', type=str,\n",
    "                        required=False, default='params.json',\n",
    "                        help=\"Input parameter file (JSON)\")\n",
    "    parser.add_argument('-o', '--outfile', dest='output_filename', type=str,\n",
    "                        required=False, default='output.json',\n",
    "                        help=\"Output file (JSON)\")\n",
    "    #args = parser.parse_args()\n",
    "    args = parser.parse_known_args()[0]\n",
    "\n",
    "    #run(exp_dir=args.dir, param_filename=args.param_filename,output_filename=args.output_filename)\n",
    "    run ('.','params.json','penalty10_decay0.3+s032_10400-10410.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
