{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Start time is:  2020-03-04 20:46:32.331517\n",
      "mean: -8.807504142904445\n",
      "mean: -8.807504142904445\n",
      "mean: -8.807504142904445\n",
      "mean: -8.807504142904445\n",
      "mean: -8.807504142904445\n",
      "mean: -8.807504142904445\n",
      "mean: -8.807504142904445\n",
      "mean: -8.807504142904445\n",
      "mean: -8.807504142904445\n",
      "mean: -8.807504142904445\n",
      "mean: -8.807504142904445\n",
      "mean: -8.807504142904445\n",
      "mean: -8.807504142904445\n",
      "mean: -8.807504142904445\n",
      "mean: -8.807504142904445\n",
      "mean: -8.807504142904445\n",
      "mean: -8.807504142904445\n",
      "mean: -8.807504142904445\n",
      "mean: -8.807504142904445\n",
      "mean: -8.807504142904445\n",
      "FN is: [772, 666, 570, 473, 377, 278, 214, 165, 134, 109, 83, 65, 56, 46, 43, 38, 34, 31, 31, 29]\n",
      "TP is: [28, 134, 230, 327, 423, 522, 586, 635, 666, 691, 717, 735, 744, 754, 757, 762, 766, 769, 769, 771]\n",
      "FP is: [1112, 4397, 7637, 10824, 14258, 17823, 21287, 24654, 27741, 30333, 32351, 33888, 35132, 35974, 36518, 36939, 37246, 37504, 37758, 37967]\n",
      "TN is: [38888, 35603, 32363, 29176, 25742, 22177, 18713, 15346, 12259, 9667, 7649, 6112, 4868, 4026, 3482, 3061, 2754, 2496, 2242, 2033]\n",
      "false_alarm_rate is: [0.0278, 0.109925, 0.190925, 0.2706, 0.35645, 0.445575, 0.532175, 0.61635, 0.693525, 0.758325, 0.808775, 0.8472, 0.8783, 0.89935, 0.91295, 0.923475, 0.93115, 0.9376, 0.94395, 0.949175]\n",
      "miss_rate is: [0.965, 0.8325, 0.7125, 0.59125, 0.47125, 0.3475, 0.2675, 0.20625, 0.1675, 0.13625, 0.10375, 0.08125, 0.07, 0.0575, 0.05375, 0.0475, 0.0425, 0.03875, 0.03875, 0.03625]\n",
      "hit_rate is: [0.03500000000000003, 0.16749999999999998, 0.2875, 0.40874999999999995, 0.52875, 0.6525000000000001, 0.7324999999999999, 0.79375, 0.8325, 0.86375, 0.89625, 0.91875, 0.9299999999999999, 0.9425, 0.94625, 0.9525, 0.9575, 0.96125, 0.96125, 0.96375]\n",
      "\n",
      "\n",
      "Finished.\n",
      "\n",
      "End time is:  2020-03-05 04:29:45.241229\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import argparse\n",
    "import json\n",
    "import sys\n",
    "import os\n",
    "import torch\n",
    "import math\n",
    "import datetime\n",
    "\n",
    "# Internal libraries\n",
    "import excitation_kernels\n",
    "import hawkes_model_single\n",
    "\n",
    "\n",
    "from make_data_for_samples import make_data #多个样本数据\n",
    "from make_data_for_samples import make_data_all\n",
    "from make_data_for_estimate import make_estimate_data     #单个样本数据\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "global result\n",
    "\n",
    "def make_object(module, name, args):\n",
    "    return getattr(module, name)(**args)\n",
    "\n",
    "param_dict_exitation = {'exitation':{'name': 'ExponentialKernel', 'args': {'decay':0.3, 'cut_off': 1000.0}}}\n",
    "\n",
    "#求正样本的情况\n",
    "def decision_fun_1(mu,W, new_events, M ,param_dict, nu, sigma, threshold):\n",
    "    events_num = len(new_events)\n",
    "    dim = len(new_events[0])\n",
    "    n_params = dim * (M * dim + 1)\n",
    "    #3倍上界\n",
    "    up =  math.exp(nu) * (math.exp(sigma))**3\n",
    "    #3倍下界\n",
    "    down = math.exp(nu) / (math.exp(sigma))**3    \n",
    "    \n",
    "    # Init Hawkes process model object\n",
    "    excitation_obj = make_object(excitation_kernels, **param_dict['exitation'])\n",
    "    hawkes_model_obj = hawkes_model_single.HawkesModel(excitation=excitation_obj, verbose=False)\n",
    "   \n",
    "    W = W.view(dim,dim,M)\n",
    "    \n",
    "    count = 0\n",
    "    \n",
    "    loglik_all=[]\n",
    "\n",
    "    for i in range(events_num):\n",
    "        loglik=[0.0,0.0]        \n",
    "        hawkes_model_obj.set_data(new_events[i])\n",
    "        loglik_max = hawkes_model_obj.log_likelihood(mu,W,epsilon_noise=up)\n",
    "        loglik_min = hawkes_model_obj.log_likelihood(mu,W,epsilon_noise=down)\n",
    "        \n",
    "        loglik[0] = loglik_min.item()\n",
    "        loglik[1] = loglik_max.item()\n",
    "        \n",
    "        if math.isnan(loglik[0]):\n",
    "            loglik[0] = loglik_all[i-1][0]\n",
    "        if math.isnan(loglik[1]):\n",
    "            loglik[1] = loglik_all[i-1][1]\n",
    "        \n",
    "        loglik_all.append(loglik)\n",
    "        \n",
    "    loglik_list = sum(loglik_all,[])\n",
    "    #print(loglik_list)\n",
    "    \n",
    "    mean = np.mean(loglik_list)\n",
    "    print('mean:',mean)\n",
    "    \n",
    "    distance = list( map(lambda x: abs(x - mean), loglik_list) )\n",
    "    \n",
    "    distance_array = np.array(distance)\n",
    "    #距离大于threshold的正样本个数\n",
    "    out_num = np.sum((distance_array > threshold))  \n",
    "    \n",
    "    return mean,out_num\n",
    "\n",
    "#求所有样本的情况\n",
    "def decision_fun_2(mu,W, new_events, M ,param_dict, nu, sigma,threshold, mean):\n",
    "    events_num = len(new_events)\n",
    "    dim = len(new_events[0])\n",
    "    n_params = dim * (M * dim + 1)\n",
    "    #3倍上界\n",
    "    up =  math.exp(nu) * (math.exp(sigma))**3\n",
    "    #3倍下界\n",
    "    down = math.exp(nu) / (math.exp(sigma))**3    \n",
    "    \n",
    "    # Init Hawkes process model object\n",
    "    excitation_obj = make_object(excitation_kernels, **param_dict['exitation'])\n",
    "    hawkes_model_obj = hawkes_model_single.HawkesModel(excitation=excitation_obj, verbose=False)\n",
    "   \n",
    "    W = W.view(dim,dim,M)\n",
    "    \n",
    "    count = 0\n",
    "    \n",
    "    loglik_all=[]\n",
    "\n",
    "    for i in range(events_num):\n",
    "        loglik=[0.0,0.0]        \n",
    "        hawkes_model_obj.set_data(new_events[i])\n",
    "        loglik_max = hawkes_model_obj.log_likelihood(mu,W,epsilon_noise=up)\n",
    "        loglik_min = hawkes_model_obj.log_likelihood(mu,W,epsilon_noise=down)\n",
    "        \n",
    "        loglik[0] = loglik_min.item()\n",
    "        loglik[1] = loglik_max.item()\n",
    "        \n",
    "        if math.isnan(loglik[0]):\n",
    "            loglik[0] = loglik_all[i-1][0]\n",
    "        if math.isnan(loglik[1]):\n",
    "            loglik[1] = loglik_all[i-1][1]\n",
    "            \n",
    "        loglik_all.append(loglik)\n",
    "        \n",
    "    loglik_list = sum(loglik_all,[])\n",
    "  \n",
    "    distance = list( map(lambda x: abs(x - mean), loglik_list) )\n",
    "    \n",
    "    distance_array = np.array(distance)\n",
    "    #距离大于threshold的正样本个数\n",
    "    out_num = np.sum((distance_array > threshold))  \n",
    "    \n",
    "    return out_num\n",
    "\n",
    "def estimate(exp_dir, param_filename, stdout=None, stderr=None):\n",
    "    if stdout is not None:\n",
    "        sys.stdout = open(stdout, 'w')\n",
    "    if stderr is not None:\n",
    "        sys.stderr = open(stderr, 'w')\n",
    "    print('\\nStart time is: ', datetime.datetime.today())\n",
    "   \n",
    "    data_fileName = \"./data/DSL-StrongPasswordData.xls\"\n",
    "    #events = make_data('s036',12000,12400,data_fileName)\n",
    "    events = make_data('s047',16000,16400,data_fileName)\n",
    "    #events = make_data('s052',18000,18400,data_fileName)\n",
    "    #events = make_data('s032',10400,10800,data_fileName)\n",
    "    #events = make_data('s010',2400,2800,data_fileName)\n",
    "    #events = make_data('s008',2000,2400,data_fileName)\n",
    "    #events = make_data('s007',1600,2000,data_fileName)\n",
    "    #events = make_data('s005',1200,1600,data_fileName)\n",
    "    #events = make_data('s004',800,1200,data_fileName)\n",
    "    #events = make_data('s003',400,800,data_fileName)\n",
    "    #events = make_data('s002',0,400,data_fileName)\n",
    "    n_jumps_per_dim = list(map(len, events[0]))\n",
    "    n_nodes = len(events[0])\n",
    "    #print('Number of jumps:', len(events)*sum(n_jumps_per_dim))\n",
    "    #print('per node:', n_jumps_per_dim)\n",
    "    \n",
    "    events = torch.tensor(events, dtype=torch.float32)\n",
    "    \n",
    "    #print('\\nestimating')\n",
    "    #print('=========')\n",
    "\n",
    "    param_filename = os.path.join(exp_dir, param_filename)\n",
    "    if not os.path.exists(param_filename):\n",
    "        raise FileNotFoundError(\n",
    "            'Input file `{:s}` not found.'.format(param_filename))\n",
    "    with open(param_filename, 'r') as param_file:\n",
    "        param_dict = json.load(param_file)\n",
    "        \n",
    "    mu = torch.tensor(param_dict['vi_exp']['mu'],dtype=torch.float32)\n",
    "    W = torch.tensor(param_dict['vi_exp']['adjacency'],dtype=torch.float32)\n",
    "    \n",
    "    #W = W.view(n_nodes,n_nodes)\n",
    "    \n",
    "    #print('mu:',mu)\n",
    "    #print('W:',W)\n",
    "    \n",
    "    #nu = -1.3839905543829933\n",
    "    #sigma = 0.2960047784292162\n",
    "    \n",
    "    nu = param_dict['vi_exp']['nu']\n",
    "    sigma = param_dict['vi_exp']['sigma']\n",
    "    \n",
    "    #threshold_range = np.linspace(1,6,20)\n",
    "    threshold_range = np.linspace(0.1,6,20)\n",
    "    FN = [0]*len(threshold_range)\n",
    "    TP = [0]*len(threshold_range)\n",
    "    FP = [0]*len(threshold_range)\n",
    "    TN = [0]*len(threshold_range)\n",
    "    \n",
    "    false_alarm_rate = [0.0]*len(threshold_range)\n",
    "    miss_rate = [0.0]*len(threshold_range)\n",
    "    recall = [0.0]*len(threshold_range)\n",
    "    precision = [0.0]*len(threshold_range)\n",
    "    #hit_rate = [0.0]*len(threshold_range)\n",
    "    \n",
    "    all_events = make_data_all(data_fileName,)\n",
    "    all_events = torch.tensor(all_events, dtype=torch.float32)\n",
    "    \n",
    "    for i,threshold in enumerate(threshold_range):\n",
    "        mean,out_num = decision_fun_1(mu=mu, W=W, new_events=events, M=1 ,param_dict=param_dict_exitation,nu=nu, sigma=sigma,\n",
    "                                      threshold=threshold)\n",
    "        out_num_all = decision_fun_2(mu=mu, W=W, new_events=all_events, M=1 ,param_dict=param_dict_exitation,nu=nu, sigma=sigma,\n",
    "                                     threshold=threshold, mean=mean)\n",
    "        \n",
    "        FN[i] = out_num\n",
    "        TP[i] = 800-out_num                         #400*2-out_num\n",
    "        FP[i] = 40000 -  out_num_all +   out_num    #20400*2 - out_num_all - 800 + out_num\n",
    "        TN[i] = out_num_all - out_num\n",
    "        \n",
    "        false_alarm_rate[i] = FP[i]/(FP[i]+TN[i])\n",
    "        miss_rate[i] = FN[i]/(TP[i]+FN[i])\n",
    "        recall[i] = TP[i]/(TP[i]+FN[i])\n",
    "        precision[i] = TP[i]/(TP[i]+FP[i])\n",
    "    \n",
    "    print('FN is:', FN)\n",
    "    print('TP is:', TP)\n",
    "    print('FP is:', FP)\n",
    "    print('TN is:', TN)\n",
    "    \n",
    "    print('false_alarm_rate is:',false_alarm_rate)\n",
    "    print('miss_rate is:',miss_rate)\n",
    "    \n",
    "    #画false-alarm/hit rate ROC图\n",
    "    hit_rate = list( map(lambda x: 1 - x, miss_rate) )\n",
    "    print('hit_rate is:',hit_rate)\n",
    "    plt.plot(false_alarm_rate,hit_rate,color=\"blue\",linewidth=1)\n",
    "    plt.plot(false_alarm_rate,false_alarm_rate,color=\"red\",linewidth=1)\n",
    "  \n",
    "    print('\\n\\nFinished.')\n",
    "    print('\\nEnd time is: ', datetime.datetime.today())\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('-d', '--dir', dest='dir', type=str,\n",
    "                        #required=True, help=\"Working directory\")\n",
    "                        required=False, default=\".\")\n",
    "    parser.add_argument('-p', '--params', dest='param_filename', type=str,\n",
    "                        required=False, default='params.json',\n",
    "                        help=\"Input parameter file (JSON)\")\n",
    "    args = parser.parse_known_args()[0]\n",
    "    estimate ('.','./result/2/penalty10+decay0.3+1e-04+c1+epsilon=-3.0/penalty10_decay0.3+s047_16000-16200.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
