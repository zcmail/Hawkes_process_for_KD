{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Experiment parameters\n",
      "=====================\n",
      "        exp_dir = .\n",
      " param_filename = params.json\n",
      "output_filename = output_varhawkes_train_samples_s002_0-40+mu.json\n",
      "\n",
      "Number of jumps: 880\n",
      "per node: [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n",
      "\n",
      "INFERENCE\n",
      "=========\n",
      "\n",
      "Run VI (vi_exp)\n",
      "------\n",
      "vi random seed: 40641\n",
      "\n",
      "\n",
      "\n",
      "Save results...\n",
      "coeffs: [-0.017805686293615834, 0.01364045031379783, 0.24161237760245424, 0.01354151839841178, -0.06363725227243722, 0.060242828006224984, 0.13548132015013983, 0.029342960692882405, 0.0294020453336555, 0.01193960350791918, 0.1573738080219819, -0.008300949479983449, 0.17969136744068281, -0.06939944561032865, -0.0620753925241238, 0.06027491153753493, 0.11557502046247817, 0.09733564010797163, -0.033925987849552926, 0.0048700009297416545, -0.09340218923520274, 0.2394747927060562, -0.054443072701731404, 0.09332893072408494, 0.028187901146683746, 0.001966227721955814, -0.22066058076883352, 0.17010698561719087, 0.007699561573439852, 0.1641319068816377, 0.1148557838538607, 0.07438324613216929, 0.15926453432503512, 0.17636505367550182, -0.005589111684088264, -0.0019347894221227319, -0.022697871697527076, 0.05852573896488319, -0.153711725934437, -0.089694390835838, 0.24569936715234103, 0.17444767428887276, -0.06808166502333941, -0.0976949545324994, 0.0897560489224152, 0.23577800858713072, 0.20968795072161292, -0.13932840777793548, 0.03644600637969134, 0.1596416405068976, 0.05384925796859368, -0.040590561783705924, -0.2224188293099124, 0.07516029178556395, 0.08659878293886276, -0.1689062299337767, -0.017620818895500087, 0.2397103921768095, 0.035457711890876084, 0.14887857976911004, 0.03594041511690235, 0.08992171838375813, 0.06199872700692788, 0.1595640089042871, 0.08184179411803572, 0.1660597199702133, 0.049164544993194545, 0.1046636277411903, 0.15806782915814102, 0.01292817353798388, 0.004319263217256772, 0.1097075893992063, 0.06866809695055989, -0.01235098395294957, 0.14307348341257353, 0.228533075235043, 0.29501409433781567, 0.09897086692808242, 0.002340940015916013, 0.05377369629555127, 0.04691456657792885, -0.02450937833297319, -0.04780720126627126, -0.07707094200893778, 0.14483037312028063, 0.01714321874568251, -0.05408241967988901, 0.20121147739817097, 0.06299016455525235, 0.13623536098835276, 0.02640268806528398, 0.0033797876658539904, 0.21086793080575747, 0.03811450955326562, 0.16275477282094, 0.2531398041312958, 0.22590106021810608, 0.12275778198549184, 0.17192703519191677, 0.06119363268022838, 0.12385886281726284, 0.08124104259504565, 0.173630862031642, 0.2125539630950998, 0.16718454288455548, 0.17129046432137057, -0.05739653625733551, 0.06729282912580849, 0.1490706641510578, 0.12280157824092242, -0.024940281404116374, 0.04969735533054171, 0.11741835602256892, -0.06896369062417175, 0.09729555462404273, 0.04502668809940186, 0.1416983691415181, 0.006670718565801339, 0.07126341044048884, 0.1193740956153213, -0.12638032614808306, 0.12209545359588808, 0.12522419544222918, 0.02076312269970324, 0.14058907054957565, -0.04840218893554574, -0.07474794087201417, 0.1712470122411643, 0.09175947969342338, 0.1484199009768968, 0.15218698008487214, -0.03274877636667815, -2.0316923752597065, -1.467790899672849, -1.616440771877109, -1.3785582990897878, -1.7572705799524284, -1.494530985153094, -1.551619637588817, -1.2624858586874452, -1.88208217679783, -1.5248401489038295, -2.2876598246959947, -1.0911255895691792, -2.3223350342135403, -1.8045497882770776, -1.6935575004204255, -1.7636376985192173, -2.019475898816003, -1.6931560121239677, -1.993872980253817, -1.7004476879524553, -1.3624262960180737, -1.439244231295547, -1.6760864123225292, -1.1396290422577005, -1.1034879945768448, -2.172548469627515, -2.2343112674067354, -1.902411874445521, -2.28322093624295, -0.9618365813627663, -1.0646564892818084, -1.316557317018041, -1.361327260457763, -0.9983883961392205, -2.284125455735343, -1.6281906678235836, -1.2044503294193627, -1.9858537829915903, -2.31528714742999, -1.6479205299882447, -1.560288994311187, -0.9107952876273872, -2.2829784374236812, -1.7035036176756884, -2.3165790735702303, -2.289757967685549, -1.5150102172898314, -1.8417817011180522, -2.3225197142603284, -1.8582090015290207, -1.4741072990132287, -1.7991452355124915, -1.114145062849985, -2.2012308136041385, -1.8941097774908386, -1.904767279605359, -1.2657922429241324, -1.511171559432255, -1.5492147780931091, -1.865127712539765, -2.3106066887817716, -0.9212964451418413, -2.14712354454672, -1.54853085610296, -2.177472137830432, -1.2093205548634516, -1.7391448177794735, -1.6447957647712923, -2.282857219835575, -1.6277462341425715, -2.3077893801505103, -2.2874119470086147, -1.4763378699005254, -1.7498816114093605, -2.2826014889508945, -1.650706197033607, -2.2830558084612846, -1.0701667960765098, -1.6516169615536376, -2.020409836723931, -1.3878554279580255, -2.306085800478251, -2.3225937243253556, -2.28652153687188, -2.2830524529235396, -1.476471602375243, -1.948465644604108, -1.4006039260532328, -1.5131271951354188, -2.280360173903233, -1.4356849105119576, -2.3131369838056024, -1.2896963241481212, -1.127677831892026, -1.7099611312812693, -1.191871961518698, -1.3554080895372709, -2.0366362892812813, -1.759539649173218, -1.319155149441844, -1.5421655891693795, -2.2831065651200175, -2.310066498513792, -0.9393121372356634, -1.1556440321687649, -1.368586227251286, -2.20953794743706, -2.3204296208439636, -0.8600629340808509, -1.5939198792304845, -2.3141574728243466, -1.3198570337746747, -1.8317000168648012, -1.6897452649118014, -2.283154228567076, -1.6078273045224467, -2.29777397070887, -1.8777821030665787, -2.2276770442055565, -2.3063338281004335, -1.7591697360136873, -1.263205656227999, -1.4832413077667055, -1.823417826113824, -1.5338703318117766, -1.4491299425792514, -1.7699794543619758, -2.182920877638707, -1.5445586433320495, -2.2993096526075734, -1.384774538880978, -1.6780377904839454]\n",
      "adjacency: [0.8859557354565415, 1.1853980990930142, 0.9080319974099629, 0.9085717123707577, 1.0313720905950199, 1.1029176667618827, 1.065562061160255, 0.9488852085821926, 0.9719281463305239, 0.8530321389096871, 1.2011207940321826, 0.914432817571519, 0.9910094683231884, 0.9214147803585959, 0.9890562996569736, 0.7928480611535356, 1.1593318698303607, 0.9973083103795012, 1.0182265811543416, 0.9959450617356461, 1.0025321331208163, 1.0980813327915557, 1.0414280048749809, 0.9841615641055692, 0.9603453171698385, 0.8934973071465678, 1.040482456392727, 0.8491997151919091, 0.8809703817228356, 1.2233190697178384, 1.0127601574839273, 0.9245190819807143, 0.8773623627060851, 1.0833217856203383, 1.252971771659624, 1.1751235604476513, 0.8483502795622558, 1.027200207133392, 1.1449039087635708, 1.001417024166909, 0.9342968778620022, 0.7188293616025029, 1.0649343317684654, 1.0660528634855653, 0.8260791226165033, 0.9074165068615461, 1.2104877614400686, 0.9903842366482057, 1.1330259340730362, 1.0264431432165866, 0.9338079853997818, 1.0495399069902114, 1.1211806079184745, 1.071434750793363, 1.0800606377793958, 1.018472949293059, 1.0697174606521809, 1.1591249703121576, 0.9746921007381808, 0.9944383327988803, 1.1045074346159822, 1.0166046003364535, 0.9583372588142854, 1.1418682273501433, 1.2113094501016095, 1.3292512057596506, 0.9815280039278753, 0.9661625934647463, 1.036853495630743, 0.9847272257180759, 0.9661466847680408, 0.9442022104395255, 0.9163128534053723, 1.1438868600372534, 0.9655642174527527, 0.928312791571981, 1.1508201015440347, 1.0145987514406938, 1.1340336013111256, 0.9702333937596372, 0.9936091232966443, 1.1445915990573268, 0.935455463939002, 1.1388737036766385, 1.1746087119510096, 1.172828716531384, 1.1115286046023183, 1.152922859891981, 0.9897644256857305, 1.0812288662946488, 1.073413528692911, 1.1779544017353298, 1.0615751447684276, 1.0704199668969112, 1.112419400528683, 0.9329143391912504, 1.0593371965004048, 0.9704717878984962, 1.0849573418796625, 0.9658840416619475, 0.9785490930657939, 1.0961161795412857, 0.9021012668908035, 1.0907868181995144, 1.0049096447208081, 1.1406538861015934, 0.9834224128410427, 1.0614620014182958, 1.1156629363266795, 0.8555344198640908, 1.043050975150361, 1.076526994745739, 0.994703693836307, 1.0986288652064709, 0.9016568721875079, 0.9014393997500457, 1.171802375313922, 1.0473020093281311, 1.148382208969852, 1.0936237388711914, 0.9346149816299203]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'mu' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-3b20aac8861c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    371\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    372\u001b[0m     \u001b[1;31m#run(exp_dir=args.dir, param_filename=args.param_filename,output_filename=args.output_filename)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 373\u001b[1;33m     \u001b[0mrun\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'.'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'params.json'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'output_varhawkes_train_samples_s002_0-40+mu.json'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-5-3b20aac8861c>\u001b[0m in \u001b[0;36mrun\u001b[1;34m(exp_dir, param_filename, output_filename, stdout, stderr)\u001b[0m\n\u001b[0;32m    347\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'coeffs:'\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[0mcoeffs_var\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    348\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m \u001b[1;34m'adjacency:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0madj_var\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 349\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'mu:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    350\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    351\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexp_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_filename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'w'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0moutput_file\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'mu' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import argparse\n",
    "import json\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# External libraries\n",
    "from tick.hawkes.simulation import SimuHawkesExpKernels\n",
    "from tick.hawkes.inference import HawkesADM4, HawkesSumGaussians\n",
    "import torch\n",
    "from torch import optim\n",
    "\n",
    "# Internal libraries\n",
    "'''\n",
    "from varhawkes import models\n",
    "from varhawkes import posteriors\n",
    "from varhawkes import priors\n",
    "from varhawkes import hawkes_model, excitation_kernels\n",
    "from varhawkes import learners\n",
    "from varhawkes import utils\n",
    "from varhawkes.utils import metrics\n",
    "'''\n",
    "import models\n",
    "import posteriors\n",
    "import priors\n",
    "import hawkes_model, excitation_kernels\n",
    "import learners\n",
    "import utils\n",
    "\n",
    "from make_data_for_samples import make_data              #多个样本数据\n",
    "from make_data_for_estimate import make_estimate_data    #单个样本数据\n",
    "\n",
    "THRESHOLD = 0.03\n",
    "\n",
    "\n",
    "def make_object(module, name, args):\n",
    "    return getattr(module, name)(**args)\n",
    "\n",
    "'''\n",
    "class LearnerCallback:\n",
    "    \n",
    "    def __init__(self, x0, adjacency_true, acc_thresh=0.01, print_every=10, line_return=False):\n",
    "        self.print_every = print_every\n",
    "        self.last_coeffs = x0.clone()\n",
    "        self.adjacency_true = adjacency_true.ravel()\n",
    "        self.acc_thresh = acc_thresh\n",
    "        self.default_end = \"\\n\" if line_return else \"\"\n",
    "\n",
    "\n",
    "    def __call__(self, learner_obj, end=None):\n",
    "        t = learner_obj._n_iter_done + 1\n",
    "        if t % self.print_every == 0:\n",
    "            # Extract number of parameters\n",
    "            n_nodes = learner_obj.dim\n",
    "            n_params = learner_obj.model.n_params  # n_nodes * (learner_obj.model.excitation.M*n_nodes + 1)\n",
    "            # Split parameters\n",
    "            xt = learner_obj.coeffs.detach()\n",
    "            alpha, beta = xt[:n_params], xt[n_params:]\n",
    "            # Compute mode estimator\n",
    "            z = learner_obj.model.posterior.mode(alpha, beta)\n",
    "            \n",
    "            x_diff = torch.abs(self.last_coeffs - xt).max()\n",
    "            self.last_coeffs = xt.clone()\n",
    "            adj_learned = z[n_nodes:].cpu().numpy().reshape(n_nodes, n_nodes, learner_obj.model.model.excitation.M).sum(2).flatten()\n",
    "            \n",
    "\n",
    "            f1score = metrics.fscore(adj_learned, self.adjacency_true, self.acc_thresh, 1.0)\n",
    "            precat20 = metrics.precision_at_n(adj_learned, self.adjacency_true, n=20)\n",
    "            precat50 = metrics.precision_at_n(adj_learned, self.adjacency_true, n=50)\n",
    "            precat100 = metrics.precision_at_n(adj_learned, self.adjacency_true, n=100)\n",
    "            relerr = metrics.relerr(adj_learned, self.adjacency_true)\n",
    "\n",
    "            \n",
    "            end = end = self.default_end if end is None else end\n",
    "\n",
    "            print(f\"\\riter: {t:>5d} | f1-score: {f1score:.2f} | relerr: {relerr:.3f} | p@20-50-100: {precat20:.2f} {precat50:.2f} {precat100:.2f} | \"\n",
    "                  f\"dx: {x_diff:.2e}\"\n",
    "                  \"    \", end=end, flush=True)\n",
    "'''\n",
    "\n",
    "'''\n",
    "def generate_data(adjacency, decay, baseline, n_jumps, sim_seed=None, verbose=False):\n",
    "    # Set random seed (for reproducibility)\n",
    "    if sim_seed is None:\n",
    "        sim_seed = np.random.randint(2**31)\n",
    "    # Simulate data\n",
    "    hawkes_simu = SimuHawkesExpKernels(adjacency=adjacency, decays=decay, baseline=baseline,\n",
    "                                       max_jumps=n_jumps, seed=sim_seed, verbose=verbose)\n",
    "    hawkes_simu.simulate()\n",
    "    return hawkes_simu.timestamps, hawkes_simu.end_time, sim_seed\n",
    "\n",
    "\n",
    "def learn_adm4(events, end_time, return_learner=False, verbose=False, **kwargs):\n",
    "    learner_mle = HawkesADM4(**kwargs, verbose=verbose)\n",
    "    learner_mle.fit(events, end_time)\n",
    "    if return_learner:\n",
    "        return learner_mle\n",
    "    return learner_mle.baseline, learner_mle.adjacency\n",
    "\n",
    "\n",
    "def learn_sum_gaussians(events, end_time, return_learner=False, verbose=False, **kwargs):\n",
    "    learner_mle = HawkesSumGaussians(**kwargs, verbose=verbose)\n",
    "    learner_mle.fit(events, end_time)\n",
    "    if return_learner:\n",
    "        return learner_mle\n",
    "    return learner_mle.baseline, learner_mle.amplitudes\n",
    "'''\n",
    "\n",
    "\n",
    "#def learn_vi(events, end_time, vi_seed, adjacency_true, inference_param_dict, return_learner=False):\n",
    "def learn_vi(events, vi_seed, inference_param_dict, return_learner=False):\n",
    "    # Extract some parameters for easier access\n",
    "    #n_nodes = len(events)\n",
    "    n_nodes = len(events[0])\n",
    "    M = inference_param_dict['excitation']['args'].get('M', 1)\n",
    "    n_params = n_nodes * (n_nodes * M + 1)\n",
    "    n_edges = M * n_nodes ** 2\n",
    "    # Set seed\n",
    "    np.random.seed(vi_seed)\n",
    "    # Set starting pointM * n_nodes ** 2\n",
    "    x0 = torch.tensor(\n",
    "        np.hstack((\n",
    "            np.hstack((  # alpha, the mean of the parameters\n",
    "                np.random.normal(loc=0.1, scale=0.1, size=n_nodes),\n",
    "                np.random.normal(loc=0.1, scale=0.1, size=n_edges),)),\n",
    "            np.hstack((  # beta=log(sigma), log of the variance of the parameters\n",
    "                np.log(np.clip(np.random.normal(loc=0.2, scale=0.1, size=n_nodes), 1e-1, 2.0)),\n",
    "                np.log(np.clip(np.random.normal(loc=0.2, scale=0.1, size=n_edges), 1e-1, 2.0)),))\n",
    "        )),\n",
    "        dtype=torch.float64, requires_grad=True\n",
    "    )\n",
    "    # Init Hawkes process model object\n",
    "    excitation_obj = make_object(excitation_kernels, **inference_param_dict['excitation'])\n",
    "    hawkes_model_obj = hawkes_model.HawkesModel(excitation=excitation_obj, verbose=False)\n",
    "    # Init the posterior object\n",
    "    posterior_obj = make_object(posteriors, **inference_param_dict['posterior'])\n",
    "    # Init the prior object\n",
    "    prior_type = inference_param_dict['prior']['name']\n",
    "    prior_args = inference_param_dict['prior']['args']\n",
    "    prior_args['C'] = torch.tensor(prior_args['C'], dtype=torch.float64)  # cast to tensor\n",
    "    prior_obj = make_object(priors, prior_type, prior_args)\n",
    "    # Init the variational inference model object\n",
    "    model = models.ModelHawkesVariational(\n",
    "        model=hawkes_model_obj, posterior=posterior_obj, prior=prior_obj,\n",
    "        **inference_param_dict['model']['args'])\n",
    "    \n",
    "    # Init callback object (for monitoring purposes)\n",
    "    '''\n",
    "    callback = LearnerCallback(x0=x0.detach(), adjacency_true=adjacency_true,\n",
    "                               acc_thresh=THRESHOLD, print_every=100, line_return=False)\n",
    "    '''\n",
    "    \n",
    "    # Init the optimizer\n",
    "    opt_type = inference_param_dict['optimizer']['name']\n",
    "    opt_args = inference_param_dict['optimizer']['args']\n",
    "    opt = getattr(optim, opt_type)([x0], **opt_args)\n",
    "    # Init learner\n",
    "    learner = learners.VariationalInferenceLearner(\n",
    "        model=model, optimizer=opt, **inference_param_dict['learner']['args'])\n",
    "    # Fit the model\n",
    "    events_t = [torch.tensor(events_i) for events_i in events]  # cast to tensor\n",
    "    #learner.fit(events_t, end_time, x0, callback=callback)\n",
    "    learner.fit(events_t, x0=x0, callback=None)\n",
    "    print()\n",
    "    if return_learner:\n",
    "        return learner\n",
    "    # Extract the mode of the posterior\n",
    "    z_est_mode = learner.model.posterior.mode(learner.coeffs[:n_params], learner.coeffs[n_params:])\n",
    "    adj_est = z_est_mode[n_nodes:].detach().numpy()\n",
    "    adj_est = np.reshape(adj_est, (n_nodes, n_nodes, M)).sum(-1).ravel()\n",
    "    mu_est = z_est_mode[:n_nodes].detach().numpy()\n",
    "    #mu_est = np.reshape(mu_est,n_nodes).ravel()\n",
    "    coeffs_est = learner.coeffs.detach().numpy()\n",
    "    return coeffs_est, adj_est,mu_est\n",
    "\n",
    "\n",
    "def run(exp_dir, param_filename, output_filename, stdout=None, stderr=None):\n",
    "    # Reset random seed\n",
    "    np.random.seed(None)\n",
    "\n",
    "    if stdout is not None:\n",
    "        sys.stdout = open(stdout, 'w')\n",
    "    if stderr is not None:\n",
    "        sys.stderr = open(stderr, 'w')\n",
    "\n",
    "    print('\\nExperiment parameters')\n",
    "    print('=====================')\n",
    "    print(f'        exp_dir = {exp_dir:s}')\n",
    "    print(f' param_filename = {param_filename:s}')\n",
    "    print(f'output_filename = {output_filename:s}')\n",
    "    print(flush=True)\n",
    "\n",
    "    '''\n",
    "    # Load parameters from file\n",
    "    param_filename = os.path.join(exp_dir, param_filename)\n",
    "    if not os.path.exists(param_filename):\n",
    "        raise FileNotFoundError(\n",
    "            'Input file `{:s}` not found.'.format(param_filename))\n",
    "    with open(param_filename, 'r') as param_file:\n",
    "        param_dict = json.load(param_file)\n",
    "    '''\n",
    "\n",
    "    result_dict = {}\n",
    "    \n",
    "    '''\n",
    "    print('\\nSIMULATION')\n",
    "    print('==========')\n",
    "    print(flush=True)\n",
    "\n",
    "    n_jumps = param_dict['simulation']['n_jumps']\n",
    "    adjacency = np.array(param_dict['simulation']['adjacency'])\n",
    "    decay = param_dict['simulation']['decay']\n",
    "    baseline = np.array(param_dict['simulation']['baseline'])\n",
    "    sim_seed = param_dict['simulation'].get('sim_seed')\n",
    "\n",
    "    print('\\ndecay:')\n",
    "    print(decay)\n",
    "    print('baseline:')\n",
    "    print(baseline.round(2))\n",
    "    print('adjacency:')\n",
    "    print(adjacency.round(2))\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    print('\\nGenerate data...')\n",
    "    # Simulate data\n",
    "    events, end_time, sim_seed = generate_data(adjacency=adjacency, decay=decay, baseline=baseline,\n",
    "                                               n_jumps=n_jumps, sim_seed=sim_seed)\n",
    "    n_jumps_per_dim = list(map(len, events))\n",
    "    print(f'simulation random seed: {sim_seed}')\n",
    "    print()\n",
    "    print('Number of jumps:', sum(n_jumps_per_dim))\n",
    "    print('per node:', n_jumps_per_dim)\n",
    "\n",
    "    result_dict.update({\n",
    "        'sim_seed': sim_seed,  # Simulation random seed\n",
    "        'n_jumps': n_jumps,    # Number of arrivals\n",
    "    })\n",
    "    '''\n",
    "    '''\n",
    "    替换Generate data，用keystroke data\n",
    "    '''\n",
    "    data_fileName = \"./data/DSL-StrongPasswordData.xls\"\n",
    "    #events,end_time = make_estimate_data('s002',0,data_fileName)\n",
    "    events = make_data('s002',0,40,data_fileName)\n",
    "    #end_time = None\n",
    "    n_jumps_per_dim = list(map(len, events[0]))\n",
    "    print('Number of jumps:', len(events)*sum(n_jumps_per_dim))\n",
    "    print('per node:', n_jumps_per_dim)\n",
    "    \n",
    "    C_list = [0.1]*132\n",
    "    \n",
    "    param_dict={'inference':{'vi_exp':{'excitation': {'name': 'ExponentialKernel','args': {'decay': 1.0, 'cut_off': 1000.0}}, \n",
    "                          'posterior': {'name': 'LogNormalPosterior', 'args': {}},\n",
    "                          'prior': {'name': 'GaussianLaplacianPrior', 'args': {'dim': 11, 'n_params': 132, 'C': C_list}}, \n",
    "                          'model': {'args': {'n_samples': 1, 'n_weights': 1, 'weight_temp': 1.0}}, \n",
    "                          'optimizer': {'name': 'Adam', 'args': {'lr': 0.01}}, \n",
    "                          'learner': {'args': {'tol': 1e-05, 'lr_gamma': 0.9999, 'max_iter': 2, 'hyperparam_momentum': 0.5, 'hyperparam_interval': 100, 'hyperparam_offset': 0}}}}\n",
    "               }\n",
    "    \n",
    "\n",
    "    print('\\nINFERENCE')\n",
    "    print('=========')\n",
    "\n",
    "    for key, inference_param_dict in param_dict['inference'].items():\n",
    "\n",
    "        '''\n",
    "        if key == 'adm4':\n",
    "            print('\\nRun ADM4')\n",
    "            print('-------')\n",
    "            print()\n",
    "            baseline_adm4, adj_adm4 = learn_adm4(events, end_time, **inference_param_dict)\n",
    "            adj_adm4 = adj_adm4.ravel()\n",
    "            print('  relerr:', utils.metrics.relerr(adj_adm4, adjacency.ravel()))\n",
    "            print('      f1:', utils.metrics.fscore(adj_adm4, adjacency.ravel(),\n",
    "                                                    threshold=THRESHOLD, beta=1.0))\n",
    "            print(' prec@20:', utils.metrics.precision_at_n(adj_adm4, adjacency.ravel(), n=20))\n",
    "            print(' prec@50:', utils.metrics.precision_at_n(adj_adm4, adjacency.ravel(), n=50))\n",
    "            print('prec@100:', utils.metrics.precision_at_n(adj_adm4, adjacency.ravel(), n=100))\n",
    "\n",
    "            result_dict.update({\n",
    "                key: {\n",
    "                    'baseline': baseline_adm4.tolist(),  # ADM4 Baseline Estimator\n",
    "                    'adjacency': adj_adm4.tolist(),      # ADM4 Adjacencey Estimator\n",
    "                }\n",
    "            })\n",
    "\n",
    "        if key == 'sum_gaussians':\n",
    "            print('\\nRun Sum-Gaussians')\n",
    "            print('-------')\n",
    "            print()\n",
    "            baseline_sumgauss, adj_sumgauss = learn_sum_gaussians(\n",
    "                events, end_time, **inference_param_dict)\n",
    "            adj_sumgauss = adj_sumgauss.sum(axis=-1).ravel()\n",
    "            print('  relerr:', utils.metrics.relerr(adj_sumgauss, adjacency.ravel()))\n",
    "            print('      f1:', utils.metrics.fscore(adj_sumgauss, adjacency.ravel(),\n",
    "                                                    threshold=THRESHOLD, beta=1.0))\n",
    "            print(' prec@20:', utils.metrics.precision_at_n(adj_sumgauss, adjacency.ravel(), n=20))\n",
    "            print(' prec@50:', utils.metrics.precision_at_n(adj_sumgauss, adjacency.ravel(), n=50))\n",
    "            print('prec@100:', utils.metrics.precision_at_n(adj_sumgauss, adjacency.ravel(), n=100))\n",
    "\n",
    "            result_dict.update({\n",
    "                key: {\n",
    "                    'baseline': baseline_sumgauss.tolist(),  # sum_gaussians Baseline Estimator\n",
    "                    'adjacency': adj_sumgauss.tolist(),      # sum_gaussians Adjacencey Estimator\n",
    "                }\n",
    "            })\n",
    "        '''\n",
    "\n",
    "        if key.startswith('vi'):\n",
    "            print(f'\\nRun VI ({key:s})')\n",
    "            print('------')\n",
    "            # Set random seed (for reproducibility)\n",
    "            np.random.seed()  # Reset random number generator to avoid dependency on simulation seed\n",
    "            #vi_seed = np.random.randint(2**32 - 1)\n",
    "            vi_seed = np.random.randint(2**16 - 1)\n",
    "            print(f'vi random seed: {vi_seed}')\n",
    "            # Run inference\n",
    "            #coeffs_var, adj_var = learn_vi(events, end_time, vi_seed, adjacency.ravel(),inference_param_dict)\n",
    "            coeffs_var, adj_var, mu_var = learn_vi(events, vi_seed, inference_param_dict)\n",
    "            adj_var = adj_var.ravel()\n",
    "            mu_var = mu_var.ravel()\n",
    "            \n",
    "            '''\n",
    "            print()\n",
    "            print('  relerr:', utils.metrics.relerr(adj_var, adjacency.ravel()))\n",
    "            print('      f1:', utils.metrics.fscore(adj_var, adjacency.ravel(),\n",
    "                                                    threshold=THRESHOLD, beta=1.0))\n",
    "            print(' prec@20:', utils.metrics.precision_at_n(adj_var, adjacency.ravel(), n=20))\n",
    "            print(' prec@50:', utils.metrics.precision_at_n(adj_var, adjacency.ravel(), n=50))\n",
    "            print('prec@100:', utils.metrics.precision_at_n(adj_var, adjacency.ravel(), n=100))\n",
    "            '''\n",
    "          \n",
    "            result_dict.update({\n",
    "                key: {\n",
    "                    'vi_seed': vi_seed,             # VI random seed\n",
    "                    'coeffs': coeffs_var.tolist(),  # VI parameters\n",
    "                    'adjacency': adj_var.tolist(),  # VI Estimator\n",
    "                    'mu':  mu_var.tolist(),\n",
    "                }\n",
    "            })\n",
    " \n",
    "\n",
    "    print('\\n\\nSave results...')\n",
    "    \n",
    "    print('coeffs:',  coeffs_var.tolist())\n",
    "    print( 'adjacency:', adj_var.tolist())\n",
    "    print('mu:', mu_var.tolist())\n",
    "\n",
    "    with open(os.path.join(exp_dir, output_filename), 'w') as output_file:\n",
    "        json.dump(result_dict, output_file)\n",
    "\n",
    "    # Log that the run is finished\n",
    "    print('\\n\\nFinished.')\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('-d', '--dir', dest='dir', type=str,\n",
    "                        #required=True, help=\"Working directory\")\n",
    "                        required=False, default=\".\")\n",
    "    parser.add_argument('-p', '--params', dest='param_filename', type=str,\n",
    "                        required=False, default='params.json',\n",
    "                        help=\"Input parameter file (JSON)\")\n",
    "    parser.add_argument('-o', '--outfile', dest='output_filename', type=str,\n",
    "                        required=False, default='output.json',\n",
    "                        help=\"Output file (JSON)\")\n",
    "    #args = parser.parse_args()\n",
    "    args = parser.parse_known_args()[0]\n",
    "\n",
    "    #run(exp_dir=args.dir, param_filename=args.param_filename,output_filename=args.output_filename)\n",
    "    run ('.','params.json','output_varhawkes_train_samples_s002_0-40+mu.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
