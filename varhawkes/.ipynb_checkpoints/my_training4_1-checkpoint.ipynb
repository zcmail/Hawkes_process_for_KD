{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Experiment parameters\n",
      "=====================\n",
      "        exp_dir = .\n",
      " param_filename = params.json\n",
      "output_filename = penalty10_decay0.1+s002_300-350.json\n",
      "\n",
      "\n",
      "Start time is:  2020-03-13 08:06:45.004038\n",
      "\n",
      "Number of jumps: 1100\n",
      "\n",
      "per node: [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n",
      "\n",
      "INFERENCE\n",
      "=========\n",
      "\n",
      "Run VI (vi_exp)\n",
      "------\n",
      "vi random seed: 1258\n",
      "end_iter is: 37948\n",
      "Converged!\n",
      "\n",
      "\n",
      "\n",
      "Save results...\n",
      "\n",
      "coeffs: [-0.03423418515749333, -0.054619594062755246, -0.0779593392231962, -0.101298730562481, -0.13485343205787348, -0.18649470286279263, -2.614023863099442, -3.2885909564505877, -3.2603822730161514, -3.8476705471919517, -4.160009703872158, -3.705233495749414, -3.843312026026374, -3.807109946101316, -3.7583761772938065, -3.6387334304134944, -3.4687000653830844, -3.3947676680585803, -3.3073403194961712, -3.253880221369032, -3.1094856208010424, -2.9395393274527675, -2.6952103073513025, -3.6443325314333315, -3.8279028592196926, -3.7781361250588232, -3.6496534069607702, -3.4749810139073602, -3.398195753613554, -3.3175199064850647, -3.2539354183579547, -3.1122008356297486, -2.9257540254788346, -2.6991846384743123, -2.514371388782306, -3.612460340588841, -3.7364073749655984, -3.6502602889309257, -3.4740143325841277, -3.401158598710949, -3.3240927654794117, -3.2458389498076605, -3.1052912535268904, -2.917632384754774, -2.6945256557616206, -2.546423523316262, -2.4850813562979983, -3.5542468844109387, -3.638342381222478, -3.4665339109879945, -3.399408357480057, -3.3030684705546958, -3.2753265807583194, -3.1146314666629356, -2.9165297076628613, -2.8008978795859036, -2.654221773310322, -2.444760310691562, -2.2796840982909785, -3.399750964721701, -3.4736834923246462, -3.4024695200370183, -3.3005778886571018, -3.2599978486426093, -3.1175861188388314, -2.948505074533462, -2.866305577219114, -2.730866565029002, -2.569638436548579, -2.412919671258839, -1.533908909766603, -3.156348977913316, -3.390148152418599, -3.3207477368736353, -3.255001128817499, -3.09099605181427, -2.9567133193033537, -2.98981947245948, -2.868117573038452, -2.7296972871728413, -2.633699321827681, -1.9596852140487173, 1.4757385107140535, -3.0782107832984136, -3.3257211805495968, -3.2380989812474077, -3.0914250453329966, -2.9270723286415405, -3.1477231950680347, -3.0633678136740463, -2.940457395549295, -2.817516991721223, -2.340863622921681, -1.1777793771542404, 1.5368711720427202, -3.0090763173543937, -3.066236851715046, -3.102746713596875, -2.9457718377565913, -3.139756366942146, -3.0240085468796365, -2.894611870794521, -2.8048687286327074, -2.3134086463550876, -1.192669774674166, 1.430316996272717, -0.8233453070654696, -2.8970432262937535, -3.1046764022548556, -2.9480376136340407, -3.3111910822482464, -3.209380048508202, -3.134165589139601, -3.055918188261, -2.6877424276333217, -2.034140494091877, -1.6737117905271834, -0.8496058588055113, 1.6391273405490747, -2.743378622820363, -2.93578475706701, -3.417283894788189, -3.364815330679275, -3.272162690445838, -3.199623995246764, -2.930723917641563, -2.4325787997918087, -2.219001502088772, -1.8016438569646243, -1.5087112204743607, 1.8611593557898076, -2.5769719117778984, -2.380591010262871, -2.3471279934783102, -2.3204523894472286, -2.304463247594196, -2.2540604066667886, -2.2158783775652786, -0.39420625721381475, -0.17082178227581699, -0.17515478092079428, -0.05016575899533613, -0.004929385306001359, 0.009977092243984746, 0.024697065927488073, 0.015799989966656578, 0.017602695559277105, 0.00407955812412555, 0.010496313169285976, 0.01340572937972581, 0.005467405866720387, 0.016921714883949328, 0.012919861952363682, -0.0026809026949021833, -0.044322037723399696, -0.009827715253637629, -0.0017583977941514096, 0.01232238145830715, 0.006940280781452138, 0.010397320508170518, 0.01563314310168641, 0.017537295264923394, 0.01204415911571125, 0.03380274909564204, 0.02890544716753268, -0.03861431528121556, -0.07148348633880688, 0.01636317794455168, 0.005740086328198971, -0.0007582748541165134, 0.026712507799806023, 0.010219990877798894, -0.0006634591876511322, 0.007359860511525483, 0.011878765542705103, 0.021777023295282173, -0.039807591780105255, -0.05808184660709306, -0.05818397794304336, -0.005669343261959027, -0.0022687248590618297, 0.023114992646634934, 0.008021251908353115, 0.0052531937235485915, 0.002704596031989448, 0.0016037172290746012, 0.03282116077323483, -0.04465277011336495, -0.0524605736957552, -0.04438026241189287, -0.08709167270681728, 0.0026043261637735014, -0.0005147638077497161, 0.01507197808194808, -0.012061851934676515, -0.0073321166937389305, 0.003923398836205922, 0.007581928205300205, -0.008486045677874919, -0.03698640661990793, -0.04490165112402628, -0.05720963155287464, -0.22059129885308146, -0.018162914788611977, -0.008699890327201967, 0.010199911259207262, 0.0023828116442354145, -0.011313094828816228, -0.001051518786274362, -0.0040524401023066805, -0.02346577482827968, -0.03482514546784009, -0.05965441388831742, -0.12288757723420253, -2.144907197781422, 0.01833670488200988, 0.0026993137190304767, -0.015637092757235713, -0.002015671222068677, -0.0032933912882892945, -0.008248545286679385, -0.008897510758317188, -0.02066335604298091, -0.01667450490690477, -0.0704298599094076, -0.2772595574418177, -2.1271286037634183, 0.0009908745809720837, -0.016548339194263753, -0.00653873899724277, 0.0157400353166572, -0.013663181347932018, -0.0013962974542350685, 0.005849630468220213, -0.02571150763472513, -0.04216657487377389, -0.27822504059326275, -2.0463512702603905, -0.3499620018495316, 0.017530107112734727, 0.011526962730157467, 0.006976319537149649, -0.007805295355237332, 0.011922555555992267, -0.004156533271872159, -0.006514614500052998, -0.006591385017115809, -0.07228720924354431, -0.11690303843212312, -0.35698973831022157, -2.120808840941601, 0.011827249848052942, 0.018309729399878072, 0.014432358505744336, 0.005936821971218435, 0.001548205300084673, -0.0314933756091444, -0.013218339091149322, -0.03166546468060434, -0.04682551816022688, -0.06663334792729753, -0.13955949353721164, -2.169947377144323, 0.012545851987332848]\n",
      "\n",
      "adjacency: [0.008867271891075492, 0.007491798548504636, 0.007913267432831257, 0.008277546962641102, 0.009591040256136043, 0.011221602240460992, 0.012010887031413819, 0.013322044498191162, 0.013728204282548001, 0.015992073519348705, 0.019561501160278227, 0.02704152707102032, 0.009804939305657734, 0.008031433568945609, 0.008204380333583741, 0.009432154355469133, 0.011153595463582987, 0.011915014345656491, 0.012865359808976202, 0.013865989943118868, 0.015265743216851115, 0.018587450281638437, 0.02665275305548499, 0.03400818375282999, 0.009602535570023512, 0.008669417313128116, 0.009573610340468847, 0.010792625285837151, 0.012012483148992005, 0.013263137251524545, 0.014112878362130822, 0.016093605770953905, 0.01902219487811628, 0.026836367881930348, 0.03216896877305341, 0.034210283797859925, 0.010641729742275015, 0.00971761355024141, 0.010956206700334974, 0.012087538499369013, 0.013384870944069727, 0.013832278049308437, 0.016279574576026502, 0.018604079181557084, 0.024344143451162575, 0.028592315340971862, 0.03474133837954462, 0.044164810678090693, 0.012216433741721197, 0.011416969308828379, 0.011877939712632252, 0.013887823422138953, 0.014329418581515804, 0.016155999967211655, 0.01899110655290579, 0.021290875029157462, 0.02574374724520679, 0.030692117764084786, 0.03670641972949131, 0.11336028777234455, 0.01623355286312495, 0.01261461932423149, 0.013018848878185007, 0.014125436133067599, 0.017100904627185894, 0.01916609413395658, 0.018653017527812038, 0.021878075103156203, 0.025670386424433426, 0.029562961992073675, 0.06445530310858909, 4.314713998119084, 0.01631671952640427, 0.013152618603507612, 0.01488637707372959, 0.016782781685045465, 0.01983103406396603, 0.016060997906023625, 0.017496923936747406, 0.02024245820865783, 0.02271526917418608, 0.04037781514150251, 0.17340458598622274, 4.584438047099007, 0.018114183451376265, 0.017709007407652706, 0.016743345649863177, 0.0187276797983261, 0.016361897155188716, 0.017931078409471616, 0.020113182447047715, 0.023406406739940072, 0.03945740098209011, 0.17103104525580756, 4.110821718762049, 0.26714375668161583, 0.019590210613539043, 0.016115107008880986, 0.01902335117786644, 0.013627006199801242, 0.014501376145155563, 0.01614916423861382, 0.017545224537544927, 0.025358376496525593, 0.05504903183135114, 0.08498954035857738, 0.2620296909474961, 5.077114237844766, 0.02311403872074499, 0.01881533654416292, 0.011718702196552322, 0.012566009786925604, 0.01390837781538754, 0.01594547946769325, 0.020148334899633708, 0.034347996058455434, 0.04373520147567185, 0.06877771493827306, 0.10381330777170142, 6.347883533114681, 0.02725874036162851]\n",
      "\n",
      "mu: [0.9581128831926203, 0.9382233316371937, 0.9161196480267105, 0.8947049875164271, 0.8642678213256996, 0.820051381706589, 0.046486668676691704, 0.018330436581092718, 0.01897083930983259, 0.008632612945241445, 0.005798248605335753]\n",
      "\n",
      "\n",
      "Finished.\n",
      "\n",
      "End time is:  2020-03-13 13:22:15.696998\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import argparse\n",
    "import json\n",
    "import sys\n",
    "import os\n",
    "import math\n",
    "from scipy.optimize import fsolve\n",
    "from scipy import log\n",
    "import random\n",
    "import datetime\n",
    "\n",
    "\n",
    "# External libraries\n",
    "import torch\n",
    "from torch import optim\n",
    "\n",
    "# Internal libraries\n",
    "\n",
    "import models\n",
    "import posteriors\n",
    "import priors\n",
    "import hawkes_model, excitation_kernels\n",
    "import learners\n",
    "import utils\n",
    "\n",
    "from make_data_for_samples import make_data              #多个样本数据\n",
    "from make_data_for_estimate import make_estimate_data    #单个样本数据\n",
    "\n",
    "def make_object(module, name, args):\n",
    "    return getattr(module, name)(**args)\n",
    "\n",
    "#def learn_vi(events, end_time, vi_seed, adjacency_true, inference_param_dict, return_learner=False):\n",
    "def learn_vi(events, vi_seed, inference_param_dict, return_learner=False):\n",
    "    # Extract some parameters for easier access\n",
    "    #n_nodes = len(events)\n",
    "    n_events = len(events)\n",
    "    n_nodes = len(events[0])\n",
    "    M = inference_param_dict['excitation']['args'].get('M', 1)\n",
    "    n_params = n_nodes * (n_nodes * M + 1)\n",
    "    n_edges = M * n_nodes ** 2\n",
    "    # Set seed\n",
    "    np.random.seed(vi_seed)\n",
    "    # Set starting pointM * n_nodes ** 2\n",
    "    x0 = torch.tensor(\n",
    "        np.hstack((\n",
    "            np.hstack((  # alpha, the mean of the parameters\n",
    "                np.random.normal(loc=0.1, scale=0.1, size=n_nodes),\n",
    "                np.random.normal(loc=0.1, scale=0.1, size=n_edges),)),\n",
    "            np.hstack((  # beta=log(sigma), log of the variance of the parameters\n",
    "                np.log(np.clip(np.random.normal(loc=0.2, scale=0.1, size=n_nodes), 1e-1, 2.0)),\n",
    "                np.log(np.clip(np.random.normal(loc=0.2, scale=0.1, size=n_edges), 1e-1, 2.0)),))\n",
    "        )),\n",
    "        dtype=torch.float64, requires_grad=True\n",
    "    )\n",
    "    # Init Hawkes process model object\n",
    "    excitation_obj = make_object(excitation_kernels, **inference_param_dict['excitation'])\n",
    "    hawkes_model_obj = hawkes_model.HawkesModel(excitation=excitation_obj, verbose=False)\n",
    "    # Init the posterior object\n",
    "    posterior_obj = make_object(posteriors, **inference_param_dict['posterior'])\n",
    "    # Init the prior object\n",
    "    prior_type = inference_param_dict['prior']['name']\n",
    "    prior_args = inference_param_dict['prior']['args']\n",
    "    prior_args['C'] = torch.tensor(prior_args['C'], dtype=torch.float64)  # cast to tensor\n",
    "    prior_obj = make_object(priors, prior_type, prior_args)\n",
    "    # Init the variational inference model object\n",
    "    model = models.ModelHawkesVariational(\n",
    "        model=hawkes_model_obj, posterior=posterior_obj, prior=prior_obj,\n",
    "        **inference_param_dict['model']['args'])\n",
    "   \n",
    "    # Init the optimizer\n",
    "    opt_type = inference_param_dict['optimizer']['name']\n",
    "    opt_args = inference_param_dict['optimizer']['args']\n",
    "    opt = getattr(optim, opt_type)([x0], **opt_args)\n",
    "    # Init learner\n",
    "    learner = learners.VariationalInferenceLearner(\n",
    "        model=model, optimizer=opt, **inference_param_dict['learner']['args'])\n",
    "    # Fit the model\n",
    "    events_t = [torch.tensor(events_i) for events_i in events]  # cast to tensor\n",
    "    #learner.fit(events_t, end_time, x0, callback=callback)\n",
    "    learner.fit(events_t, x0=x0, callback=None)\n",
    "    print()\n",
    "    if return_learner:\n",
    "        return learner\n",
    "    # Extract the mode of the posterior\n",
    "    z_est_mode = learner.model.posterior.mode(learner.coeffs[:n_params], learner.coeffs[n_params:])\n",
    "    adj_est_ora = z_est_mode[n_nodes:].detach()\n",
    "    mu_est_ora = z_est_mode[:n_nodes].detach()\n",
    "    adj_est_ora = adj_est_ora.view(n_nodes, n_nodes, M)\n",
    "    adj_est = z_est_mode[n_nodes:].detach().numpy()\n",
    "    adj_est = np.reshape(adj_est, (n_nodes, n_nodes, M)).sum(-1).ravel()\n",
    "    mu_est = z_est_mode[:n_nodes].detach().numpy()\n",
    "    #mu_est = np.reshape(mu_est,n_nodes).ravel()\n",
    "    coeffs_est = learner.coeffs.detach().numpy()\n",
    "    #log_like_sum,min_intens,log_like,end_time = hawkes_model_obj.log_likelihood(mu_est_ora,adj_est_ora)\n",
    "    log_like_sum,intens_sum,integral_instesity,end_time = hawkes_model_obj.log_likelihood(mu_est_ora,adj_est_ora)\n",
    "    \n",
    "    return coeffs_est, adj_est,mu_est,intens_sum,integral_instesity,end_time\n",
    "\n",
    "\n",
    "def run(exp_dir, param_filename, output_filename, stdout=None, stderr=None):\n",
    "    # Reset random seed\n",
    "    np.random.seed(None)\n",
    "\n",
    "    if stdout is not None:\n",
    "        sys.stdout = open(stdout, 'w')\n",
    "    if stderr is not None:\n",
    "        sys.stderr = open(stderr, 'w')\n",
    "\n",
    "    print('\\nExperiment parameters')\n",
    "    print('=====================')\n",
    "    print(f'        exp_dir = {exp_dir:s}')\n",
    "    print(f' param_filename = {param_filename:s}')\n",
    "    print(f'output_filename = {output_filename:s}')\n",
    "    print(flush=True)\n",
    "    print('\\nStart time is: ', datetime.datetime.today())\n",
    "\n",
    "    result_dict = {}\n",
    "    \n",
    "    data_fileName = \"./data/DSL-StrongPasswordData.xls\"\n",
    "    global events\n",
    "    events = make_data('s047',16000,16200,data_fileName)\n",
    "    n_jumps_per_dim = list(map(len, events[0]))\n",
    "    print('\\nNumber of jumps:', len(events)*sum(n_jumps_per_dim))\n",
    "    print('\\nper node:', n_jumps_per_dim)\n",
    "    \n",
    "    C_list = [1.0]*132\n",
    "    \n",
    "    param_dict={'inference':{'vi_exp':{'excitation': {'name': 'ExponentialKernel','args': {'decay': 1.0, 'cut_off': 1000.0}}, \n",
    "                          'posterior': {'name': 'LogNormalPosterior', 'args': {}},\n",
    "                          'prior': {'name': 'GaussianLaplacianPrior', 'args': {'dim': 11, 'n_params': 132, 'C': C_list}}, \n",
    "                          'model': {'args': {'n_samples': 1, 'n_weights': 1, 'weight_temp': 1.0}}, \n",
    "                          'optimizer': {'name': 'Adam', 'args': {'lr': 0.01}}, \n",
    "                          'learner': {'args': {'tol': 1e-04, 'lr_gamma': 0.9999, 'max_iter': 40000, 'hyperparam_momentum': 0.5, 'hyperparam_interval': 100, 'hyperparam_offset': 0}}}}\n",
    "               }\n",
    "    \n",
    "\n",
    "    print('\\nINFERENCE')\n",
    "    print('=========')\n",
    "\n",
    "    for key, inference_param_dict in param_dict['inference'].items():\n",
    "        if key.startswith('vi'):\n",
    "            print(f'\\nRun VI ({key:s})')\n",
    "            print('------')\n",
    "            # Set random seed (for reproducibility)\n",
    "            np.random.seed()  # Reset random number generator to avoid dependency on simulation seed\n",
    "            #vi_seed = np.random.randint(2**32 - 1)\n",
    "            vi_seed = np.random.randint(2**16 - 1)\n",
    "            print(f'vi random seed: {vi_seed}')\n",
    "            # Run inference\n",
    "            global intens_sum\n",
    "            global integral_instesity\n",
    "            #coeffs_var, adj_var, mu_var, nu, varsigma = learn_vi(events, vi_seed, inference_param_dict)\n",
    "            coeffs_var, adj_var, mu_var,intens_sum,integral_instesity,end_time  = learn_vi(events, vi_seed, inference_param_dict)\n",
    "            #模型参数\n",
    "            adj_var = adj_var.ravel()\n",
    "            mu_var = mu_var.ravel()            \n",
    "          \n",
    "            global  end_time_result\n",
    "            end_time_result = [0.0]*len(end_time)\n",
    "            \n",
    "            for i in range(len(end_time)):\n",
    "                end_time_result[i]=end_time[i].tolist()\n",
    "                \n",
    "            expresion_temp = ''\n",
    "            events_n = len(events)\n",
    "            dim = len(events[0])\n",
    "            \n",
    "            for i in range(events_n):\n",
    "                temp = ''                  \n",
    "                for j in range(dim):\n",
    "                    temp += 'log('+str(intens_sum[i][j].detach().numpy())+ '-'+ 'epsilon_noise['+str(i)+'])'+ '+'   \n",
    "                #print(intens)\n",
    "                expresion_temp += temp[:-1] + '-' + str(integral_instesity[i].detach().numpy()) + '+' + str(dim) +'*'+ str(end_time_result[i])+'*'+ 'epsilon_noise['+str(i)+'],'\n",
    "\n",
    "            expresion = expresion_temp[:-1]\n",
    "            expresion = '['+expresion+']'\n",
    "         \n",
    "            result_dict.update({\n",
    "                key: {\n",
    "                    'vi_seed': vi_seed,             # VI random seed\n",
    "                    'coeffs': coeffs_var.tolist(),  # VI parameters\n",
    "                    'adjacency': adj_var.tolist(),  # VI Estimator\n",
    "                    'mu':  mu_var.tolist(),\n",
    "                    'expresion': expresion,\n",
    "                }\n",
    "            })\n",
    " \n",
    "\n",
    "    print('\\n\\nSave results...')\n",
    "    \n",
    "    print('\\ncoeffs:',  coeffs_var.tolist())\n",
    "    print( '\\nadjacency:', adj_var.tolist())\n",
    "    print('\\nmu:', mu_var.tolist())\n",
    "    #print('\\nnu:',nu)\n",
    "    #print('\\nvarsigma:',varsigma)\n",
    "\n",
    "    with open(os.path.join(exp_dir, output_filename), 'w') as output_file:\n",
    "        json.dump(result_dict, output_file)\n",
    "\n",
    "    # Log that the run is finished\n",
    "    print('\\n\\nFinished.')\n",
    "    print('\\nEnd time is: ', datetime.datetime.today())\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('-d', '--dir', dest='dir', type=str,\n",
    "                        #required=True, help=\"Working directory\")\n",
    "                        required=False, default=\".\")\n",
    "    parser.add_argument('-p', '--params', dest='param_filename', type=str,\n",
    "                        required=False, default='params.json',\n",
    "                        help=\"Input parameter file (JSON)\")\n",
    "    parser.add_argument('-o', '--outfile', dest='output_filename', type=str,\n",
    "                        required=False, default='output.json',\n",
    "                        help=\"Output file (JSON)\")\n",
    "    #args = parser.parse_args()\n",
    "    args = parser.parse_known_args()[0]\n",
    "\n",
    "    #run(exp_dir=args.dir, param_filename=args.param_filename,output_filename=args.output_filename)\n",
    "    run ('.','params.json','penalty10_decay1.0+s047_16000-16200.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
