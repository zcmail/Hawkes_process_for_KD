{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Experiment parameters\n",
      "=====================\n",
      "        exp_dir = .\n",
      " param_filename = params.json\n",
      "output_filename = penalty1_decay0.4+s036_12100-12150.json\n",
      "\n",
      "\n",
      "Start time is:  2020-03-06 23:26:29.717899\n",
      "\n",
      "Number of jumps: 1100\n",
      "\n",
      "per node: [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n",
      "\n",
      "INFERENCE\n",
      "=========\n",
      "\n",
      "Run VI (vi_exp)\n",
      "------\n",
      "vi random seed: 35712\n",
      "end_iter is: 37205\n",
      "Converged!\n",
      "\n",
      "\n",
      "\n",
      "Save results...\n",
      "\n",
      "coeffs: [-0.9062751402065302, -5.21446553510708, -5.5051603171898265, -5.397201523689036, -5.482639537991112, -5.399688140677453, -5.549557970718827, -5.721773022068095, -5.737102613055672, -5.750319411773816, -5.825286223368872, -4.305068705508965, -5.078422493083186, -5.04890710557745, -5.029436330877368, -4.948675219577778, -4.858644519761916, -4.747115175886463, -4.636449550826734, -4.542462925231196, -4.2273393052261525, -2.967840970193029, 0.07280235642800638, -4.641776343704574, -5.058902494611957, -4.987082701675021, -4.955639163737786, -4.879840666176762, -4.736570171943706, -4.667745984092366, -4.520173013056964, -4.2281630266982955, -2.9727338009390176, -3.903224933717675, 0.08589777033299185, -4.727439397912419, -4.981177204101088, -4.941994021940526, -4.85893254935696, -4.729604478036602, -4.660393513872461, -4.5190629785702034, -4.201579011823282, -2.9844143934650735, -4.113205426978065, -2.94668596465445, 0.04847160531208377, -4.61279069240824, -4.9593977712109485, -4.877785839867668, -4.729476734535197, -4.649290254826448, -4.506820792669956, -4.214364981472844, -2.963402619154055, -4.426752648135958, -3.952269736855142, -3.669532012498732, 0.11184427478204, -4.586440958661291, -4.857438663307013, -4.727478165481311, -4.651439341188553, -4.540074836600908, -4.207070164018962, -3.00280293973871, -4.589856152445912, -4.248163130750271, -4.087124917935384, -3.39138237393599, 0.1465935218538349, -4.40655697522927, -4.728957817895497, -4.672143504203769, -4.543468505845134, -4.214409412316605, -2.9712925293136734, -4.797554608547508, -4.573006860594893, -4.4897381815284705, -4.204511766473359, -3.7974101643306866, 0.2497097546346507, -4.287497516857152, -4.658676191169112, -4.513009561560872, -4.233994111137926, -2.985369305912635, -4.906464208436359, -4.743774159850751, -4.716282411472389, -4.510953676879481, -4.329258490626653, -3.7682204480678436, 0.3772133315071596, -4.289141702234366, -4.533854715226385, -4.21155873330291, -2.9841322896707205, -4.948378361134266, -4.825734100626468, -4.768627657444718, -4.633460858686796, -4.467876048613026, -4.076406414731408, -3.061147636724794, 0.4329402291412964, -4.115684687663174, -4.210242760826365, -2.966385888911995, -4.996888746655239, -4.901598326784995, -4.831977567540699, -4.720235280954034, -4.6243944980941585, -4.325759422715275, -3.779544027702283, -3.313438390944267, 0.557527582289278, -3.65872987543081, -2.954826580975872, -5.041847610684103, -4.955171052543275, -4.941467277282503, -4.854768711667358, -4.778091669133347, -4.602231934801217, -4.276041376288078, -4.090667736862154, -3.66101178163489, 0.7176488158450561, 0.3119124815141627, -2.4331143303284204, -0.03732537810534426, 0.010557374355838523, -0.009619150486482505, -0.006279469303764652, 0.009321501221519684, -0.001182121318063034, 0.00768240223704679, -0.011142557578821443, -0.0015199742678504635, 0.00642942792506542, -0.019862703550321468, -0.016705499950804722, 0.016932942492553584, 0.011673653190283068, 0.014600484559759543, -0.00535641296271298, -0.0048752772332799005, 0.02939724538515214, -0.005003028696127135, 0.005827264629088369, -0.011031024478511144, -2.3695302538841583, 0.009443912291176464, -0.009598844715211916, 0.024449480015562332, 0.006236187858393235, 0.009056026132568378, -0.0012738699181967037, 0.004944264472482307, -0.02358760684041896, -0.011424276920464263, 0.009787896368106938, -0.05507903876615284, -2.327552010012673, -0.013519698323730327, 0.015510376430953248, 0.01849261242612514, 0.0014462084228343453, 0.016361561523421372, -0.016062820366625558, 0.007605126638236466, 0.027935639060358494, 0.008706669195978492, -0.014561704645044153, -0.2183444802744742, -2.2975414104027156, -0.014710199487067002, -0.008320309724873283, -0.0042594326341071735, 0.0003515972836503726, 0.006122466875241477, 0.02707390351111766, 0.009699697381536847, -0.008983351923454693, 0.0031262368348431743, -0.0371588851160971, -0.07438374430540103, -2.3016832525449393, 0.0026011230320339266, 0.013236815319829114, 0.0004189620513485402, -0.0017116296159212976, -0.007199764512463505, 0.00443860032804456, 0.018272404532941718, 0.009297593763786725, -0.018134393821479904, -0.04146641926681477, -0.11107396510441897, -2.3033010510662097, -0.0061124457273628585, -0.006302829580926016, -0.0029882318372392936, -0.013348983793658656, -0.0006140515703322885, 0.022731338008828476, 0.010535124890435406, -0.011153820704240328, 0.010873971757834269, -0.03390005119823783, -0.047828026403910526, -2.285456343862799, 0.0155220498852106, 0.01728956414211651, 0.01173290757814535, 0.005910524691549128, -0.006448439793386862, 0.012560453951044975, 0.003013838305591724, 0.005957135785714678, 0.01343457717670906, -0.006882003730386672, -0.039050806119490605, -2.3087808092883675, 0.002931013193015414, 0.0170121853293575, -0.009719294471734922, -0.012018907490002157, -0.008870895657163157, -0.001115476987980987, 0.004624080634009811, -0.011877237547324187, -0.001520743483082885, 0.019671098628358242, -0.10382062998078048, -2.259914613213437, 0.002725799885038232, 0.0008237153801801795, 0.0032430576349503134, -0.0007872581842935152, 0.008331195365831132, -0.0048883144347727486, 0.012429871834276551, 0.0019732408975007484, 0.0135528611817001, -0.035596247190269235, -0.06512008476329377, -2.295383130136234, -0.003940828521041401, -0.0006282026608171547, 0.011670841681862188, 0.012606436260364378, 0.007775113330971521, 0.002662555659888966, 0.008783096520549158, 0.008331516362711257, -0.005970855658786872, -0.011212445520933792, -0.006916889197233121, -2.1379351197410106, -0.9596227156396234]\n",
      "\n",
      "adjacency: [0.005163596186615577, 0.002368345956522544, 0.0022805173171174223, 0.0023506619276583377, 0.002533111937175506, 0.0028856968324922666, 0.0032230988580159168, 0.0033559955550279586, 0.0039560597492774505, 0.005305230739626289, 0.01933147836507511, 1.066151564794246, 0.003479580036631319, 0.0023818258840981373, 0.0023882439225561894, 0.00255886969364759, 0.0027446060318203156, 0.003234031832370925, 0.00342147489133858, 0.004194029737140434, 0.005485903239541293, 0.01845347727752458, 0.00823866082952878, 1.0793778892298025, 0.003343415823257378, 0.0024475099590780336, 0.0025296566148138556, 0.0028460330878973283, 0.0031420843593779357, 0.003592961738822154, 0.003948618545834182, 0.0052002916503593654, 0.01827940563643154, 0.006191969818218112, 0.02751955737193001, 1.039115864366357, 0.0037582612568657268, 0.0026244213585906568, 0.0028248411181898544, 0.0032464922396210354, 0.003476912941326767, 0.0038393146134598367, 0.005332400498700035, 0.019339679630062993, 0.004369858241917227, 0.00759210510676828, 0.01076665441529942, 1.1071910492273027, 0.003728844943507438, 0.002782888579266024, 0.0032525484848491427, 0.003524481539147541, 0.003982766960760915, 0.005429072967252724, 0.01759705501540082, 0.0036661056646147406, 0.005447795891503641, 0.006687348111186568, 0.015113313007642638, 1.146378485984113, 0.004541915206683502, 0.0032914361909321013, 0.0034610444750547416, 0.004017386233795654, 0.0054443219198081995, 0.017992424456433447, 0.002971024597519877, 0.0038837806915624253, 0.00403913654921045, 0.005863790654539817, 0.009039181074471993, 1.2704373918221468, 0.004897509296075833, 0.0033665724523895303, 0.003939297523074194, 0.0052691548187061375, 0.018825268645791437, 0.002653426898516526, 0.003183353623001572, 0.0032527062374387706, 0.003933651845322695, 0.004914384441527524, 0.009158334942274499, 1.4438836771800927, 0.005016509309022983, 0.0038163357831852963, 0.005559162255840318, 0.019055851067787687, 0.0026563745718704646, 0.002957220022980969, 0.0030951505994120587, 0.0036611195135163943, 0.004233021737191178, 0.005996779128093403, 0.020782456266791628, 1.5250837792392866, 0.005969147408376035, 0.00545135242701163, 0.01881890960540688, 0.0024903912080309703, 0.0026894991040421886, 0.002960939760019167, 0.0031974341957618194, 0.003594505758528659, 0.004732811540828932, 0.008997336985716533, 0.015126260262079052, 1.7287221615945043, 0.009553199091258723, 0.019186066536883727, 0.002321680869030505, 0.0025270454683701915, 0.0025873035709995016, 0.002850935689174381, 0.0030402575245522365, 0.003628142135305814, 0.005173681865650751, 0.006291898568088908, 0.009587709604700203, 2.0213161702685905, 1.1796229489276249]\n",
      "\n",
      "mu: [0.4009263641859696, 0.002149471917731248, 0.0014641219621026485, 0.0016982667653776323, 0.0015489792184572684, 0.001631091251243231, 0.001434130523029496, 0.00118589623710616, 0.001212508437098409, 0.001174063959352303, 0.0010720011861863417]\n",
      "\n",
      "\n",
      "Finished.\n",
      "\n",
      "End time is:  2020-03-07 05:10:03.589336\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import argparse\n",
    "import json\n",
    "import sys\n",
    "import os\n",
    "import math\n",
    "from scipy.optimize import fsolve\n",
    "from scipy import log\n",
    "import random\n",
    "import datetime\n",
    "\n",
    "\n",
    "# External libraries\n",
    "import torch\n",
    "from torch import optim\n",
    "\n",
    "# Internal libraries\n",
    "\n",
    "import models\n",
    "import posteriors\n",
    "import priors\n",
    "import hawkes_model, excitation_kernels\n",
    "import learners\n",
    "import utils\n",
    "\n",
    "from make_data_for_samples import make_data              #多个样本数据\n",
    "from make_data_for_estimate import make_estimate_data    #单个样本数据\n",
    "\n",
    "def make_object(module, name, args):\n",
    "    return getattr(module, name)(**args)\n",
    "\n",
    "#def learn_vi(events, end_time, vi_seed, adjacency_true, inference_param_dict, return_learner=False):\n",
    "def learn_vi(events, vi_seed, inference_param_dict, return_learner=False):\n",
    "    # Extract some parameters for easier access\n",
    "    #n_nodes = len(events)\n",
    "    n_events = len(events)\n",
    "    n_nodes = len(events[0])\n",
    "    M = inference_param_dict['excitation']['args'].get('M', 1)\n",
    "    n_params = n_nodes * (n_nodes * M + 1)\n",
    "    n_edges = M * n_nodes ** 2\n",
    "    # Set seed\n",
    "    np.random.seed(vi_seed)\n",
    "    # Set starting pointM * n_nodes ** 2\n",
    "    x0 = torch.tensor(\n",
    "        np.hstack((\n",
    "            np.hstack((  # alpha, the mean of the parameters\n",
    "                np.random.normal(loc=0.1, scale=0.1, size=n_nodes),\n",
    "                np.random.normal(loc=0.1, scale=0.1, size=n_edges),)),\n",
    "            np.hstack((  # beta=log(sigma), log of the variance of the parameters\n",
    "                np.log(np.clip(np.random.normal(loc=0.2, scale=0.1, size=n_nodes), 1e-1, 2.0)),\n",
    "                np.log(np.clip(np.random.normal(loc=0.2, scale=0.1, size=n_edges), 1e-1, 2.0)),))\n",
    "        )),\n",
    "        dtype=torch.float64, requires_grad=True\n",
    "    )\n",
    "    # Init Hawkes process model object\n",
    "    excitation_obj = make_object(excitation_kernels, **inference_param_dict['excitation'])\n",
    "    hawkes_model_obj = hawkes_model.HawkesModel(excitation=excitation_obj, verbose=False)\n",
    "    # Init the posterior object\n",
    "    posterior_obj = make_object(posteriors, **inference_param_dict['posterior'])\n",
    "    # Init the prior object\n",
    "    prior_type = inference_param_dict['prior']['name']\n",
    "    prior_args = inference_param_dict['prior']['args']\n",
    "    prior_args['C'] = torch.tensor(prior_args['C'], dtype=torch.float64)  # cast to tensor\n",
    "    prior_obj = make_object(priors, prior_type, prior_args)\n",
    "    # Init the variational inference model object\n",
    "    model = models.ModelHawkesVariational(\n",
    "        model=hawkes_model_obj, posterior=posterior_obj, prior=prior_obj,\n",
    "        **inference_param_dict['model']['args'])\n",
    "   \n",
    "    # Init the optimizer\n",
    "    opt_type = inference_param_dict['optimizer']['name']\n",
    "    opt_args = inference_param_dict['optimizer']['args']\n",
    "    opt = getattr(optim, opt_type)([x0], **opt_args)\n",
    "    # Init learner\n",
    "    learner = learners.VariationalInferenceLearner(\n",
    "        model=model, optimizer=opt, **inference_param_dict['learner']['args'])\n",
    "    # Fit the model\n",
    "    events_t = [torch.tensor(events_i) for events_i in events]  # cast to tensor\n",
    "    #learner.fit(events_t, end_time, x0, callback=callback)\n",
    "    learner.fit(events_t, x0=x0, callback=None)\n",
    "    print()\n",
    "    if return_learner:\n",
    "        return learner\n",
    "    # Extract the mode of the posterior\n",
    "    z_est_mode = learner.model.posterior.mode(learner.coeffs[:n_params], learner.coeffs[n_params:])\n",
    "    adj_est_ora = z_est_mode[n_nodes:].detach()\n",
    "    mu_est_ora = z_est_mode[:n_nodes].detach()\n",
    "    adj_est_ora = adj_est_ora.view(n_nodes, n_nodes, M)\n",
    "    adj_est = z_est_mode[n_nodes:].detach().numpy()\n",
    "    adj_est = np.reshape(adj_est, (n_nodes, n_nodes, M)).sum(-1).ravel()\n",
    "    mu_est = z_est_mode[:n_nodes].detach().numpy()\n",
    "    #mu_est = np.reshape(mu_est,n_nodes).ravel()\n",
    "    coeffs_est = learner.coeffs.detach().numpy()\n",
    "    #log_like_sum,min_intens,log_like,end_time = hawkes_model_obj.log_likelihood(mu_est_ora,adj_est_ora)\n",
    "    log_like_sum,intens_sum,integral_instesity,end_time = hawkes_model_obj.log_likelihood(mu_est_ora,adj_est_ora)\n",
    "    \n",
    "    return coeffs_est, adj_est,mu_est,intens_sum,integral_instesity,end_time\n",
    "\n",
    "\n",
    "def run(exp_dir, param_filename, output_filename, stdout=None, stderr=None):\n",
    "    # Reset random seed\n",
    "    np.random.seed(None)\n",
    "\n",
    "    if stdout is not None:\n",
    "        sys.stdout = open(stdout, 'w')\n",
    "    if stderr is not None:\n",
    "        sys.stderr = open(stderr, 'w')\n",
    "\n",
    "    print('\\nExperiment parameters')\n",
    "    print('=====================')\n",
    "    print(f'        exp_dir = {exp_dir:s}')\n",
    "    print(f' param_filename = {param_filename:s}')\n",
    "    print(f'output_filename = {output_filename:s}')\n",
    "    print(flush=True)\n",
    "    print('\\nStart time is: ', datetime.datetime.today())\n",
    "\n",
    "    result_dict = {}\n",
    "    \n",
    "    data_fileName = \"./data/DSL-StrongPasswordData.xls\"\n",
    "    global events\n",
    "    events = make_data('s002',50,100,data_fileName)\n",
    "    n_jumps_per_dim = list(map(len, events[0]))\n",
    "    print('\\nNumber of jumps:', len(events)*sum(n_jumps_per_dim))\n",
    "    print('\\nper node:', n_jumps_per_dim)\n",
    "    \n",
    "    C_list = [1.0]*132\n",
    "    \n",
    "    param_dict={'inference':{'vi_exp':{'excitation': {'name': 'ExponentialKernel','args': {'decay': 0.3, 'cut_off': 1000.0}}, \n",
    "                          'posterior': {'name': 'LogNormalPosterior', 'args': {}},\n",
    "                          'prior': {'name': 'GaussianLaplacianPrior', 'args': {'dim': 11, 'n_params': 132, 'C': C_list}}, \n",
    "                          'model': {'args': {'n_samples': 1, 'n_weights': 1, 'weight_temp': 1.0}}, \n",
    "                          'optimizer': {'name': 'Adam', 'args': {'lr': 0.01}}, \n",
    "                          'learner': {'args': {'tol': 1e-04, 'lr_gamma': 0.9999, 'max_iter': 40000, 'hyperparam_momentum': 0.5, 'hyperparam_interval': 100, 'hyperparam_offset': 0}}}}\n",
    "               }\n",
    "    \n",
    "\n",
    "    print('\\nINFERENCE')\n",
    "    print('=========')\n",
    "\n",
    "    for key, inference_param_dict in param_dict['inference'].items():\n",
    "        if key.startswith('vi'):\n",
    "            print(f'\\nRun VI ({key:s})')\n",
    "            print('------')\n",
    "            # Set random seed (for reproducibility)\n",
    "            np.random.seed()  # Reset random number generator to avoid dependency on simulation seed\n",
    "            #vi_seed = np.random.randint(2**32 - 1)\n",
    "            vi_seed = np.random.randint(2**16 - 1)\n",
    "            print(f'vi random seed: {vi_seed}')\n",
    "            # Run inference\n",
    "            global intens_sum\n",
    "            global integral_instesity\n",
    "            #coeffs_var, adj_var, mu_var, nu, varsigma = learn_vi(events, vi_seed, inference_param_dict)\n",
    "            coeffs_var, adj_var, mu_var,intens_sum,integral_instesity,end_time  = learn_vi(events, vi_seed, inference_param_dict)\n",
    "            #模型参数\n",
    "            adj_var = adj_var.ravel()\n",
    "            mu_var = mu_var.ravel()            \n",
    "          \n",
    "            global  end_time_result\n",
    "            end_time_result = [0.0]*len(end_time)\n",
    "            \n",
    "            for i in range(len(end_time)):\n",
    "                end_time_result[i]=end_time[i].tolist()\n",
    "                \n",
    "            expresion_temp = ''\n",
    "            events_n = len(events)\n",
    "            dim = len(events[0])\n",
    "            \n",
    "            for i in range(events_n):\n",
    "                temp = ''                  \n",
    "                for j in range(dim):\n",
    "                    temp += 'log('+str(intens_sum[i][j].detach().numpy())+ '-'+ 'epsilon_noise['+str(i)+'])'+ '+'   \n",
    "                #print(intens)\n",
    "                expresion_temp += temp[:-1] + '-' + str(integral_instesity[i].detach().numpy()) + '+' + str(dim) +'*'+ str(end_time_result[i])+'*'+ 'epsilon_noise['+str(i)+'],'\n",
    "\n",
    "            expresion = expresion_temp[:-1]\n",
    "            expresion = '['+expresion+']'\n",
    "         \n",
    "            result_dict.update({\n",
    "                key: {\n",
    "                    'vi_seed': vi_seed,             # VI random seed\n",
    "                    'coeffs': coeffs_var.tolist(),  # VI parameters\n",
    "                    'adjacency': adj_var.tolist(),  # VI Estimator\n",
    "                    'mu':  mu_var.tolist(),\n",
    "                    'expresion': expresion,\n",
    "                }\n",
    "            })\n",
    " \n",
    "\n",
    "    print('\\n\\nSave results...')\n",
    "    \n",
    "    print('\\ncoeffs:',  coeffs_var.tolist())\n",
    "    print( '\\nadjacency:', adj_var.tolist())\n",
    "    print('\\nmu:', mu_var.tolist())\n",
    "    #print('\\nnu:',nu)\n",
    "    #print('\\nvarsigma:',varsigma)\n",
    "\n",
    "    with open(os.path.join(exp_dir, output_filename), 'w') as output_file:\n",
    "        json.dump(result_dict, output_file)\n",
    "\n",
    "    # Log that the run is finished\n",
    "    print('\\n\\nFinished.')\n",
    "    print('\\nEnd time is: ', datetime.datetime.today())\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('-d', '--dir', dest='dir', type=str,\n",
    "                        #required=True, help=\"Working directory\")\n",
    "                        required=False, default=\".\")\n",
    "    parser.add_argument('-p', '--params', dest='param_filename', type=str,\n",
    "                        required=False, default='params.json',\n",
    "                        help=\"Input parameter file (JSON)\")\n",
    "    parser.add_argument('-o', '--outfile', dest='output_filename', type=str,\n",
    "                        required=False, default='output.json',\n",
    "                        help=\"Output file (JSON)\")\n",
    "    #args = parser.parse_args()\n",
    "    args = parser.parse_known_args()[0]\n",
    "\n",
    "    #run(exp_dir=args.dir, param_filename=args.param_filename,output_filename=args.output_filename)\n",
    "    run ('.','params.json','penalty1_decay0.4+s002_50-100.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
