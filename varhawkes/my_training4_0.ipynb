{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Experiment parameters\n",
      "=====================\n",
      "        exp_dir = .\n",
      " param_filename = params.json\n",
      "output_filename = penalty10_decay1.0+s052_18000-18200-2.json\n",
      "\n",
      "\n",
      "Start time is:  2020-03-18 20:55:34.354631\n",
      "\n",
      "Number of jumps: 4400\n",
      "\n",
      "per node: [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n",
      "\n",
      "INFERENCE\n",
      "=========\n",
      "\n",
      "Run VI (vi_exp)\n",
      "------\n",
      "vi random seed: 28329\n",
      "end_iter is: 39083\n",
      "Converged!\n",
      "\n",
      "\n",
      "\n",
      "Save results...\n",
      "\n",
      "coeffs: [-0.33760936210868353, -5.921927120229073, -6.219390375658878, -6.4388797094522525, -6.265863940503068, -6.375512168110261, -6.475510952918774, -6.544683968989855, -6.590237789662321, -6.602614259950855, -6.617942825822207, -5.189159607077691, -6.4023420387249415, -6.402565592569591, -6.397806451349562, -6.322827898366633, -6.224709143962778, -6.1157064210113266, -5.916389339373493, -5.720494646373496, -5.643240775907305, -3.7386711080125417, 0.07231104665957135, -5.750402081933343, -5.778509857458311, -6.3999576432538685, -6.330119551608338, -6.22838568905173, -6.118025465748385, -5.924367329581671, -5.752903527885983, -5.644435562599149, -3.7383744568997557, -5.035453127850649, 0.10863521468542826, -6.099117638416225, -6.321231883335853, -6.310737868983304, -6.223240165624043, -6.12349067785848, -5.924646255648731, -5.762367660929066, -5.647536469960119, -3.742458576853064, -5.773185033208069, -0.6995462614696355, -0.4788963415423478, -6.041193614549797, -6.306158128759039, -6.202631992839059, -6.100509166747189, -5.929059921204541, -5.7454457838239295, -5.640326774962253, -3.74377418187896, -5.945414054403571, -4.782745819419564, -4.321840372329222, 0.11155241592700621, -5.824272197820152, -6.246608824747599, -6.108306755437487, -5.9230673926177815, -5.743794367178911, -5.632424491765465, -3.7308813588136447, -6.165184222343102, -5.664739355236559, -5.564653812145039, -5.350934666155013, 0.18962465043850135, -5.748169735412601, -6.121578621063497, -5.931216739954634, -5.738779121015241, -5.646940921119475, -3.731795798322038, -6.276757447247919, -6.007273827681385, -5.941238871403706, -5.846943479480313, -5.3020959168107336, 0.2826523792218308, -5.652439038456025, -5.909105371053884, -5.754721927928401, -5.648826048694983, -3.7389495889973325, -6.340438409087668, -6.14073884992874, -6.12894226577376, -6.070514399622204, -5.756524047584269, -5.096724617760087, 0.39492539123266507, -5.4520790560721695, -5.566813826533125, -5.587755721598131, -3.7389091755901878, -6.385930343565729, -6.2248820083715986, -6.184307630176877, -6.142992992269902, -5.914245783602263, -5.534768330386944, -4.7994326939535314, 0.5753034221271189, -5.337160271720633, -5.158350881832335, -3.755234131180898, -6.379207711679772, -6.231723229684953, -6.206875490421865, -6.186852468733821, -5.977777711989301, -5.649984510188754, -5.068031976478567, -1.6327611360947143, 0.633857135499962, -5.296444383820057, -3.7431350957741705, -6.427865302176253, -6.326878203537829, -6.316286085332411, -6.28435701492378, -6.153804104431171, -5.940385768803357, -5.644955709556636, -5.064434373757355, -3.9577056644606836, 0.3549600458207833, 1.7886096013225599, -3.0911433303190545, -0.0030982580092716204, 0.007338958980985084, 0.009828462146426664, 0.010027738148515852, 0.008934029758125997, 0.004850367887322931, 0.006828587356572078, -0.006457310543671475, 0.011890561992080327, 0.02379257690737377, -0.039967750284337224, 0.02854653337035076, 0.011481357665557045, -0.00973302380745418, -0.0035010827747384175, -0.004530612649352619, 0.017998970492511295, 0.0016154755678997172, 0.011185710280751725, 0.012333547150178889, 0.02745842239688451, -3.0328517070603582, 0.018724499195609808, 0.005729760298709163, -0.009649741481248718, 0.0041539937811995295, 0.005013376983213641, 0.012296360064607258, 0.006699326850016684, 0.0004464055936950443, 0.0036356235260880136, 0.003458579844985021, -0.02223157137720638, -3.027654850308764, 0.0049140780004469625, 0.02106841541374023, -0.006599494629545454, 0.0004891565334229799, -0.010668223509702928, 0.009866481510751235, -0.004956914950368292, 0.014434222904228276, -0.0014985211862006142, -0.006105486585313186, -2.231464302981455, -2.4531733509686027, -0.004697013539405231, 0.0015970094563874805, 0.010476534208572563, 0.010684558240936804, 0.0023617082581303887, 0.009644319902464272, -0.0030955412624585846, 0.01588908363125999, -0.0015089097281847893, -0.030484364286539768, -0.06914457132249086, -3.009753562197784, 0.0024707816160318124, -0.00795183626524955, -0.004355687500297246, -0.001362338934348045, -0.00983125222613682, 0.024791832336932256, 0.00328017819992982, 0.001200898634626767, 0.005369831472099903, 0.0013930613826008823, 0.00041272758661945884, -3.005114687229838, -0.0049881090837531165, -0.016011071579120448, -0.007513395703814681, 0.014375955283693367, 0.0034293232780105657, -0.00378337550409233, 0.0014646073096262196, 0.010510921457437495, 0.014622628184616421, 0.008318763546274435, -0.0023873962351365872, -3.001875289602845, 0.008367846471523237, 0.007309156371119836, 0.006057671287969043, 0.007658432497463211, 0.01225181619898478, 0.007679670100660257, 0.00332660878111202, 0.00011215721675391186, -0.003267118078879391, 0.008631122301421034, 0.00011380711851656725, -2.9969783288882086, -0.0010683271172340608, -0.00348643049842686, -0.006857810135292122, 0.00512498669744201, -0.00043810949519778377, -0.012593407359328745, 0.007113948995105425, 0.017224652394228494, 0.023973892626944274, 0.0013344424516211156, -0.003963157497328107, -3.004115028780379, 0.002292476467555827, 0.019136957562245895, 0.005144598156526774, -0.0031837214210774486, 0.01562351865825425, 0.01188234785199307, -0.01635702589399149, 0.003246870448484064, 0.0032205764832548044, -0.01487606438393167, -1.0156179083287582, -2.8840570177787708, 0.0044470988734773825, 0.01725078569907315, 0.012100255129837686, 0.015850225446219505, 0.004428054267194783, 0.022957121651688988, -0.009148426695439825, 0.018997589364725113, 0.024182472463122356, -0.00874567679891932, -0.06910317677846409, -2.6932009019627614, -2.3725421087289]\n",
      "\n",
      "adjacency: [0.002215370776890156, 0.0005750253798041923, 0.0005956877243314835, 0.0006245191003548843, 0.0006649157674242407, 0.0007349641408874179, 0.0007830138818979036, 0.0009881999366512693, 0.0011789651890096405, 0.0012706653475432039, 0.008269974366830945, 1.072497372497574, 0.0011265886232229205, 0.001124929074846581, 0.0006230752854921891, 0.0006500494336016874, 0.0007184152026763071, 0.0007904382013037844, 0.0009703476510970039, 0.001166442526508463, 0.0012917811075735229, 0.008692318317234759, 0.002498751725386548, 1.1121441725983094, 0.0008177169980690106, 0.0006334882716407397, 0.0006771446772553361, 0.0007287214793996623, 0.00082314330891114, 0.0009638496882495963, 0.0011679527945165301, 0.0012597705872308825, 0.008743313683961022, 0.0011580145774538258, 0.4911160559178384, 0.6148998850093532, 0.0008833018467286319, 0.0006692470697478154, 0.0007290223864186502, 0.0008070634745317891, 0.000974296865580483, 0.001153537868939183, 0.0013146894279639837, 0.008429121981698273, 0.0009659477792241791, 0.0032679301356244818, 0.005557053658535353, 1.1152979049037726, 0.0010816950356746962, 0.0007239190741489775, 0.0008254076152776392, 0.0009874877924761767, 0.0012013325151056895, 0.0012516933080355588, 0.0087608418111593, 0.000771179878443683, 0.0012613951667856534, 0.0014053852426029016, 0.0017436747593068556, 1.2058336157917366, 0.00118472675836585, 0.0008333442318966531, 0.0009914894134428922, 0.0011500517267868451, 0.001289084320073538, 0.00887730194556615, 0.0006893985851273582, 0.0008862440569063565, 0.000938792606234929, 0.0010450190323095156, 0.0018412096487982637, 1.3233718433676898, 0.0012692671940335307, 0.0009840527507317255, 0.0011512454086433257, 0.0012756992516075759, 0.008533498143992277, 0.0006388018087269095, 0.000786896170256889, 0.0008013869808775834, 0.0008553485894455959, 0.00114318603657095, 0.002249713829141011, 1.4805766107403422, 0.001580609601122923, 0.001416076556955536, 0.0013960147177574365, 0.008658516638782386, 0.000620456842608852, 0.000746578540271485, 0.0007476039293435659, 0.0007631602311194992, 0.0009459113930251203, 0.0014481899974265577, 0.003053283502129304, 1.773304910255636, 0.00176120727808211, 0.0020347818234947384, 0.008517976696403433, 0.0006280690168807666, 0.0007006769768675913, 0.0007238511238573413, 0.0007812090816261327, 0.0009263183583082733, 0.0012857070840752087, 0.002384613826476506, 0.17136929163356385, 1.8789845326072254, 0.0018264551768861065, 0.008410799444559393, 0.0005800704354440385, 0.0006367799143516277, 0.0006587400746166421, 0.000654694635691055, 0.0007961892714132318, 0.0009311296852262727, 0.0012376890292670145, 0.0023647213039456796, 0.007997513321466048, 1.4196092079144427, 5.9293540124032695]\n",
      "\n",
      "mu: [0.7120016422753881, 0.000992037386859797, 0.0007215011807456554, 0.0005763870833801685, 0.000684979341129195, 0.0006152137334637966, 0.000561297834884247, 0.0005216911410960708, 0.0005118872333988827, 0.00048727573224747046, 0.000468170352612672]\n",
      "\n",
      "\n",
      "Finished.\n",
      "\n",
      "End time is:  2020-03-19 13:50:17.490293\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import argparse\n",
    "import json\n",
    "import sys\n",
    "import os\n",
    "import math\n",
    "from scipy.optimize import fsolve\n",
    "from scipy import log\n",
    "import random\n",
    "import datetime\n",
    "\n",
    "\n",
    "# External libraries\n",
    "import torch\n",
    "from torch import optim\n",
    "\n",
    "# Internal libraries\n",
    "\n",
    "import models\n",
    "import posteriors\n",
    "import priors\n",
    "import hawkes_model, excitation_kernels\n",
    "import learners\n",
    "import utils\n",
    "\n",
    "from make_data_for_samples import make_data              #多个样本数据\n",
    "from make_data_for_estimate import make_estimate_data    #单个样本数据\n",
    "\n",
    "def make_object(module, name, args):\n",
    "    return getattr(module, name)(**args)\n",
    "\n",
    "#def learn_vi(events, end_time, vi_seed, adjacency_true, inference_param_dict, return_learner=False):\n",
    "def learn_vi(events, vi_seed, inference_param_dict, return_learner=False):\n",
    "    # Extract some parameters for easier access\n",
    "    #n_nodes = len(events)\n",
    "    n_events = len(events)\n",
    "    n_nodes = len(events[0])\n",
    "    M = inference_param_dict['excitation']['args'].get('M', 1)\n",
    "    n_params = n_nodes * (n_nodes * M + 1)\n",
    "    n_edges = M * n_nodes ** 2\n",
    "    # Set seed\n",
    "    np.random.seed(vi_seed)\n",
    "    # Set starting pointM * n_nodes ** 2\n",
    "    x0 = torch.tensor(\n",
    "        np.hstack((\n",
    "            np.hstack((  # alpha, the mean of the parameters\n",
    "                np.random.normal(loc=0.1, scale=0.1, size=n_nodes),\n",
    "                np.random.normal(loc=0.1, scale=0.1, size=n_edges),)),\n",
    "            np.hstack((  # beta=log(sigma), log of the variance of the parameters\n",
    "                np.log(np.clip(np.random.normal(loc=0.2, scale=0.1, size=n_nodes), 1e-1, 2.0)),\n",
    "                np.log(np.clip(np.random.normal(loc=0.2, scale=0.1, size=n_edges), 1e-1, 2.0)),))\n",
    "        )),\n",
    "        dtype=torch.float64, requires_grad=True\n",
    "    )\n",
    "    # Init Hawkes process model object\n",
    "    excitation_obj = make_object(excitation_kernels, **inference_param_dict['excitation'])\n",
    "    hawkes_model_obj = hawkes_model.HawkesModel(excitation=excitation_obj, verbose=False)\n",
    "    # Init the posterior object\n",
    "    posterior_obj = make_object(posteriors, **inference_param_dict['posterior'])\n",
    "    # Init the prior object\n",
    "    prior_type = inference_param_dict['prior']['name']\n",
    "    prior_args = inference_param_dict['prior']['args']\n",
    "    prior_args['C'] = torch.tensor(prior_args['C'], dtype=torch.float64)  # cast to tensor\n",
    "    prior_obj = make_object(priors, prior_type, prior_args)\n",
    "    # Init the variational inference model object\n",
    "    model = models.ModelHawkesVariational(\n",
    "        model=hawkes_model_obj, posterior=posterior_obj, prior=prior_obj,\n",
    "        **inference_param_dict['model']['args'])\n",
    "   \n",
    "    # Init the optimizer\n",
    "    opt_type = inference_param_dict['optimizer']['name']\n",
    "    opt_args = inference_param_dict['optimizer']['args']\n",
    "    opt = getattr(optim, opt_type)([x0], **opt_args)\n",
    "    # Init learner\n",
    "    learner = learners.VariationalInferenceLearner(\n",
    "        model=model, optimizer=opt, **inference_param_dict['learner']['args'])\n",
    "    # Fit the model\n",
    "    events_t = [torch.tensor(events_i) for events_i in events]  # cast to tensor\n",
    "    #learner.fit(events_t, end_time, x0, callback=callback)\n",
    "    learner.fit(events_t, x0=x0, callback=None)\n",
    "    print()\n",
    "    if return_learner:\n",
    "        return learner\n",
    "    # Extract the mode of the posterior\n",
    "    z_est_mode = learner.model.posterior.mode(learner.coeffs[:n_params], learner.coeffs[n_params:])\n",
    "    adj_est_ora = z_est_mode[n_nodes:].detach()\n",
    "    mu_est_ora = z_est_mode[:n_nodes].detach()\n",
    "    adj_est_ora = adj_est_ora.view(n_nodes, n_nodes, M)\n",
    "    adj_est = z_est_mode[n_nodes:].detach().numpy()\n",
    "    adj_est = np.reshape(adj_est, (n_nodes, n_nodes, M)).sum(-1).ravel()\n",
    "    mu_est = z_est_mode[:n_nodes].detach().numpy()\n",
    "    #mu_est = np.reshape(mu_est,n_nodes).ravel()\n",
    "    coeffs_est = learner.coeffs.detach().numpy()\n",
    "    #log_like_sum,min_intens,log_like,end_time = hawkes_model_obj.log_likelihood(mu_est_ora,adj_est_ora)\n",
    "    log_like_sum,intens_sum,integral_instesity,end_time = hawkes_model_obj.log_likelihood(mu_est_ora,adj_est_ora)\n",
    "    \n",
    "    return coeffs_est, adj_est,mu_est,intens_sum,integral_instesity,end_time\n",
    "\n",
    "\n",
    "def run(exp_dir, param_filename, output_filename, stdout=None, stderr=None):\n",
    "    # Reset random seed\n",
    "    np.random.seed(None)\n",
    "\n",
    "    if stdout is not None:\n",
    "        sys.stdout = open(stdout, 'w')\n",
    "    if stderr is not None:\n",
    "        sys.stderr = open(stderr, 'w')\n",
    "\n",
    "    print('\\nExperiment parameters')\n",
    "    print('=====================')\n",
    "    print(f'        exp_dir = {exp_dir:s}')\n",
    "    print(f' param_filename = {param_filename:s}')\n",
    "    print(f'output_filename = {output_filename:s}')\n",
    "    print(flush=True)\n",
    "    print('\\nStart time is: ', datetime.datetime.today())\n",
    "\n",
    "    result_dict = {}\n",
    "    \n",
    "    data_fileName = \"./data/DSL-StrongPasswordData.xls\"\n",
    "    global events\n",
    "    events = make_data('s052',18000,18200,data_fileName)\n",
    "    n_jumps_per_dim = list(map(len, events[0]))\n",
    "    print('\\nNumber of jumps:', len(events)*sum(n_jumps_per_dim))\n",
    "    print('\\nper node:', n_jumps_per_dim)\n",
    "    \n",
    "    C_list = [1.0]*132\n",
    "    \n",
    "    param_dict={'inference':{'vi_exp':{'excitation': {'name': 'ExponentialKernel','args': {'decay': 1.0, 'cut_off': 1000.0}}, \n",
    "                          'posterior': {'name': 'LogNormalPosterior', 'args': {}},\n",
    "                          'prior': {'name': 'GaussianLaplacianPrior', 'args': {'dim': 11, 'n_params': 132, 'C': C_list}}, \n",
    "                          'model': {'args': {'n_samples': 1, 'n_weights': 1, 'weight_temp': 1.0}}, \n",
    "                          'optimizer': {'name': 'Adam', 'args': {'lr': 0.01}}, \n",
    "                          'learner': {'args': {'tol': 1e-04, 'lr_gamma': 0.9999, 'max_iter': 40000, 'hyperparam_momentum': 0.5, 'hyperparam_interval': 100, 'hyperparam_offset': 0}}}}\n",
    "               }\n",
    "    \n",
    "\n",
    "    print('\\nINFERENCE')\n",
    "    print('=========')\n",
    "\n",
    "    for key, inference_param_dict in param_dict['inference'].items():\n",
    "        if key.startswith('vi'):\n",
    "            print(f'\\nRun VI ({key:s})')\n",
    "            print('------')\n",
    "            # Set random seed (for reproducibility)\n",
    "            np.random.seed()  # Reset random number generator to avoid dependency on simulation seed\n",
    "            #vi_seed = np.random.randint(2**32 - 1)\n",
    "            vi_seed = np.random.randint(2**16 - 1)\n",
    "            print(f'vi random seed: {vi_seed}')\n",
    "            # Run inference\n",
    "            global intens_sum\n",
    "            global integral_instesity\n",
    "            #coeffs_var, adj_var, mu_var, nu, varsigma = learn_vi(events, vi_seed, inference_param_dict)\n",
    "            coeffs_var, adj_var, mu_var,intens_sum,integral_instesity,end_time  = learn_vi(events, vi_seed, inference_param_dict)\n",
    "            #模型参数\n",
    "            adj_var = adj_var.ravel()\n",
    "            mu_var = mu_var.ravel()            \n",
    "          \n",
    "            global  end_time_result\n",
    "            end_time_result = [0.0]*len(end_time)\n",
    "            \n",
    "            for i in range(len(end_time)):\n",
    "                end_time_result[i]=end_time[i].tolist()\n",
    "                \n",
    "            expresion_temp = ''\n",
    "            events_n = len(events)\n",
    "            dim = len(events[0])\n",
    "            \n",
    "            for i in range(events_n):\n",
    "                temp = ''                  \n",
    "                for j in range(dim):\n",
    "                    temp += 'log('+str(intens_sum[i][j].detach().numpy())+ '-'+ 'epsilon_noise['+str(i)+'])'+ '+'   \n",
    "                #print(intens)\n",
    "                expresion_temp += temp[:-1] + '-' + str(integral_instesity[i].detach().numpy()) + '+' + str(dim) +'*'+ str(end_time_result[i])+'*'+ 'epsilon_noise['+str(i)+'],'\n",
    "\n",
    "            expresion = expresion_temp[:-1]\n",
    "            expresion = '['+expresion+']'\n",
    "         \n",
    "            result_dict.update({\n",
    "                key: {\n",
    "                    'vi_seed': vi_seed,             # VI random seed\n",
    "                    'coeffs': coeffs_var.tolist(),  # VI parameters\n",
    "                    'adjacency': adj_var.tolist(),  # VI Estimator\n",
    "                    'mu':  mu_var.tolist(),\n",
    "                    'expresion': expresion,\n",
    "                }\n",
    "            })\n",
    " \n",
    "\n",
    "    print('\\n\\nSave results...')\n",
    "    \n",
    "    print('\\ncoeffs:',  coeffs_var.tolist())\n",
    "    print( '\\nadjacency:', adj_var.tolist())\n",
    "    print('\\nmu:', mu_var.tolist())\n",
    "    #print('\\nnu:',nu)\n",
    "    #print('\\nvarsigma:',varsigma)\n",
    "\n",
    "    with open(os.path.join(exp_dir, output_filename), 'w') as output_file:\n",
    "        json.dump(result_dict, output_file)\n",
    "\n",
    "    # Log that the run is finished\n",
    "    print('\\n\\nFinished.')\n",
    "    print('\\nEnd time is: ', datetime.datetime.today())\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('-d', '--dir', dest='dir', type=str,\n",
    "                        #required=True, help=\"Working directory\")\n",
    "                        required=False, default=\".\")\n",
    "    parser.add_argument('-p', '--params', dest='param_filename', type=str,\n",
    "                        required=False, default='params.json',\n",
    "                        help=\"Input parameter file (JSON)\")\n",
    "    parser.add_argument('-o', '--outfile', dest='output_filename', type=str,\n",
    "                        required=False, default='output.json',\n",
    "                        help=\"Output file (JSON)\")\n",
    "    #args = parser.parse_args()\n",
    "    args = parser.parse_known_args()[0]\n",
    "\n",
    "    #run(exp_dir=args.dir, param_filename=args.param_filename,output_filename=args.output_filename)\n",
    "    run ('.','params.json','penalty10_decay1.0+s052_18000-18200-2.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
