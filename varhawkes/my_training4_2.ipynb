{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Experiment parameters\n",
      "=====================\n",
      "        exp_dir = .\n",
      " param_filename = params.json\n",
      "output_filename = penalty10_decay0.3+s032_10400-10410.json\n",
      "\n",
      "\n",
      "Start time is:  2020-03-17 13:17:47.603268\n",
      "\n",
      "Number of jumps: 220\n",
      "\n",
      "per node: [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n",
      "\n",
      "INFERENCE\n",
      "=========\n",
      "\n",
      "Run VI (vi_exp)\n",
      "------\n",
      "vi random seed: 41543\n",
      "end_iter is: 39276\n",
      "Converged!\n",
      "\n",
      "\n",
      "\n",
      "Save results...\n",
      "\n",
      "coeffs: [-0.48712535939632673, -0.6291089668478922, -0.8163064690369258, -0.9501784033879538, -0.9111588394791271, -0.9744105341481439, -2.150387413093768, -2.4785814327781517, -2.6476130298174274, -2.711587023303444, -2.644317224080956, -3.4208108579366856, -3.6166799520027197, -3.6199357282475586, -3.5671878948688955, -3.4979559672257077, -3.3901077672749733, -3.328659447827607, -3.26422530457173, -3.2481468142864593, -3.1503409624372387, -2.9159048300256494, -2.1086613447205624, -3.391859979009077, -3.628428993499887, -3.577536623986946, -3.507222230420168, -3.3941832189940775, -3.3373590947030776, -3.2885733070378844, -3.231531313032937, -3.150392779260835, -2.9177570697591553, -2.3141332928591445, -1.8302841322086605, -3.3546117818002967, -3.58153143613762, -3.493799068298133, -3.3659157876826566, -3.3061890252141164, -3.2587867591880872, -3.250501732024068, -3.153286126415253, -2.927417873396346, -2.481652282111918, -2.1427453757500095, -1.8503493991380369, -3.324547276907237, -3.4770153253245266, -3.3736157788826575, -3.3153295925096615, -3.2689149880948936, -3.2275140168962952, -3.148424770545977, -2.8977927774087124, -2.7793243719535554, -2.5341482198625864, -2.3591188255439572, -2.065416514526085, -3.201920311756887, -3.394611808926244, -3.3327282767682758, -3.2803965733714873, -3.238930125915074, -3.138991139910873, -2.9062391234751677, -3.0119606282473854, -2.82548610961217, -2.708470338927882, -2.527818651857173, -1.7390101299718255, -3.053348414130362, -3.3078187299194206, -3.2612004381016195, -3.2370414409059767, -3.163358018847742, -2.920737746263471, -3.140174587387047, -2.9873228900648323, -2.9063261052666274, -2.7935387408034256, -2.3010704033442404, -0.4009254172219079, -2.9971787690454086, -3.2634399523525723, -3.2300476059959813, -3.1458006008781743, -2.9190242849202566, -3.2028955733035813, -3.0927296516057314, -3.0447761874601884, -2.9403184652056304, -2.5166585148466534, -1.6261134275124753, -0.4401497257457673, -3.0008210923940917, -3.234675811510949, -3.1265475579319633, -2.938213088676312, -3.267658496966026, -3.179899224842822, -3.102220313371709, -2.9892212390840704, -2.658806657546549, -1.9713596948930845, -1.4506860250064288, -0.6095892824306771, -2.9315759026929853, -3.1241129199354285, -2.905040655752966, -3.3044042325320477, -3.2196490662315806, -3.161668082765337, -3.0748164185573197, -2.7917318791171835, -2.1977118482891824, -1.8639153755039748, -1.4855372734194654, -0.7043026131377493, -2.823873603241454, -2.9278922565823473, -3.353670314410169, -3.307438523418207, -3.2368023213404484, -3.1660468131830304, -2.9354525854715803, -2.489873857896983, -2.245707826477562, -2.021315819117576, -1.6951011310474737, -0.5586806669666169, -2.502384583169232, -1.5931788859316378, -1.4714236109501098, -1.2998713864907216, -1.1760167693306007, -1.2094406114135523, -1.1478993785113343, -0.38522201306939147, -0.2541246489537628, -0.20674656417883427, -0.1944881957599103, -0.2046886353860092, 0.0008012596982478727, 0.009280403962827817, -0.002014832951962752, 0.03385812999644803, -0.006887078824032926, 0.0009979878520138318, 0.006024494619603398, 0.0009802096356821871, 0.011593123920489263, 0.009334619105757029, 0.001392773710315462, -0.2397367875217672, -0.001262676314714071, -0.014873639219905005, 0.01483553478058181, 0.003399757620106523, -0.006247700940388644, -0.00711785834161583, 0.0043851332029437836, -0.011007542156250084, -0.0009675038154251509, -0.003281360636612875, -0.1762181909723291, -0.30678187401439966, -0.004601742387563416, 0.01100685316371314, -0.0014893001226377342, 0.019832435451918075, -0.00033627270570061083, 0.0047362070680421805, -0.0030868314825237926, -0.00637956872842406, 0.002222692415910228, -0.11301202615061316, -0.2288027991089492, -0.33036161701454636, -0.012849464462434049, 0.01177453138936631, 0.00643056469937417, 0.005275297234716826, 0.014277959498723694, -0.004974616256526509, 0.003853571993630272, 0.021467595894141114, -0.06076507941599576, -0.09972632287067396, -0.12047594194921472, -0.2595775584597065, 0.008585766617328733, -0.002196875584137012, 0.005587330621440125, -0.005568361611342145, 0.0023462772131373037, 0.008587094315567033, 0.017050374144662407, -0.0321337657547823, -0.04589164767680333, -0.061777692447614406, -0.11434709947708808, -0.2831446378587625, 0.00820584602655942, 0.008136403431282567, 0.017330700299045116, 0.01824591180177361, 0.005125110494022151, 0.006939465732724284, -0.016046394776907637, -0.02383203680496163, -0.02634692646332719, -0.07424653936047751, -0.12726713594691408, -1.0487430805705105, 0.014981303824610952, 0.019549289741087106, 0.008568458475423972, 0.010072210958475342, 0.0043333292596711625, -0.019230390888980032, -0.02133991524795727, -0.03831619066538021, -0.036413266403045944, -0.07591244050931162, -0.2915615103858945, -0.979466979344276, -0.024303234740184334, 0.0018234224692335297, 0.014777308607211048, -0.0023236420861999212, -0.02730019598024281, 0.0013892325447212009, -0.019971650243750326, -0.02072138700472212, -0.05834100467825487, -0.1751429396138304, -0.3548018496278535, -0.7988471762915679, 0.01041853883089611, 0.028806936276878078, 0.009147615011326273, 0.007796690736889941, -0.03364154688241768, -0.010525783638523053, -0.0315335090210492, -0.03242790836522798, -0.11645539107769014, -0.23002092129656967, -0.33565132596243846, -0.7183091810365757, -0.015697536404359662, 0.012122572445268464, 0.00817136017718109, -0.01119253761937449, -0.025367170161815732, -0.0002753099726292503, -0.029236993430613742, -0.07284802093659523, -0.11129009968703966, -0.16490445544588878, -0.23429773253635358, -0.7617947501983482, -0.011767702284197903]\n",
      "\n",
      "adjacency: [0.012005208735815266, 0.009702088742280617, 0.009893135258896664, 0.009684297293062069, 0.011285052243867104, 0.01237464402912347, 0.013026346500094264, 0.01403518838530784, 0.013959375009179802, 0.015464850181845445, 0.019867018963217485, 0.06536485401834116, 0.012408943548976058, 0.010060687159292328, 0.009975209979838131, 0.010954062194503802, 0.012503263853223033, 0.013257070758752388, 0.013604126067883353, 0.01484997953106212, 0.015788718032957304, 0.020016149903344792, 0.04894262511052976, 0.09332174975426487, 0.012965665647069021, 0.010013819080321448, 0.011211391720632038, 0.012199286478257422, 0.013493911356399867, 0.014005513875851066, 0.014345096722771228, 0.015913172690220658, 0.019606911377345403, 0.037652678052542334, 0.06231566881121755, 0.09377780566956936, 0.013579747442316381, 0.011099626091167592, 0.012443461580185075, 0.013221168749900267, 0.013597320385183766, 0.014733755660120725, 0.015667579667088816, 0.01941589887890728, 0.025607020743226745, 0.03496781432213618, 0.043066998790511235, 0.06991748100497011, 0.014709817907426974, 0.01239790594344046, 0.012984932817200912, 0.013991271139098066, 0.014355333869490847, 0.01566519897431312, 0.019430175793903035, 0.019260195627944655, 0.023806683033388766, 0.02753649588251351, 0.03603046548796098, 0.0995955318876535, 0.017079172884420162, 0.01324381457573039, 0.013616546844571734, 0.01392308166482875, 0.015395793544956588, 0.01955130120002721, 0.01643090434179913, 0.019433111028429418, 0.021173677291606584, 0.025847414195909548, 0.046127411979408686, 0.5923307691537673, 0.01781713271359728, 0.013523681554737146, 0.014302338805011205, 0.015511876991314594, 0.01968834175199206, 0.01552715246320384, 0.01740586980056199, 0.018854446995440286, 0.02085668904951224, 0.03419084933864765, 0.11256032853501846, 0.5592501627317129, 0.019189788158827936, 0.014431682519445092, 0.015661602742955538, 0.019573540751551464, 0.014779385458715311, 0.015257538755653213, 0.017196245044519585, 0.019281186028081782, 0.02876273148617239, 0.06884853324136887, 0.1433415406803632, 0.4439906214358872, 0.01920409794669227, 0.015246294187013027, 0.019771687896298278, 0.013298289976968778, 0.01569238749559692, 0.015909536765636705, 0.018066480418412308, 0.024018414747790203, 0.05029065023366361, 0.08248221315405514, 0.13579896206340314, 0.38983452220690173, 0.022528677212616425, 0.01920789849121202, 0.012649377082868347, 0.013769460658188355, 0.01518672669874252, 0.015522008719471594, 0.02067861175942493, 0.03493401548322515, 0.04754119716975038, 0.06454601206399847, 0.0981771426836267, 0.45996315302468804, 0.03083441088289213]\n",
      "\n",
      "mu: [0.5895195115356827, 0.5056935683921605, 0.41040978004942363, 0.35156740375759593, 0.3678132302713155, 0.341266536284339, 0.07329998042542618, 0.045953318120572385, 0.03655456845577058, 0.033731023253057754, 0.0365753458089337]\n",
      "\n",
      "\n",
      "Finished.\n",
      "\n",
      "End time is:  2020-03-17 14:17:00.537045\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import argparse\n",
    "import json\n",
    "import sys\n",
    "import os\n",
    "import math\n",
    "from scipy.optimize import fsolve\n",
    "from scipy import log\n",
    "import random\n",
    "import datetime\n",
    "\n",
    "\n",
    "# External libraries\n",
    "import torch\n",
    "from torch import optim\n",
    "\n",
    "# Internal libraries\n",
    "\n",
    "import models\n",
    "import posteriors\n",
    "import priors\n",
    "import hawkes_model, excitation_kernels\n",
    "import learners\n",
    "import utils\n",
    "\n",
    "from make_data_for_samples import make_data              #多个样本数据\n",
    "from make_data_for_estimate import make_estimate_data    #单个样本数据\n",
    "\n",
    "def make_object(module, name, args):\n",
    "    return getattr(module, name)(**args)\n",
    "\n",
    "#def learn_vi(events, end_time, vi_seed, adjacency_true, inference_param_dict, return_learner=False):\n",
    "def learn_vi(events, vi_seed, inference_param_dict, return_learner=False):\n",
    "    # Extract some parameters for easier access\n",
    "    #n_nodes = len(events)\n",
    "    n_events = len(events)\n",
    "    n_nodes = len(events[0])\n",
    "    M = inference_param_dict['excitation']['args'].get('M', 1)\n",
    "    n_params = n_nodes * (n_nodes * M + 1)\n",
    "    n_edges = M * n_nodes ** 2\n",
    "    # Set seed\n",
    "    np.random.seed(vi_seed)\n",
    "    # Set starting pointM * n_nodes ** 2\n",
    "    x0 = torch.tensor(\n",
    "        np.hstack((\n",
    "            np.hstack((  # alpha, the mean of the parameters\n",
    "                np.random.normal(loc=0.1, scale=0.1, size=n_nodes),\n",
    "                np.random.normal(loc=0.1, scale=0.1, size=n_edges),)),\n",
    "            np.hstack((  # beta=log(sigma), log of the variance of the parameters\n",
    "                np.log(np.clip(np.random.normal(loc=0.2, scale=0.1, size=n_nodes), 1e-1, 2.0)),\n",
    "                np.log(np.clip(np.random.normal(loc=0.2, scale=0.1, size=n_edges), 1e-1, 2.0)),))\n",
    "        )),\n",
    "        dtype=torch.float64, requires_grad=True\n",
    "    )\n",
    "    # Init Hawkes process model object\n",
    "    excitation_obj = make_object(excitation_kernels, **inference_param_dict['excitation'])\n",
    "    hawkes_model_obj = hawkes_model.HawkesModel(excitation=excitation_obj, verbose=False)\n",
    "    # Init the posterior object\n",
    "    posterior_obj = make_object(posteriors, **inference_param_dict['posterior'])\n",
    "    # Init the prior object\n",
    "    prior_type = inference_param_dict['prior']['name']\n",
    "    prior_args = inference_param_dict['prior']['args']\n",
    "    prior_args['C'] = torch.tensor(prior_args['C'], dtype=torch.float64)  # cast to tensor\n",
    "    prior_obj = make_object(priors, prior_type, prior_args)\n",
    "    # Init the variational inference model object\n",
    "    model = models.ModelHawkesVariational(\n",
    "        model=hawkes_model_obj, posterior=posterior_obj, prior=prior_obj,\n",
    "        **inference_param_dict['model']['args'])\n",
    "   \n",
    "    # Init the optimizer\n",
    "    opt_type = inference_param_dict['optimizer']['name']\n",
    "    opt_args = inference_param_dict['optimizer']['args']\n",
    "    opt = getattr(optim, opt_type)([x0], **opt_args)\n",
    "    # Init learner\n",
    "    learner = learners.VariationalInferenceLearner(\n",
    "        model=model, optimizer=opt, **inference_param_dict['learner']['args'])\n",
    "    # Fit the model\n",
    "    events_t = [torch.tensor(events_i) for events_i in events]  # cast to tensor\n",
    "    #learner.fit(events_t, end_time, x0, callback=callback)\n",
    "    learner.fit(events_t, x0=x0, callback=None)\n",
    "    print()\n",
    "    if return_learner:\n",
    "        return learner\n",
    "    # Extract the mode of the posterior\n",
    "    z_est_mode = learner.model.posterior.mode(learner.coeffs[:n_params], learner.coeffs[n_params:])\n",
    "    adj_est_ora = z_est_mode[n_nodes:].detach()\n",
    "    mu_est_ora = z_est_mode[:n_nodes].detach()\n",
    "    adj_est_ora = adj_est_ora.view(n_nodes, n_nodes, M)\n",
    "    adj_est = z_est_mode[n_nodes:].detach().numpy()\n",
    "    adj_est = np.reshape(adj_est, (n_nodes, n_nodes, M)).sum(-1).ravel()\n",
    "    mu_est = z_est_mode[:n_nodes].detach().numpy()\n",
    "    #mu_est = np.reshape(mu_est,n_nodes).ravel()\n",
    "    coeffs_est = learner.coeffs.detach().numpy()\n",
    "    #log_like_sum,min_intens,log_like,end_time = hawkes_model_obj.log_likelihood(mu_est_ora,adj_est_ora)\n",
    "    log_like_sum,intens_sum,integral_instesity,end_time = hawkes_model_obj.log_likelihood(mu_est_ora,adj_est_ora)\n",
    "    \n",
    "    return coeffs_est, adj_est,mu_est,intens_sum,integral_instesity,end_time\n",
    "\n",
    "\n",
    "def run(exp_dir, param_filename, output_filename, stdout=None, stderr=None):\n",
    "    # Reset random seed\n",
    "    np.random.seed(None)\n",
    "\n",
    "    if stdout is not None:\n",
    "        sys.stdout = open(stdout, 'w')\n",
    "    if stderr is not None:\n",
    "        sys.stderr = open(stderr, 'w')\n",
    "\n",
    "    print('\\nExperiment parameters')\n",
    "    print('=====================')\n",
    "    print(f'        exp_dir = {exp_dir:s}')\n",
    "    print(f' param_filename = {param_filename:s}')\n",
    "    print(f'output_filename = {output_filename:s}')\n",
    "    print(flush=True)\n",
    "    print('\\nStart time is: ', datetime.datetime.today())\n",
    "\n",
    "    result_dict = {}\n",
    "    \n",
    "    data_fileName = \"./data/DSL-StrongPasswordData.xls\"\n",
    "    global events\n",
    "    events = make_data('s032',10400,10410,data_fileName)\n",
    "    n_jumps_per_dim = list(map(len, events[0]))\n",
    "    print('\\nNumber of jumps:', len(events)*sum(n_jumps_per_dim))\n",
    "    print('\\nper node:', n_jumps_per_dim)\n",
    "    \n",
    "    C_list = [1.0]*132\n",
    "    \n",
    "    param_dict={'inference':{'vi_exp':{'excitation': {'name': 'ExponentialKernel','args': {'decay': 0.3, 'cut_off': 1000.0}}, \n",
    "                          'posterior': {'name': 'LogNormalPosterior', 'args': {}},\n",
    "                          'prior': {'name': 'GaussianLaplacianPrior', 'args': {'dim': 11, 'n_params': 132, 'C': C_list}}, \n",
    "                          'model': {'args': {'n_samples': 1, 'n_weights': 1, 'weight_temp': 1.0}}, \n",
    "                          'optimizer': {'name': 'Adam', 'args': {'lr': 0.01}}, \n",
    "                          'learner': {'args': {'tol': 1e-04, 'lr_gamma': 0.9999, 'max_iter': 40000, 'hyperparam_momentum': 0.5, 'hyperparam_interval': 100, 'hyperparam_offset': 0}}}}\n",
    "               }\n",
    "    \n",
    "\n",
    "    print('\\nINFERENCE')\n",
    "    print('=========')\n",
    "\n",
    "    for key, inference_param_dict in param_dict['inference'].items():\n",
    "        if key.startswith('vi'):\n",
    "            print(f'\\nRun VI ({key:s})')\n",
    "            print('------')\n",
    "            # Set random seed (for reproducibility)\n",
    "            np.random.seed()  # Reset random number generator to avoid dependency on simulation seed\n",
    "            #vi_seed = np.random.randint(2**32 - 1)\n",
    "            vi_seed = np.random.randint(2**16 - 1)\n",
    "            print(f'vi random seed: {vi_seed}')\n",
    "            # Run inference\n",
    "            global intens_sum\n",
    "            global integral_instesity\n",
    "            #coeffs_var, adj_var, mu_var, nu, varsigma = learn_vi(events, vi_seed, inference_param_dict)\n",
    "            coeffs_var, adj_var, mu_var,intens_sum,integral_instesity,end_time  = learn_vi(events, vi_seed, inference_param_dict)\n",
    "            #模型参数\n",
    "            adj_var = adj_var.ravel()\n",
    "            mu_var = mu_var.ravel()            \n",
    "          \n",
    "            global  end_time_result\n",
    "            end_time_result = [0.0]*len(end_time)\n",
    "            \n",
    "            for i in range(len(end_time)):\n",
    "                end_time_result[i]=end_time[i].tolist()\n",
    "                \n",
    "            expresion_temp = ''\n",
    "            events_n = len(events)\n",
    "            dim = len(events[0])\n",
    "            \n",
    "            for i in range(events_n):\n",
    "                temp = ''                  \n",
    "                for j in range(dim):\n",
    "                    temp += 'log('+str(intens_sum[i][j].detach().numpy())+ '-'+ 'epsilon_noise['+str(i)+'])'+ '+'   \n",
    "                #print(intens)\n",
    "                expresion_temp += temp[:-1] + '-' + str(integral_instesity[i].detach().numpy()) + '+' + str(dim) +'*'+ str(end_time_result[i])+'*'+ 'epsilon_noise['+str(i)+'],'\n",
    "\n",
    "            expresion = expresion_temp[:-1]\n",
    "            expresion = '['+expresion+']'\n",
    "         \n",
    "            result_dict.update({\n",
    "                key: {\n",
    "                    'vi_seed': vi_seed,             # VI random seed\n",
    "                    'coeffs': coeffs_var.tolist(),  # VI parameters\n",
    "                    'adjacency': adj_var.tolist(),  # VI Estimator\n",
    "                    'mu':  mu_var.tolist(),\n",
    "                    'expresion': expresion,\n",
    "                }\n",
    "            })\n",
    " \n",
    "\n",
    "    print('\\n\\nSave results...')\n",
    "    \n",
    "    print('\\ncoeffs:',  coeffs_var.tolist())\n",
    "    print( '\\nadjacency:', adj_var.tolist())\n",
    "    print('\\nmu:', mu_var.tolist())\n",
    "    #print('\\nnu:',nu)\n",
    "    #print('\\nvarsigma:',varsigma)\n",
    "\n",
    "    with open(os.path.join(exp_dir, output_filename), 'w') as output_file:\n",
    "        json.dump(result_dict, output_file)\n",
    "\n",
    "    # Log that the run is finished\n",
    "    print('\\n\\nFinished.')\n",
    "    print('\\nEnd time is: ', datetime.datetime.today())\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('-d', '--dir', dest='dir', type=str,\n",
    "                        #required=True, help=\"Working directory\")\n",
    "                        required=False, default=\".\")\n",
    "    parser.add_argument('-p', '--params', dest='param_filename', type=str,\n",
    "                        required=False, default='params.json',\n",
    "                        help=\"Input parameter file (JSON)\")\n",
    "    parser.add_argument('-o', '--outfile', dest='output_filename', type=str,\n",
    "                        required=False, default='output.json',\n",
    "                        help=\"Output file (JSON)\")\n",
    "    #args = parser.parse_args()\n",
    "    args = parser.parse_known_args()[0]\n",
    "\n",
    "    #run(exp_dir=args.dir, param_filename=args.param_filename,output_filename=args.output_filename)\n",
    "    run ('.','params.json','penalty10_decay0.3+s032_10400-10410.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
