{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Experiment parameters\n",
      "=====================\n",
      "        exp_dir = .\n",
      " param_filename = params.json\n",
      "output_filename = penalty10+decay0.1+s036_12250-12300.json\n",
      "\n",
      "\n",
      "Start time is:  2020-03-15 07:51:56.414305\n",
      "\n",
      "Number of jumps: 1100\n",
      "\n",
      "per node: [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n",
      "\n",
      "INFERENCE\n",
      "=========\n",
      "\n",
      "Run VI (vi_exp)\n",
      "------\n",
      "vi random seed: 6829\n",
      "end_iter is: 38669\n",
      "Converged!\n",
      "\n",
      "\n",
      "\n",
      "Save results...\n",
      "\n",
      "coeffs: [-0.6515652694316378, -0.7070147201967928, -2.1673319070117687, -2.131110380055726, -3.6581745574784246, -3.899330343733042, -4.436593270075662, -4.916753798797778, -5.006230624449326, -5.150527312020117, -5.342360612595374, -4.053623348209336, -4.22100134994801, -4.219272751043128, -4.129802175957928, -4.056917632934381, -3.910089878178106, -3.749096826744451, -3.6713790556903736, -3.5319492753082713, -3.3015589093010274, -2.911489720596724, -2.260557549538086, -3.9395832188773587, -4.212406382015516, -4.131550340304921, -4.055358947847328, -3.9255500052063836, -3.734532383481594, -3.667567969633924, -3.54207966418233, -3.2981347966874517, -2.939221035674543, -2.4336387317247703, 0.6625924146299209, -3.9101141413862726, -4.1277169274232275, -4.053880788830575, -3.952414776901299, -3.747485421335953, -3.665090523496037, -3.5447643787235714, -3.30129300875485, -2.931546140494347, -2.6152417907998173, -1.4827433935039556, 0.5556325379896976, -3.7885004145752528, -4.056883377258045, -3.924377301540327, -3.7428094350592196, -3.6683441710710847, -3.535674184553819, -3.3095293282862315, -2.9144782290996663, -3.0072011125769236, -2.424047350148107, -2.1720976848229845, 0.8787264585582931, -3.748657878418033, -3.94551574708461, -3.755327368285054, -3.6750067395667894, -3.563593325524565, -3.318423373365473, -2.914058760231995, -3.2230191659693026, -2.789757746890927, -2.6151733056979856, -1.9323172086039004, 0.9314857112636843, -3.5845246145965612, -3.7555636424908503, -3.6639531107165872, -3.539759813079348, -3.287448801693599, -2.9344673685021276, -3.521223825869864, -3.211854525089905, -3.1249183112917027, -2.7760744571414087, -2.388706621980662, 1.1178375057614989, -3.3609996809384977, -3.669820886901735, -3.528639992980104, -3.308806190110308, -2.9321764400100396, -3.762504399750854, -3.535566262768167, -3.4836699229936805, -3.272560004736314, -3.045468627178419, -2.470720500476229, 1.3240671410465092, -3.362248040861734, -3.5137018697954314, -3.2905410042598424, -2.9121262668834875, -3.795428440802797, -3.6264880901150467, -3.580840814326688, -3.3828057601656227, -3.191672900978342, -2.7214446914420876, -1.554939741017012, 1.3468115356204424, -3.1951548566512193, -3.2831960259571074, -2.9160924903893295, -3.9187354479108643, -3.731931295644341, -3.678901301027428, -3.552116111427453, -3.377850071314499, -3.00803246189367, -2.300956375857658, -1.8573165536648302, 1.4834168672761183, -2.869619244021713, -2.9012586576977064, -4.049159870229059, -3.9059224827512073, -3.833393707031478, -3.707392932590337, -3.616852251216424, -3.349646525187528, -2.903847388287926, -2.67740070199919, -2.2170139437766943, 1.752475580035183, -2.461934144941782, -2.404993928347436, -2.3626070834718114, -1.0485812576077302, -1.0530413142386448, -0.2564138395651069, -0.14879598535523036, -0.08135662686852478, 0.0027864076329632984, -0.01593553224988924, -0.03041675580581642, 0.015749918459827993, 0.0068235657297032685, 0.0023009846583489147, 0.0039840898950903635, -0.0013767824890113104, 0.0037447664567897858, 0.012678500620214457, 0.0004123079878266646, 0.0006204568758805805, 0.003247778862175042, 0.0024242969065537924, 0.03231265647855847, -0.19800711437891316, -0.0033424382299524305, 0.01369885894629437, -0.0026596916515514977, 0.0028792794253940227, -0.003710760406213826, -0.0043236571808502695, -0.011001897946224517, -0.0005244381383530037, 0.0204987435776097, 0.005767955120492732, -0.17536932231562086, -2.098482782720059, 0.0164556125128023, 0.0012757608382488207, 0.010444258034999383, -9.436593551575942e-05, -0.0020168775125842175, -0.003040265724408895, 0.009054901139493702, 0.0055461409883488764, -0.008250072451134403, -0.1212207838268012, -0.441299761008289, -1.9691301810329875, 0.01904858411316646, 0.004836963681298329, 0.01665427022167485, 0.007986512270997054, 0.0007640766234835158, 0.010156512010317207, -0.003363851956000092, 0.016001821549226736, -0.05165828387991875, -0.1614924874499421, -0.19115860093019374, -2.2170296058912444, -0.012846918112929538, 0.004466959207355544, 0.0021571109146879194, 0.010482130678204724, 0.005126377854901643, 0.008083676859412105, -0.003065900191505514, -0.032570453337984875, -0.07478454333200636, -0.08755391118813936, -0.24896256844787662, -2.171144282575079, -0.012798628676766725, 0.005724614907761014, 0.010222934962487506, 0.021251400146732907, 0.009012503082027992, -0.009079034690084241, -0.020462253695236295, -0.0069776621834711835, -0.03191766433854723, -0.07769076546247171, -0.12545807703368933, -2.2558902057397714, 0.010594739503363055, -0.0072405970603891335, 0.0180118197841671, 0.00016422143902685018, -0.00021276665415742308, -0.010586367806598598, -0.010941191829201094, -0.005122301663730429, -0.01613745669951193, -0.0244638169644768, -0.09824809314142963, -2.265156874707456, -0.015934340533773374, 0.004772464176872253, 0.013186840669086843, 0.012617889962708824, 0.020644602071890124, 0.0038904650985166628, -0.0024590809731381653, -0.0057655513638632866, -0.008395056642592767, -0.049796260511229345, -0.2345622313811413, -2.216212188961467, -0.002441667905047875, 0.014801608616433938, -0.002996391072455304, -0.011558990766265084, 0.003691834080322011, -0.007182669347893561, -0.00455927873719054, -0.002108173064926799, -0.031993472720805126, -0.0886900356295783, -0.17054879868393494, -2.230220801373654, 0.0004518422617648737, 0.011497369125491628, 0.013191961320346024, 0.009046063124810301, 0.02876922280207747, 0.012322822738226597, 0.007260648128785506, -0.011695742608699853, -0.011279160037846974, -0.026704396859261237, -0.05490815544669584, -2.2639972683577003, 0.007301123853093133]\n",
      "\n",
      "adjacency: [0.006299002277147613, 0.005377057838371162, 0.005368145571652762, 0.005934025863696852, 0.006317477485433603, 0.0071849184983691595, 0.008652371940879852, 0.009347739405803244, 0.010689792391805642, 0.013481737642633699, 0.01871838713015123, 0.05320756627705951, 0.007205428083611899, 0.005299287673932681, 0.005938818448020011, 0.0063383669722216025, 0.007312603184100689, 0.008862535782568865, 0.009601801984565663, 0.010662404340533655, 0.01303673308421, 0.019238847416451443, 0.04337784294079057, 1.9108559166946995, 0.007129081096893674, 0.005914953121151085, 0.006251155220921336, 0.007067658353051776, 0.008708464537491087, 0.009475664097097646, 0.010430311362080804, 0.013400717372637093, 0.019936932209678227, 0.03337489229236376, 0.15010061124311236, 1.709413725164252, 0.008007853078092096, 0.006303789942343711, 0.007025233807400992, 0.008574944911219627, 0.009373455264026347, 0.010501943727007372, 0.013530292685364436, 0.01931256234760247, 0.02005969808936969, 0.04293653935383649, 0.05759173082458602, 2.379428265622124, 0.008885884079895106, 0.00705167788884296, 0.008568600090059207, 0.009129975254170117, 0.010317654511037206, 0.013105515250117177, 0.02008171215780055, 0.015608266525636854, 0.02596939125796621, 0.031601843575447146, 0.07885791084101221, 2.5054766199685674, 0.01046988550669342, 0.008505190408174866, 0.009236341352506524, 0.010222349877527643, 0.01349228499493858, 0.019911194583308162, 0.011320665495742871, 0.015025656211551126, 0.01719601193889518, 0.026458893260104335, 0.04213846783095015, 3.024841247525972, 0.012495143239077024, 0.009509689612502517, 0.010406544979160581, 0.013445178851012112, 0.019609306632969448, 0.008725074842967077, 0.010955413496731852, 0.011407575612448675, 0.014396065081455182, 0.018357470695230745, 0.037167336104480565, 3.718386534354203, 0.013155941273231235, 0.010853230555561708, 0.013336301192619204, 0.019493325293819853, 0.007926197251629125, 0.009712909806920989, 0.01029667010558438, 0.012634288067442859, 0.0153748387051296, 0.026605138987554393, 0.11298621468138008, 3.7997143626647607, 0.015141992646451535, 0.013390071567932729, 0.020038143853284045, 0.00747730654387665, 0.00874439556835772, 0.009422652469750138, 0.010641019287913542, 0.012605240970195549, 0.019330913924994152, 0.043351333938596436, 0.07666530131811422, 4.357330541953578, 0.02084745632478354, 0.019751619063675705, 0.006245494658097224, 0.007268689514794643, 0.007501744394978756, 0.00880579904249987, 0.009740337668538636, 0.013213364492595402, 0.020619014300450822, 0.026638623583739328, 0.04446679050691112, 5.706884551205866, 0.03091098902894356]\n",
      "\n",
      "mu: [0.5169995741999281, 0.48876008457374553, 0.1012526604844355, 0.10510197474142978, 0.014165093769410912, 0.009639031656558989, 0.0050598010708337825, 0.0026789183381866915, 0.0025418526108642353, 0.0022619970600972037, 0.0017047073590617395]\n",
      "\n",
      "\n",
      "Finished.\n",
      "\n",
      "End time is:  2020-03-15 13:12:19.927868\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import argparse\n",
    "import json\n",
    "import sys\n",
    "import os\n",
    "import math\n",
    "from scipy.optimize import fsolve\n",
    "from scipy import log\n",
    "import random\n",
    "import datetime\n",
    "\n",
    "\n",
    "# External libraries\n",
    "import torch\n",
    "from torch import optim\n",
    "\n",
    "# Internal libraries\n",
    "\n",
    "import models\n",
    "import posteriors\n",
    "import priors\n",
    "import hawkes_model, excitation_kernels\n",
    "import learners\n",
    "import utils\n",
    "\n",
    "from make_data_for_samples import make_data              #多个样本数据\n",
    "from make_data_for_estimate import make_estimate_data    #单个样本数据\n",
    "\n",
    "def make_object(module, name, args):\n",
    "    return getattr(module, name)(**args)\n",
    "\n",
    "#def learn_vi(events, end_time, vi_seed, adjacency_true, inference_param_dict, return_learner=False):\n",
    "def learn_vi(events, vi_seed, inference_param_dict, return_learner=False):\n",
    "    # Extract some parameters for easier access\n",
    "    #n_nodes = len(events)\n",
    "    n_events = len(events)\n",
    "    n_nodes = len(events[0])\n",
    "    M = inference_param_dict['excitation']['args'].get('M', 1)\n",
    "    n_params = n_nodes * (n_nodes * M + 1)\n",
    "    n_edges = M * n_nodes ** 2\n",
    "    # Set seed\n",
    "    np.random.seed(vi_seed)\n",
    "    # Set starting pointM * n_nodes ** 2\n",
    "    x0 = torch.tensor(\n",
    "        np.hstack((\n",
    "            np.hstack((  # alpha, the mean of the parameters\n",
    "                np.random.normal(loc=0.1, scale=0.1, size=n_nodes),\n",
    "                np.random.normal(loc=0.1, scale=0.1, size=n_edges),)),\n",
    "            np.hstack((  # beta=log(sigma), log of the variance of the parameters\n",
    "                np.log(np.clip(np.random.normal(loc=0.2, scale=0.1, size=n_nodes), 1e-1, 2.0)),\n",
    "                np.log(np.clip(np.random.normal(loc=0.2, scale=0.1, size=n_edges), 1e-1, 2.0)),))\n",
    "        )),\n",
    "        dtype=torch.float64, requires_grad=True\n",
    "    )\n",
    "    # Init Hawkes process model object\n",
    "    excitation_obj = make_object(excitation_kernels, **inference_param_dict['excitation'])\n",
    "    hawkes_model_obj = hawkes_model.HawkesModel(excitation=excitation_obj, verbose=False)\n",
    "    # Init the posterior object\n",
    "    posterior_obj = make_object(posteriors, **inference_param_dict['posterior'])\n",
    "    # Init the prior object\n",
    "    prior_type = inference_param_dict['prior']['name']\n",
    "    prior_args = inference_param_dict['prior']['args']\n",
    "    prior_args['C'] = torch.tensor(prior_args['C'], dtype=torch.float64)  # cast to tensor\n",
    "    prior_obj = make_object(priors, prior_type, prior_args)\n",
    "    # Init the variational inference model object\n",
    "    model = models.ModelHawkesVariational(\n",
    "        model=hawkes_model_obj, posterior=posterior_obj, prior=prior_obj,\n",
    "        **inference_param_dict['model']['args'])\n",
    "   \n",
    "    # Init the optimizer\n",
    "    opt_type = inference_param_dict['optimizer']['name']\n",
    "    opt_args = inference_param_dict['optimizer']['args']\n",
    "    opt = getattr(optim, opt_type)([x0], **opt_args)\n",
    "    # Init learner\n",
    "    learner = learners.VariationalInferenceLearner(\n",
    "        model=model, optimizer=opt, **inference_param_dict['learner']['args'])\n",
    "    # Fit the model\n",
    "    events_t = [torch.tensor(events_i) for events_i in events]  # cast to tensor\n",
    "    #learner.fit(events_t, end_time, x0, callback=callback)\n",
    "    learner.fit(events_t, x0=x0, callback=None)\n",
    "    print()\n",
    "    if return_learner:\n",
    "        return learner\n",
    "    # Extract the mode of the posterior\n",
    "    z_est_mode = learner.model.posterior.mode(learner.coeffs[:n_params], learner.coeffs[n_params:])\n",
    "    adj_est_ora = z_est_mode[n_nodes:].detach()\n",
    "    mu_est_ora = z_est_mode[:n_nodes].detach()\n",
    "    adj_est_ora = adj_est_ora.view(n_nodes, n_nodes, M)\n",
    "    adj_est = z_est_mode[n_nodes:].detach().numpy()\n",
    "    adj_est = np.reshape(adj_est, (n_nodes, n_nodes, M)).sum(-1).ravel()\n",
    "    mu_est = z_est_mode[:n_nodes].detach().numpy()\n",
    "    #mu_est = np.reshape(mu_est,n_nodes).ravel()\n",
    "    coeffs_est = learner.coeffs.detach().numpy()\n",
    "    #log_like_sum,min_intens,log_like,end_time = hawkes_model_obj.log_likelihood(mu_est_ora,adj_est_ora)\n",
    "    log_like_sum,intens_sum,integral_instesity,end_time = hawkes_model_obj.log_likelihood(mu_est_ora,adj_est_ora)\n",
    "    \n",
    "    return coeffs_est, adj_est,mu_est,intens_sum,integral_instesity,end_time\n",
    "\n",
    "\n",
    "def run(exp_dir, param_filename, output_filename, stdout=None, stderr=None):\n",
    "    # Reset random seed\n",
    "    np.random.seed(None)\n",
    "\n",
    "    if stdout is not None:\n",
    "        sys.stdout = open(stdout, 'w')\n",
    "    if stderr is not None:\n",
    "        sys.stderr = open(stderr, 'w')\n",
    "\n",
    "    print('\\nExperiment parameters')\n",
    "    print('=====================')\n",
    "    print(f'        exp_dir = {exp_dir:s}')\n",
    "    print(f' param_filename = {param_filename:s}')\n",
    "    print(f'output_filename = {output_filename:s}')\n",
    "    print(flush=True)\n",
    "    print('\\nStart time is: ', datetime.datetime.today())\n",
    "\n",
    "    result_dict = {}\n",
    "    \n",
    "    data_fileName = \"./data/DSL-StrongPasswordData.xls\"\n",
    "    global events\n",
    "    events = make_data('s036',12250,12300,data_fileName)\n",
    "    n_jumps_per_dim = list(map(len, events[0]))\n",
    "    print('\\nNumber of jumps:', len(events)*sum(n_jumps_per_dim))\n",
    "    print('\\nper node:', n_jumps_per_dim)\n",
    "    \n",
    "    C_list = [1.0]*132\n",
    "    \n",
    "    param_dict={'inference':{'vi_exp':{'excitation': {'name': 'ExponentialKernel','args': {'decay': 0.1, 'cut_off': 1000.0}}, \n",
    "                          'posterior': {'name': 'LogNormalPosterior', 'args': {}},\n",
    "                          'prior': {'name': 'GaussianLaplacianPrior', 'args': {'dim': 11, 'n_params': 132, 'C': C_list}}, \n",
    "                          'model': {'args': {'n_samples': 1, 'n_weights': 1, 'weight_temp': 1.0}}, \n",
    "                          'optimizer': {'name': 'Adam', 'args': {'lr': 0.01}}, \n",
    "                          'learner': {'args': {'tol': 1e-04, 'lr_gamma': 0.9999, 'max_iter': 40000, 'hyperparam_momentum': 0.5, 'hyperparam_interval': 100, 'hyperparam_offset': 0}}}}\n",
    "               }\n",
    "    \n",
    "\n",
    "    print('\\nINFERENCE')\n",
    "    print('=========')\n",
    "\n",
    "    for key, inference_param_dict in param_dict['inference'].items():\n",
    "        if key.startswith('vi'):\n",
    "            print(f'\\nRun VI ({key:s})')\n",
    "            print('------')\n",
    "            # Set random seed (for reproducibility)\n",
    "            np.random.seed()  # Reset random number generator to avoid dependency on simulation seed\n",
    "            #vi_seed = np.random.randint(2**32 - 1)\n",
    "            vi_seed = np.random.randint(2**16 - 1)\n",
    "            print(f'vi random seed: {vi_seed}')\n",
    "            # Run inference\n",
    "            global intens_sum\n",
    "            global integral_instesity\n",
    "            #coeffs_var, adj_var, mu_var, nu, varsigma = learn_vi(events, vi_seed, inference_param_dict)\n",
    "            coeffs_var, adj_var, mu_var,intens_sum,integral_instesity,end_time  = learn_vi(events, vi_seed, inference_param_dict)\n",
    "            #模型参数\n",
    "            adj_var = adj_var.ravel()\n",
    "            mu_var = mu_var.ravel()            \n",
    "          \n",
    "            global  end_time_result\n",
    "            end_time_result = [0.0]*len(end_time)\n",
    "            \n",
    "            for i in range(len(end_time)):\n",
    "                end_time_result[i]=end_time[i].tolist()\n",
    "                \n",
    "            expresion_temp = ''\n",
    "            events_n = len(events)\n",
    "            dim = len(events[0])\n",
    "            \n",
    "            for i in range(events_n):\n",
    "                temp = ''                  \n",
    "                for j in range(dim):\n",
    "                    temp += 'log('+str(intens_sum[i][j].detach().numpy())+ '-'+ 'epsilon_noise['+str(i)+'])'+ '+'   \n",
    "                #print(intens)\n",
    "                expresion_temp += temp[:-1] + '-' + str(integral_instesity[i].detach().numpy()) + '+' + str(dim) +'*'+ str(end_time_result[i])+'*'+ 'epsilon_noise['+str(i)+'],'\n",
    "\n",
    "            expresion = expresion_temp[:-1]\n",
    "            expresion = '['+expresion+']'\n",
    "         \n",
    "            result_dict.update({\n",
    "                key: {\n",
    "                    'vi_seed': vi_seed,             # VI random seed\n",
    "                    'coeffs': coeffs_var.tolist(),  # VI parameters\n",
    "                    'adjacency': adj_var.tolist(),  # VI Estimator\n",
    "                    'mu':  mu_var.tolist(),\n",
    "                    'expresion': expresion,\n",
    "                }\n",
    "            })\n",
    " \n",
    "\n",
    "    print('\\n\\nSave results...')\n",
    "    \n",
    "    print('\\ncoeffs:',  coeffs_var.tolist())\n",
    "    print( '\\nadjacency:', adj_var.tolist())\n",
    "    print('\\nmu:', mu_var.tolist())\n",
    "    #print('\\nnu:',nu)\n",
    "    #print('\\nvarsigma:',varsigma)\n",
    "\n",
    "    with open(os.path.join(exp_dir, output_filename), 'w') as output_file:\n",
    "        json.dump(result_dict, output_file)\n",
    "\n",
    "    # Log that the run is finished\n",
    "    print('\\n\\nFinished.')\n",
    "    print('\\nEnd time is: ', datetime.datetime.today())\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('-d', '--dir', dest='dir', type=str,\n",
    "                        #required=True, help=\"Working directory\")\n",
    "                        required=False, default=\".\")\n",
    "    parser.add_argument('-p', '--params', dest='param_filename', type=str,\n",
    "                        required=False, default='params.json',\n",
    "                        help=\"Input parameter file (JSON)\")\n",
    "    parser.add_argument('-o', '--outfile', dest='output_filename', type=str,\n",
    "                        required=False, default='output.json',\n",
    "                        help=\"Output file (JSON)\")\n",
    "    #args = parser.parse_args()\n",
    "    args = parser.parse_known_args()[0]\n",
    "\n",
    "    #run(exp_dir=args.dir, param_filename=args.param_filename,output_filename=args.output_filename)\n",
    "    run ('.','params.json','penalty10+decay0.1+s036_12250-12300.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
